```
Geometria
A.A. 2020-2021
Docente: M. Trombetti
Docente: M. Trombetti
Dispense tratte dal corso di Informatica a cura dello studente S. Cerrone
Dispense tratte dal corso di Informatica
cura dello studente S. Cerrone

Sommario
0. Operazioni su di un Insieme ............................................................................................................ 4
Operazione interna a ğ‘† .................................................................................................................................. 4
Operazione esterna a ğ‘† ................................................................................................................................. 4
Prodotto scalare standard ............................................................................................................................. 4
1. Operazioni su Matrici (su â„) ............................................................................................................ 4
Somma di matrici e prodotto per uno scalare (reale) ................................................................................... 4
Prodotto righe per colonne e proprietÃ  ........................................................................................................ 4
Matrice trasposta .......................................................................................................................................... 5
Matrice a gradini ........................................................................................................................................... 5
Operazioni elementari di Riga ....................................................................................................................... 6
2. Sistemi Lineari ................................................................................................................................ 6
Equazioni lineari su â„ .................................................................................................................................... 6
Sistemi equivalenti ........................................................................................................................................ 7
Soluzioni di un sistema lineare ...................................................................................................................... 7
Sistema omogeneo ........................................................................................................................................ 9
Notazioni per i sistemi lineari ........................................................................................................................ 9
3. Spazi Vettoriali ............................................................................................................................... 9
Definizione ..................................................................................................................................................... 9
Esempi di spazi vettoriali ............................................................................................................................... 9
ProprietÃ  degli spazi vettoriali ..................................................................................................................... 11
Definizioni .................................................................................................................................................... 11
Sottospazi vettoriali ..................................................................................................................................... 11
Esempi di sottospazi vettoriali..................................................................................................................... 12
Alcune proprietÃ  e definizioni di sottospazi vettoriali (sottospazio generato) ........................................... 13
Somma diretta di sottospazi vettoriali ........................................................................................................ 14
Dipendenza ed indipendenza lineare .......................................................................................................... 14
Sistemi di vettori equivalenti ....................................................................................................................... 15
Relazione tra dipendenza e linearmente dipendenza ................................................................................. 16
Vettori finitamente generabili ..................................................................................................................... 18
Dimensione di uno spazio vettoriale ........................................................................................................... 19
Relazione di Grassmann .............................................................................................................................. 21
Forma canonica ........................................................................................................................................... 22
Metodi per estrarre una base da un sottospazio generato ........................................................................ 22
4. Matrici e Sistemi lineari ................................................................................................................ 23
Determinante di una matrice quadrata ...................................................................................................... 23
Minore di una matrice ................................................................................................................................. 24
Criteri di compatibilitÃ  di sistemi di equazioni lineari ................................................................................. 26
Risoluzione di sistemi lineari in situazioni particolari .................................................................................. 27
Sistemi omogenei ........................................................................................................................................ 28
Risoluzione sistema omogeneo con ğ‘› âˆ’ 1 equazioni indipendenti ed ğ‘› incognite .................................... 29
5. Applicazioni Lineari ....................................................................................................................... 30
Definizione ................................................................................................................................................... 30
Esempi ......................................................................................................................................................... 30
Proposizioni ................................................................................................................................................. 31
Concetto di Ker e sue proprietÃ  .................................................................................................................. 32
Isomorfismo coordinato .............................................................................................................................. 33
Forma canonica delle applicazioni lineari e matrice di passaggio ............................................................... 34
2

6. Matrici simili e diagonalizzazione (spazi vettoriali) ......................................................................... 35
Matrici simili ................................................................................................................................................ 35
Diagonalizzazione di un endomorfismo ...................................................................................................... 36
Diagonalizzazione di una matrice ................................................................................................................ 40
Spazi Vettoriali: Prodotti diretti esterni ...................................................................................................... 40
7. Geometria .................................................................................................................................... 41
Spazio vettoriale dei vettori geometrici liberi dello spazio (e del piano) .................................................... 41
Cambiamenti di riferimento ........................................................................................................................ 44
Prodotto vettoriale ...................................................................................................................................... 44
Rappresentazioni ......................................................................................................................................... 45
Rappresentazione di un piano nello spazio ............................................................................................. 45
Rappresentazione della retta nel piano .................................................................................................. 47
Altre tipologie di espressione ...................................................................................................................... 48
Espressione di una retta passante per due punti .................................................................................... 48
Coseni direttori ........................................................................................................................................ 48
Rette parallele ......................................................................................................................................... 48
Distanza tra insiemi ................................................................................................................................. 49
Punto medio di un segmento .................................................................................................................. 49
Asse del segmento ................................................................................................................................... 49
Rappresentazione ordinaria di una retta nello spazio ............................................................................ 49
3

0. Operazioni su di un Insieme
Operazione interna a ğ‘º
Sia ğ‘† un insieme non vuoto, unâ€™operazione âŠ¥: ğ‘† Ã— ğ‘† â†’ ğ‘† si dice interna a S. Tutte le operazioni interne
possono essere impropriamente considerate esterne; un esempio di operazione interna Ã¨ +:â„2 Ã— â„2 â†’ â„2
Operazione esterna a ğ‘º
Siano ğ‘†, ğ´ â‰  âˆ…, unâ€™operazione âŠ¥: ğ‘† Ã— ğ´ â†’ ğ‘† si dice esterna a ğ‘† con dominio di operatori in ğ´ perchÃ© gli
oggetti di ğ´ agiscono su ğ‘† portandoli in altri oggetti di ğ‘†. Esempio Ã¨ la moltiplicazione â‹… âˆ¶ â„2 Ã— â„ â†’ â„2.
Prodotto scalare standard
â‹… âˆ¶ â„ğ‘› Ã— â„ğ‘› â†’ â„, il quale prende in input due ennuple di numeri reali e restituisce un numero reale; non Ã¨
nÃ© unâ€™operazione interna ne esterna, infatti (ğ‘1, â€¦ , ğ‘ğ‘›) â‹… (ğ‘1,â€¦ , ğ‘ğ‘›) = ğ‘1 â‹… ğ‘1 +â‹¯+ ğ‘ğ‘› â‹… ğ‘ğ‘›. Un prodotto
scalare standard ha la proprietÃ  di essere una forma bilineare simmetrica definita positiva. Ovvero:
1) Simmetria: ğ‘ â‹… ğ‘ = ğ‘ â‹… ğ‘ con ğ‘ = (ğ‘1,â€¦ , ğ‘ğ‘›) e ğ‘ = (ğ‘1,â€¦ , ğ‘ğ‘›)
2) Bilineare: (â„ â‹… ğ‘ + ğ‘˜ â‹… ğ‘) â‹… ğ‘ = â„(ğ‘ â‹… ğ‘) + ğ‘˜(ğ‘ â‹… ğ‘) con â„, ğ‘˜ scalari
Dimostrazione: Sia ğ‘ = (ğ‘1, ğ‘2), ğ‘ = (ğ‘1, ğ‘2) e ğ‘ = (ğ‘1, ğ‘2) allora:
(â„ â‹… ğ‘ + ğ‘˜ â‹… ğ‘) â‹… ğ‘ = (â„(ğ‘1, ğ‘2) + ğ‘˜(ğ‘1, ğ‘2))(ğ‘1, ğ‘2) = (â„ğ‘1ğ‘1 + â„ğ‘2ğ‘2) + (ğ‘˜ğ‘1ğ‘1 + ğ‘˜ğ‘2ğ‘2)
= â„(ğ‘1ğ‘1 + ğ‘2ğ‘2) + ğ‘˜(ğ‘1, ğ‘1 + ğ‘2ğ‘2) = â„(ğ‘ â‹… ğ‘) + ğ‘˜(ğ‘ â‹… ğ‘)
3) Positiva: ğ‘ â‹… ğ‘ â‰¥ 0 e ğ‘ â‹… ğ‘ = 0 â‡” ğ‘ = (0, â€¦ ,0)
1. Operazioni su Matrici (su â„)
Somma di matrici e prodotto per uno scalare (reale)
Una matrice ğ´ ad ğ‘› righe ed ğ‘š colonne si scrive nel modo seguente:
ğ´ = ( â‹® â‹±
ğ‘1,1 â‹¯ ğ‘1,ğ‘š
ğ‘ğ‘›,1 â‹¯ ğ‘ğ‘›,ğ‘š
â‹® )
A volte posso denotare la matrice in modo generico come ğ´ = (ğ‘ğ‘–ğ‘—)ğ‘–=1,â€¦,ğ‘› ;ğ‘—=1,â€¦,ğ‘š , o usare la definizione
formale ğ´ = {1,â€¦ , ğ‘›} Ã— {1,â€¦ , ğ‘š} â†’ â„. Lâ€™insieme delle matrici su â„ con ğ‘› righe ed ğ‘š colonne viene
rappresentato da ğ‘€ğ‘›,ğ‘š(â„) o semplicemente â„ğ‘›,ğ‘š.
Per le matrici possiamo definire unâ€™operazione interna +: â„ğ‘›,ğ‘š Ã— â„ğ‘›,ğ‘š â†’ â„ğ‘›,ğ‘š del tipo:
(( â‹® â‹±
[/
\\
ğ‘1,1 â‹¯ ğ‘1,ğ‘š
ğ‘ğ‘›,1 â‹¯ ğ‘ğ‘›,ğ‘š
â‹® ) , ( â‹® â‹±
\
/ \
ğ‘1,1 â‹¯ ğ‘1,ğ‘š
ğ‘ğ‘›,1 â‹¯ ğ‘ğ‘›,ğ‘š
â‹® )) â†’ (
ğ‘1,1 + ğ‘1,1 â‹¯ ğ‘1,ğ‘š + ğ‘1,ğ‘š
â‹®
J)\ğ‘ğ‘›,1 + ğ‘ğ‘›,1 â‹¯ ğ‘ğ‘›,ğ‘š + ğ‘ğ‘›,ğ‘š
â‹±
â‹®
)
Possiamo definire anche unâ€™operazione esterna â‹… âˆ¶ â„ğ‘›,ğ‘š Ã— â„ â†’ â„ğ‘›,ğ‘š del tipo ((ğ‘ğ‘–ğ‘—), â„) â†’ (â„ â‹… ğ‘ğ‘–ğ‘—)
Prodotto righe per colonne e proprietÃ 
Il prodotto righe per colonne Ã¨ unâ€™operazione del tipo â‹… âˆ¶ â„ğ‘›,ğ‘š Ã— â„ğ‘š,ğ‘™ â†’ â„ğ‘›,ğ‘™; infatti affinchÃ©
questâ€™operazione sia possibile devo avere le colonne della matrice di sinistra uguale alle righe della matrice
di destra, e come risultato avrÃ² una matrice che ha il numero di righe della matrice a sinistra e il numero di
colonne della matrice di destra.
Si definisce prodotto righe per colonne di ğ´ âˆˆ â„ğ‘š,ğ‘› e ğµ âˆˆ â„ğ‘›,ğ‘
la matrice, che si denota con ğ´ Ã— ğµ o
semplicemente con ğ´ğµ, definita dalla posizione ğ´ğµ = (ğ´ğ‘– Â· ğµğ‘—) âˆˆ â„ğ‘š,ğ‘
Esercizio: Fare, ove possibile, il prodotto righe per colonne delle seguenti matrici:
(
5 âˆ’1
0 2
1 âˆ’3
) â‹… (2 0
1 2
)
( 3 1
âˆ’1 4
) â‹… (5 âˆ’2) (5 âˆ’1 2
0 2 3
) â‹… (
2 0 3 âˆ’1
1 2
0 2
0 âˆ’1 0 0
) (1 1
2 2
) â‹… ( 1 âˆ’1
âˆ’1 1
)
4

Il prodotto righe per colonne fornisce le seguenti proprietÃ :
1) DistributivitÃ  a destra: âˆ€ğ´ âˆˆ â„ğ‘š,ğ‘› e âˆ€ğµ, ğ¶ âˆˆ â„ğ‘›,ğ‘, ğ´(ğµ + ğ¶) = ğ´ğµ + ğ´ğ¶
Dim.: ğ´(ğµ + ğ¶) = (ğ‘ğ‘–ğ‘—) (ğ‘ğ‘˜ğ‘™ + ğ‘ğ‘˜ğ‘™
2) DistributivitÃ  a sinistra: (ğ´ + ğµ)ğ¶ = ğ´ğ¶ + ğµğ¶, âˆ€ğ´, ğµ âˆˆ â„ğ‘š,ğ‘› ğ‘’ âˆ€ğ¶ âˆˆ â„ğ‘›,ğ‘
La dimostrazione Ã¨ analoga alla precedente
YT)
/
3) ğ´ğµ â‰  ğµğ´, ad esempio: (0 1Vac
) (1 1
iN0 17X0 0
) = (0 0
0 0
) invece (1 1
0 0
) (0 1
0 1
) = (0 2
0 0
)
4) Ha elemento neutro formato dalla matrice identica ğ¼ğ‘› formata da tutti zeri eccetto per la diagonale
principale con 1. La matrice identica deve essere quadrata: ğ¼ğ‘› = (
1
â‹±
0
1
0
). La diagonale secondaria
sarÃ  quella da destra a sinistra. La matrice identica ha la proprietÃ  che ğ¼ğ‘›ğ´ = ğ´ğ¼ğ‘› = ğ´.
ESERCIZIO: verifica che ğ¼ğ‘›ğ´ = ğ´ğ¼ğ‘› = ğ´. E che ğ¼ğ‘› sia lâ€™unico elemento neutro.
5) Gode di proprietÃ  commutativa nel caso di matrici scalari ğ‘† di ordine ğ‘› (che occupano solo la
diagonale principale con una stessa costante, mentre il resto Ã¨ 0), infatti qualunque sia la matrice ğ´
di ordine ğ‘› avremo ğ´ğ‘† = ğ‘†ğ´. Possiamo definire ğ‘†ğ‘› = â„ â‹… ğ¼ğ‘›.
Nota bene che in generale non commutano matrici diagonali (tutti 0 eccetto per la diagonale) che
non hanno la stessa costante.
6) âˆ€ğ´ âˆˆ â„ğ‘š,ğ‘›, âˆ€ğµ âˆˆ â„ğ‘›,ğ‘ e âˆ€â„ âˆˆ â„ ğ´(â„ğµ) = â„(ğ´ğµ) = (â„ğ´)ğµ
Dim.: (ğ’‚ğ’Šğ’‹)[ğ’‰(ğ’ƒğ’Šğ’‹)] = (ğ‘ğ‘–ğ‘—)(â„ğ‘ğ‘–ğ‘—) = (ğ‘ğ‘– â‹… â„ğ‘ğ‘—) = ğ’‰(ğ’‚ğ’Š â‹… ğ’ƒğ’‹) = (â„ğ‘ğ‘– â‹… ğ‘ğ‘—) = (â„ğ‘ğ‘–ğ‘—)(ğ‘ğ‘–ğ‘—) = [ğ’‰(ğ’‚ğ’Šğ’‹)](ğ’ƒğ’Šğ’‹)
ğ´(ğµğ¶) = (ğ´ğµ)ğ¶
7) AssociativitÃ : âˆ€ğ´ âˆˆ â„ğ‘š,ğ‘›, âˆ€ğµ âˆˆ â„ğ‘›,ğ‘, âˆ€ğ¶ âˆˆ â„ğ‘,ğ‘—
ğ‘›
ğ´(ğµğ¶) = ğ´ğ· = ğ‘ğ‘– â‹… ğ‘‘ğ‘— =âˆ‘(ğ‘ğ‘–ğ‘˜ğ‘‘ğ‘˜ğ‘—)
NW
~ 7a
ğ‘˜=1
=âˆ‘(ğ‘ğ‘–ğ‘˜ (âˆ‘(ğ‘ğ‘˜ğ‘™ ğ‘ğ‘™ğ‘—)
ğ‘
al (wa.
ğ‘›
ğ‘˜=1
ğ‘™=1
))
\\
yy
=âˆ‘(ğ‘ğ‘–ğ‘˜ ğ‘ğ‘˜ğ‘™ğ‘ğ‘™ğ‘—)
ğ‘˜,ğ‘™
= ğ´ğµğ¶ = (ğ´ğµ)ğ¶
Matrice trasposta
Lâ€™operazione di trasposta Ã¨ unâ€™operazione unaria ğ‘¡: â„ğ‘›,ğ‘š â†’ â„ğ‘š,ğ‘› dove semplicemente scambio le righe con
le colonne: ğ´ = (1 2 3
4 5 6
) â†’ (
1 4
2 5
3 6
) = ğ´ğ‘¡ . Formalmente una i-riga diverrÃ  una i-colonna: ğ‘ğ‘– â†’ (ğ‘ğ‘¡)
ğ‘–
âŸ    
ğ‘‘ğ‘˜ğ‘™
) = (ğ‘ğ‘– â‹… ğ‘‘ğ‘—) = (ğ‘ğ‘– â‹… (ğ‘ğ‘— + ğ‘ğ‘—)) = (ğ‘ğ‘– â‹… ğ‘ğ‘—) + (ğ‘ğ‘– â‹… ğ‘ğ‘—) = ğ´ğµ + ğ´ğ¶
Sia ğ´ âˆˆ â„ğ‘š,ğ‘›, ğµ âˆˆ â„ğ‘›,ğ‘. Allora la trasposta ha le seguenti proprietÃ :
1) (ğ´ğµ)ğ‘¡ = ğµğ‘¡ğ´ğ‘¡
Dimostrazione: consideriamo ğ¶ = ğ´ğµ, ğ· = (ğ´ğµ)ğ‘¡ = ğ¶ğ‘¡ e ğ¸ = ğµğ‘¡ğ´ğ‘¡ con ğ´ğ‘¡ = ğ´â€², ğµğ‘¡ = ğµâ€² allora:
ğ· = ğ‘‘ğ‘–ğ‘— = ğ‘ğ‘—ğ‘– = ğ‘ğ‘— â‹… ğ‘ğ‘– =âˆ‘ğ‘ğ‘—ğ‘˜ğ‘ğ‘˜ğ‘–
ğ‘˜
=âˆ‘ğ‘ğ‘˜ğ‘—
XN
â€² ğ‘ğ‘–ğ‘˜
â€²
Lad
ğ‘˜
=âˆ‘ğ‘ğ‘–ğ‘˜
â€²
ğ‘˜
2) ğµğ‘¡ğ´ğ‘¡ â‰  ğ´ğ‘¡ğµğ‘¡ il che significa in particolare che (ğ´ğµ)ğ‘¡ = ğµğ‘¡ğ´ğ‘¡ â‰  ğ´ğ‘¡ğµğ‘¡
3) (ğ´ğµğ¶)ğ‘¡ = ğ¶ğ‘¡ğµğ‘¡ğ´ğ‘¡
4) (â„ğ´ + ğ‘˜ğµ)ğ‘¡ = â„(ğ´ğ‘¡) + ğ‘˜(ğµğ‘¡) che si generalizza in (â„1ğ´1 +â‹¯+ â„ğ‘›ğ´ğ‘›)ğ‘¡ = â„1(ğ´1
ğ‘¡ ) +â‹¯+ â„ğ‘›(ğ´ğ‘›
ğ‘¡ )
5) (ğ´ğ‘¡)ğ‘¡ = ğ´; ovviamente la trasposta della trasposta Ã¨ la matrice originale.
Matrice a gradini
Il concetto della matrice a gradine Ã¨ che il numero degli zeri che precedono il primo elemento diverso da zero
in ogni riga aumenta di riga in riga fino ad eventuali righe costituite da soli zeri. Il primo elemento non nullo
che si incontra da sinistra si chiama pivot. Una delle proprietÃ  della matrice a gradini Ã¨ che se una matrice a
gradini Ã¨ priva di righe nulle allora il numero di righe deve essere minore o uguale al numero di colonne.
Di seguito esempi di matrici a gradini:
(
1 2 0 3
0 1 2 3
0 0 4 5
) (1 0 0 0)
(2 0 0
0 1 0
) (
1 2 0 0
0 2 0 3
0
0
0
0
0
0
0
0
)
5
â€²
ğ‘ğ‘˜ğ‘—
= ğ‘ğ‘– â‹… ğ‘ğ‘— = ğ‘’ğ‘–ğ‘— = ğ¸
t 4
t 14

Operazioni elementari di Riga
ğ´ = (
ğ‘1 1 â‹¯ ğ‘1 ğ‘›
â‹®
â‹±
ğ‘ğ‘š 1 â‹¯ ğ‘ğ‘š ğ‘›
â‹® ) âˆˆ â„ğ‘š,ğ‘› che possiamo rappresentare con le notazioni ğ´ = (
Le operazioni elementari di riga sono:
1) Definiamo la funzione ğ¸1
ğ‘1
â‹®
ğ‘ğ‘›
) = (ğ‘1 â€¦ ğ‘ğ‘›).
ğ‘–,ğ‘—: â„ğ‘š,ğ‘› â†’ â„ğ‘š,ğ‘› che prende la riga i-esima della matrice e la scambia con la
riga j-esima della stessa matrice.
2) ğ¸2
â„,ğ‘–: â„ğ‘š,ğ‘› â†’ â„ğ‘š,ğ‘› che non fa altro che moltiplicare la i-esima riga per una costante â„ â‰  0 e â„ âˆˆ â„
3) ğ¸3
ğ‘–,ğ‘—: â„ğ‘š,ğ‘› â†’ â„ğ‘š,ğ‘› che agisce sostituendo alla j-esima riga la somma tra la i-esima riga e la j-esima
riga.
ğ´ âŸ¼ ğ¸1
ğ‘–,ğ‘— =
 
 
(
 
ğ‘1
â‹®
   
ğ‘ğ‘—
â‹®
ğ‘ğ‘›)
 
 
 
ğ‘ğ‘–
â‹®
ğ´ âŸ¼ ğ¸2
â„,ğ‘– =
(
 
 
ğ‘ğ‘› )
 
ğ‘1
â‹®
â„ğ‘ğ‘–
â‹®
 
ğ´ âŸ¼ ğ¸3
ğ‘–,ğ‘— =
 
 
(
 
 
ğ‘1
â‹®
ğ‘ğ‘–
â‹®
ğ‘ğ‘– + ğ‘ğ‘—
â‹®
ğ‘ğ‘›
 
 
)
 
 
Queste 3 operazioni possono essere combinate tra di loro dando luce ad altre operazioni, utile Ã¨ la seguente:
4) ğ¸4
â„,ğ‘–,ğ‘— che combina ğ¸2 ed ğ¸3, quindi ğ‘ğ‘— â†’ â„ğ‘ğ‘– + ğ‘ğ‘— (utile per annullare una riga)
Se ğ´â€² Ã¨ una matrice che si puÃ² ottenere da ğ´ mediante un numero finito di operazioni elementari allora
diciamo che ğ´ e ğ´â€² sono equivalenti (per righe).
Proposizione: Per ogni matrice esiste una matrice a gradini ad essa equivalente.
Dimostrazione per induzione sul numero di righe: Sia ğ´ âˆˆ â„ğ‘›,ğ‘š, per ğ‘› = 1 avremo una matrice giÃ  a gradini,
ğ´ = (ğ‘11 â€¦ ğ‘1ğ‘š), supposta vera per ğ‘› dimostriamo che sia vera per ğ‘› + 1: se ğ´ Ã¨ una matrice nulla allora
Ã¨ anche a gradini, ora se ğ´ â‰  0 possiamo supporre che ci sia almeno un elemento non nullo, per cui posso
prendere la prima riga non nulla e scambiarla con unâ€™eventuale riga nulla usando ğ¸1. Ora non ci resta che
annullare lâ€™elemento al di sotto, a tal scopo possiamo usare le operazioni ğ¸2, ğ¸3 o ğ¸4. Iterando questo
processo potrÃ² annullare, se necessario, tutte le righe successive.
ESEMPIO: (
1 âˆ’1 0 1
1 2 0 0
0 1 0 1
) ğ¸4
âˆ’1,1,2
âŸ¶
(
1 âˆ’1 0 1
0 3 0 âˆ’1
0 1
0 1 âŸ¶ 0 3 0 âˆ’1
) ğ¸1
2,3
(
1 âˆ’1 0 1
0 1
0 1 ) ğ¸4
âˆ’3,2,3
âŸ¶
ESERCIZIO riduci a gradini, ove necessario, le seguenti matrici: (
0 0 0 1
0 1 1 1
1
1
1
1
2. Sistemi Lineari
Equazioni lineari su â„
Diciamo equazione lineare sul campo â„ nelle incognite ğ‘¥1,â€¦ , ğ‘¥ğ‘› una equazione del tipo ğ’‚ğŸğ’™ğŸ +â‹¯+
ğ’‚ğ’ğ’™ğ’ = ğ’ƒ con ğ‘1, â€¦ , ğ‘ğ‘›, ğ‘ âˆˆ â„, gli ğ‘ğ‘– sono chiamati coefficienti delle rispettive incognite ğ‘¥ğ‘– mentre ğ‘ Ã¨ il
termine noto. Nel caso ğ‘ = 0 allora lâ€™equazione si dice lineare omogenea.
Si definisce un sistema lineare ğ‘š equazioni ed ğ‘› incognite ğ‘† {
ğ‘1 1ğ‘¥1 +â‹¯+ ğ‘1 ğ‘›ğ‘¥ğ‘› = ğ‘1
â‹®
ğ‘ğ‘š 1ğ‘¥1 +â‹¯+ ğ‘ğ‘š ğ‘›ğ‘¥ğ‘› = ğ‘ğ‘š
soluzione del sistema si intende la n-upla (ğ‘¦1, â€¦ , ğ‘¦ğ‘›) tale che ciascuna delle equazioni risulta verificata
sostituendo ad ğ‘¥ğ‘– ğ‘¦ğ‘–. Lâ€™insieme delle soluzioni lo indico con ğ‘† = {(ğ‘¦1, â€¦ , ğ‘¦ğ‘›)| ğ‘ ğ‘–ğ‘ğ‘›ğ‘œ ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘– ğ‘‘ğ‘– ğ‘†}
6
, mentre con
1
1
1
1
(
1 âˆ’1 0 1
0 1 0 1
0 0 0 âˆ’4
) , (
1 1 1
1 1 1
1
1
1
1
1
1
) , (
ğœ‹
ğ‘’
0 ğ‘’
ğœ‹)
ğœ‹
)

Un sistema si dice compatibile se ammette almeno una soluzione, incompatibile altrimenti. Nel caso il
sistema sia compatibile allora esso puÃ² essere determinato nel caso abbia una sola soluzione e
indeterminato se ammette infinite soluzioni (fondamentalmente in â„ si hanno solo questi due casi per un
sistema compatibile, quindi o una oppure infinite).
Definisco la matrice dei coefficienti (o matrice incompleta) ğ´ âˆˆ â„ğ‘š,ğ‘› = ( â‹® â‹± â‹® ) con ğ‘› numero
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘š1 â‹¯ ğ‘ğ‘šğ‘›
delle incognite ed ğ‘š delle equazioni, se a questa matrice aggiungo la colonna dei termini noti avrÃ² la matrice
completa(
ğ‘11 â‹¯ ğ‘1ğ‘›
â‹® â‹± â‹®
ğ‘ğ‘š1 â‹¯ ğ‘ğ‘šğ‘› ğ‘ğ‘š
|
ğ‘1
â‹®
) (la linea divisoria delinea quale sia la matrice dei coefficienti).
Se la matrice ha una particolare forma anche il sistema Ã¨ detto avere quella forma.
Sistemi equivalenti
Un sistema ğ‘† Ã¨ equivalente a ğ‘†â€² se ammettono le stesse soluzione ovvero ğ‘† = ğ‘†â€² (con la segnatura specifico
che sto parlando delle soluzioni di quel sistema), per dimostrare che due sistemi sono equivalenti si puÃ² usare
la doppia inclusione (ovvero verificare che ğ‘† Ã¨ contenuto in ğ‘†â€² e che ğ‘†â€² Ã¨ contenuto in ğ‘†).
Proposizione: Ogni sistema di equazioni lineari Ã¨ equivalente ad un sistema a gradini.
Dimostrazione: bisogna verificare che le operazioni ğ¸1, ğ¸2, ğ¸3, ğ¸4 non influiscono nellâ€™insieme delle soluzioni
del sistema lineare. Per ğ¸1 che scambia due righe Ã¨ evidente che non influisce nel sistema poichÃ© il sistema
non dipende dallâ€™ordine dellâ€™equazioni. ğ¸2 moltiplica una riga per uno scalare â„ â‰  0, diciamo che se ğ‘¦ âˆˆ ğ‘†
avrÃ² ğ‘¦1ğ‘ğ‘–1 +â‹¯+ ğ‘¦ğ‘›ğ‘ğ‘–ğ‘› = ğ‘ğ‘– che Ã¨ equivalente a ğ‘¦1(â„ğ‘ğ‘–1) +â‹¯+ ğ‘¦ğ‘›(â„ğ‘ğ‘–ğ‘›) = â„(ğ‘¦1ğ‘ğ‘–1 +â‹¯+ ğ‘¦ğ‘›ğ‘ğ‘–ğ‘›) = â„ğ‘ğ‘–
Ora resta da provare la ğ¸3 (essendo ğ¸4 combinazione di ğ¸2 e ğ¸3), questa operazione significa sostituire ad
una riga ğ‘ğ‘— = ğ‘ğ‘– + ğ‘ğ‘—, quindi avrÃ² una equazione di questo tipo: (ğ‘ğ‘–1 + ğ‘ğ‘—1)ğ‘¥1 +â‹¯+ (ğ‘ğ‘–ğ‘› + ğ‘ğ‘—ğ‘›) = ğ‘ğ‘– + ğ‘ğ‘—
quindi cambierÃ  solo lâ€™equazione j-esima che comunque Ã¨ scritta come somma di due equazioni,
praticamente sommo un equazione membro a membro, il che non mi cambia le soluzioni del sistema. CosÃ¬
abbiamo dimostrato che ğ‘† âŠ† ğ‘†â€², il viceversa ğ‘†â€² âŠ† ğ‘† Ã¨ evidente poichÃ© se partiamo dal nostro sistema
possiamo invertire le operazioni ğ¸ğ‘– tramite operazioni inverse per ritrovarci sempre il sistema ğ‘†. Quindi
verificato che le operazioni sulle righe non influiscono sulle equazioni abbiamo anche dimostrato che un
sistema Ã¨ equivalente ad un sistema a gradini poichÃ© per ogni matrice esiste una matrice a gradini ad essa
equivalente.
La precedente preposizione ci aiuta a risolvere sistemi complessi poichÃ© in un sistema a gradini le soluzioni
sono dirette; quindi, dovrÃ² solo trovarmi la matrice a gradini della nostra matrice completa.
Soluzioni di un sistema lineare
Sia ğ‘š il numero di equazioni ed ğ‘› il numero di incognite di un sistema ğ‘†, si possono definire i seguenti casi:
â€¢
ğ‘š = ğ‘› = 1: ğ‘11ğ‘¥1 = ğ‘1 {
ğ‘11 = ğ‘1 = 0: ğ‘’ğ‘ğ‘¢ğ‘ğ‘§ğ‘–ğ‘œğ‘›ğ‘’ ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘ğ‘ â‡’ ğ‘–ğ‘›ğ‘“ğ‘–ğ‘›ğ‘–ğ‘¡ğ‘’ ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘–
ğ‘11 â‰  0 â‡’ ğ‘¥1 = ğ‘11
âˆ’1ğ‘1
ğ‘11 = 0 ğ‘’ ğ‘1 â‰  0 ğ‘›ğ‘œğ‘› ğ‘’ğ‘ ğ‘–ğ‘ ğ‘¡ğ‘œğ‘›ğ‘œ ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘–
â€¢ ğ‘š = 1 ğ‘’ ğ‘› > 1: ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘›ğ‘¥ğ‘› = ğ‘1 {
ğ‘11 = â‹¯ = ğ‘1ğ‘› = ğ‘1 = 0 ğ‘’ğ‘ğ‘¢ğ‘ğ‘§ğ‘–ğ‘œğ‘›ğ‘– ğ‘–ğ‘‘ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘ğ‘
ğ‘11 = â‹¯ = ğ‘1ğ‘› = 0 ğ‘’ ğ‘1 â‰  0 ğ‘›ğ‘œğ‘› ğ‘’ğ‘ ğ‘–ğ‘ ğ‘¡ğ‘œğ‘›ğ‘œ ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘–
in
questo caso, se esiste un elemento diverso da zero, supponiamo ğ‘11 posso scrivere il mio sistema come
ğ‘11ğ‘¥1 = ğ‘1 âˆ’ ğ‘12ğ‘¥2 âˆ’â‹¯âˆ’ ğ‘1ğ‘›ğ‘¥ğ‘› dove poi mi Ã¨ permesso scegliere un valore ğ‘¦ğ‘– per ogni ğ‘¥2, â€¦ , ğ‘¥ğ‘› con
cui avrÃ² che âˆƒ! ğ‘¦1: (ğ‘¦1, ğ‘¦2, â€¦ , ğ‘¦ğ‘›) ğ‘ ğ‘–ğ‘ ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘’ ğ‘‘ğ‘– ğ‘†, in questo frangente si dice che il sistema lineare
ammetta âˆâˆ’ 1 soluzioni (perchÃ© faccio ğ‘› âˆ’ 1 scelte arbitrarie, lâ€™altra dipende da queste).
7

â€¢ ğ‘š, ğ‘› > 1: ğ‘ğ‘£ğ‘ŸÃ² ğ‘¢ğ‘› ğ‘ ğ‘–ğ‘ ğ‘¡ğ‘’ğ‘šğ‘ ğ‘†: {
ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘›ğ‘¥ğ‘› = ğ‘1
â‹®
ğ‘ğ‘š1ğ‘¥1 +â‹¯+ ğ‘ğ‘šğ‘›ğ‘¥ğ‘› = ğ‘ğ‘›
Elimino da ğ‘†â€² le equazioni identiche 0 = 0, quindi ottengo ğ‘ equazioni non identiche dove ğ‘ coincide con
il numero di pivot della matrice completa di ğ‘†â€². CosÃ¬ facendo otteniamo un sistema ğ‘†â€²â€² che supponiamo
ancora avere ğ‘š equazioni ed ğ‘› incognite, cosÃ¬ facendo potrÃ² avere i seguenti casi (chiamiamo ğ‘†â€²â€²
semplicemente ğ‘† poichÃ© hanno le stesse soluzioni):
o ğ‘† contiene equazioni del tipo 0 = ğ‘ğ¼(â‰  0) allora il nostro sistema Ã¨ incompatibile (non ammette
soluzioni); in questo caso la matrice incompleta ha lâ€™ultima riga tutta nulla
o La matrice incompleta non ha lâ€™ultima riga nulla dove, sia # = ğ‘›ğ‘¢ğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘–, allora avrÃ² #ğ‘ğ‘–ğ‘£ğ‘œğ‘¡ =
#ğ‘’ğ‘ğ‘¢ğ‘ğ‘§ğ‘–ğ‘œğ‘›ğ‘– â‰¤ #ğ‘–ğ‘›ğ‘ğ‘œğ‘”ğ‘›ğ‘–ğ‘¡ğ‘’(= #ğ‘ğ‘œğ‘™ğ‘œğ‘›ğ‘›ğ‘’), questo quindi Ã¨ il caso ğ‘š â‰¤ ğ‘› che si puÃ²
ulteriormente suddividere in:
â–ª ğ‘š = ğ‘›: qui la matrice ha un numero di righe uquale a quello della colonne, quindi lâ€™unica
possibilitÃ  di trovare delle soluzioni sia quello in cui non abbia zeri sulla diagonale
principale, altrimenti per assurdo mi troverÃ² con una riga di elementi tutti nulli. AvrÃ²
come soluzione: ğ‘¥ğ‘› =
ğ‘ğ‘›
ğ‘ğ‘›ğ‘›
= ğ‘ğ‘›ğ‘ğ‘›ğ‘›
âˆ’1 che sostituisco nellâ€™equazione precedente, cosÃ¬
potrÃ² esplicitare il valore di ğ‘ğ‘›âˆ’1 ed avrÃ² lâ€™equazione ğ‘ğ‘›âˆ’1 ,ğ‘›âˆ’1 ğ‘¥ğ‘›âˆ’1 + ğ‘ğ‘›âˆ’1ğ‘¥ğ‘› = ğ‘ğ‘›âˆ’1,
iterando questo procedimento avrÃ² tutte le soluzioni e quindi ğ‘† Ã¨ determinato.
â–ª ğ‘š < ğ‘›: significa che ci sono piÃ¹ incognite che equazioni, in questo caso si prende la prima
riga e di questa andiamo a prendere il primo elemento da sinistra diverso da zero, che si
trova nella posizione i-esima, dunque avrÃ²: ğ‘1ğ‘–ğ‘¥ğ‘– +â‹¯ğ‘1ğ‘›ğ‘¥ğ‘› = ğ‘1, questo procedimento
lo iteriamo per tutte le righe restanti prendendo oltre al primo elemento non nullo anche
il suo indice di colonna. Questi indici di colonna sono associati anche alle incognite
corrispondenti. Le incognite che non sono state prese andranno a destra dellâ€™equazione,
con i termini noti (ad esempio: ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘ğ‘¥ğ‘ = ğ‘1 âˆ’ ğ‘1(ğ‘+1)ğ‘¥ğ‘+1 +â‹¯âˆ’ ğ‘1ğ‘›ğ‘¥ğ‘›).
In questo modo, per ogni scelta di (ğ‘¥ğ‘+1,â€¦ , ğ‘¥ğ‘›) avrÃ² una sola soluzione e quindi mi
troverÃ² in un sistema dove il numero di equazioni Ã¨ pari al numero di incognite e di
conseguenza posso procedere con il metodo precedente dove ğ‘š = ğ‘›. Quindi avrÃ² un
insieme di soluzioni dove alcune incognite sono funzioni delle altre (ğ‘† Ã¨ indeterminato).
ESEMPI:
â€¢ ğ‘†: {
ğ‘¥1 âˆ’ ğ‘¥2 + 3ğ‘¥3 = 1
ğ‘¥1 + ğ‘¥2 = 4
2ğ‘¥1 + 2ğ‘¥2 + 2ğ‘¥3 = 9
ğ‘†â€²: {
â€¢ ğ‘†: {
ğ‘¥1 âˆ’ ğ‘¥2 + 3ğ‘¥3 = 1
2ğ‘¥2 âˆ’ 3ğ‘¥3 = 3
2ğ‘¥3 = 1
2ğ‘¥1 + ğ‘¥2 = 1
ğ‘¥1 + ğ‘¥2 + ğ‘¥3 âˆ’ ğ‘¥4 = 2
ğ‘¥1 âˆ’ ğ‘¥3 + ğ‘¥4 = 1
{
ğ‘¥1 + ğ‘¥2 + ğ‘¥3 âˆ’ ğ‘¥4 = 2
ğ‘¥2 + 2ğ‘¥3 âˆ’ 2ğ‘¥4 = 3
0 = 2
{
â‡’ ğ´ = (
1 âˆ’1 3
1 1 0
2 2 2
ğ‘¥1 = 7 4â„
ğ‘¥2 = 9 4â„
ğ‘¥3 = 1 2â„
â‡’ ğ‘† = {(
7
4 ,
â†’ (
2 1 0
1 1 1
1 0 âˆ’1
1
4
9
) â†’     (
ğ¸4
âˆ’2.2.3
1 âˆ’1 3
1 1 0
0 0 2
1
4
1
)â†’    (
ğ¸4
âˆ’1.1.2
1 âˆ’1 3
0 2 âˆ’3
0 0
2
9
4 ,
1
2)} ; ğ‘† Ã¨ ğ‘¢ğ‘› ğ‘ ğ‘–ğ‘ ğ‘¡ğ‘’ğ‘šğ‘ ğ‘‘ğ‘’ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–ğ‘›ğ‘ğ‘¡ğ‘œ
0 1
âˆ’1 2
1 1
) â†’ (
1 1 1
0 1 2
0 0 0
â‡’ ğ‘† Ã¨ ğ‘¢ğ‘› ğ‘ ğ‘–ğ‘ ğ‘¡ğ‘’ğ‘šğ‘ ğ‘–ğ‘›ğ‘ğ‘œğ‘šğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘–ğ‘™ğ‘’ (0 = 2)
â€¢ ğ‘†: {
2ğ‘¥1 âˆ’ ğ‘¥2 + ğ‘¥3 âˆ’ ğ‘¥4 = 1
ğ‘¥3 + ğ‘¥4 = 1
ğ‘¥3 = âˆ’2
{
2ğ’™ğŸ âˆ’ ğ‘¥2 + ğ‘¥3 âˆ’ ğ‘¥4 = 1
ğ’™ğŸ‘ + ğ‘¥4 = 1
ğ’™ğŸ’ = âˆ’2
â†’ (
2 âˆ’1 1
0 0 1
0 0 1
âˆ’1 1
1
0 âˆ’2
1 ) â†’ (
2 âˆ’1 1
0 0 1
0 0 0
{
2ğ’™ğŸ + ğ‘¥3 âˆ’ ğ‘¥4 = 1 + ğ‘¥2
ğ’™ğŸ‘ + ğ‘¥4 = 1
ğ’™ğŸ’ = âˆ’2
â†’ ğ‘† = {(
âˆ’1 1
1 1
1 3
) â†’
cs
uN
ğ‘¦
2 âˆ’ 2, ğ‘¦, âˆ’2,3) |ğ‘¦ âˆˆ â„}
ğ‘† Ã¨ ğ‘¢ğ‘› ğ‘ ğ‘–ğ‘ ğ‘¡ğ‘’ğ‘šğ‘ ğ‘–ğ‘›ğ‘‘ğ‘’ğ‘¡ğ‘’ğ‘Ÿğ‘šğ‘–ğ‘›ğ‘ğ‘¡ğ‘œ ğ‘ğ‘œğ‘› âˆğ’Š ğ’”ğ’ğ’ğ’–ğ’›ğ’Šğ’ğ’ğ’Š ğ’„ğ’ğ’ ğ’Š ğ’ğ’–ğ’ğ’†ğ’“ğ’ ğ’…ğ’Š ğ’Šğ’ğ’„ğ’ğ’ˆğ’ğ’Šğ’•ğ’†, ğ‘ğ‘¢ğ‘–ğ‘›ğ‘‘ğ‘– âˆ1 ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘–
8
âˆ’1 2
âˆ’2 3
0 2
) â†’
1
3
1
) â‡’
ğ‘’ğ‘ğ‘¢ğ‘–ğ‘£ğ‘ğ‘™ğ‘’ğ‘›ğ‘¡ğ‘’
â‡”         ğ‘†â€²ğ‘ ğ‘”ğ‘Ÿğ‘ğ‘‘ğ‘–ğ‘›ğ‘–

Sistema omogeneo
Per sistema omogeneo si intende un sistema che ha come termini noti tutti zeri, questa tipologia di sistemi Ã¨
sempre compatibile poichÃ© ammette o la soluzione banale (0, â€¦ ,0), oppure infinite soluzioni (tra cui anche
quella banale), quindi se ho una soluzione diversa da quella banale allora ne avrÃ² infinite.
Notazioni per i sistemi lineari
Posso denotare un sistema lineare con la seguente rappresentazione compatta: ğ´ğ‘‹ = ğµ, infatti
( â‹® â‹± â‹® )(
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘š1 â‹¯ ğ‘ğ‘šğ‘›
\f \ f
/\ J
ğ‘¥1
â‹®
ğ‘¥ğ‘›
) = (
ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘›ğ‘¥ğ‘›
â‹®
\ğ‘ğ‘š1ğ‘¥1 +â‹¯+ ğ‘ğ‘šğ‘›ğ‘¥ğ‘›
) = (
ğ‘1
â‹®
ğ‘ğ‘›
); di conseguenza ğ‘Œ = (
ğ‘¦1
â‹®
ğ‘¦ğ‘›
) Ã¨ soluzione del
sistema se verifica lâ€™uguaglianza ğ´ğ‘Œ = ğµ. Ovviamente un sistema Ã¨ omogeneo se ğ´ğ‘‹ = ğµ = 0.
3. Spazi Vettoriali
Definizione
Sia ğ‘‰ un insieme non vuoto, +: ğ‘‰ Ã— ğ‘‰ â†’ ğ‘‰ un operazione interna (se indico un operazione interna con + Ã¨
perchÃ© ho la commutativitÃ ) e â‹… âˆ¶ â„ Ã— ğ‘‰ â†’ ğ‘‰ un operazione esterna; la terna (ğ‘½,+, â‹…
) Ã¨ detta spazio
vettoriale sul campo â„ se:
1) (ğ‘‰, +) Ã¨ un gruppo abeliano, ovvero gode di
i.
ProprietÃ  associativa ((ğ‘ + ğ‘) + ğ‘ = ğ‘ + (ğ‘ + ğ‘))
ii.
iii.
ProprietÃ  commutativa (ğ‘ + ğ‘ = ğ‘ + ğ‘)
Elemento neutro(âˆƒğœ€ âˆˆ ğ‘‰(âˆ€ğ‘ âˆˆ ğ‘‰, ğœ€ + ğ‘ = ğ‘ = ğ‘ + ğœ€))
iv. Opposto (âˆ€ğ‘ âˆˆ ğ‘‰, âˆƒ! ğ‘(ğ‘ + ğ‘ = ğœ€))
2) âˆ€â„, ğ‘˜ âˆˆ â„, âˆ€ğ‘£ âˆˆ ğ‘‰ risulta (â„ğ‘˜) â‹… ğ‘£ = â„ â‹… (ğ‘˜ğ‘£) (da non confondere con la proprietÃ  associativa,
poichÃ© anche se simile â‹… Ã¨ un operazione esterna).
3) âˆ€ğ‘£ âˆˆ ğ‘‰ risulta 1 â‹… ğ‘£ = ğ‘£
4) DistributivitÃ  di â‹… rispetto a + in â„: âˆ€â„, ğ‘˜ âˆˆ â„, âˆ€ğ‘£ âˆˆ ğ‘‰ risulta (â„ + ğ‘˜)ğ‘£ = â„ğ‘£ + ğ‘˜ğ‘£
5) DistributivitÃ  di â‹… rispetto a + in ğ‘‰: âˆ€â„ âˆˆ â„, âˆ€ğ‘£, ğ‘¤ âˆˆ ğ‘‰ risulta â„(ğ‘£ + ğ‘¤) = â„ğ‘£ + â„ğ‘¤
Nello spazio vettoriale cosÃ¬ definito si hanno le seguenti notazioni:
â€¢ Gli elementi di ğ‘‰ si dicono vettori
â€¢ Gli elementi di â„ si dicono scalari
â€¢ + Ã¨ detta addizione tra vettori
â€¢ â‹… Ã¨ detta moltiplicazione di uno scalare per un vettore
Proposizione: Sia (ğ‘‰, +,â‹…) uno spazio vettoriale sul campo â„ allora:
1) âˆƒ! Elemento neutro rispetto a + (lo indicheremo con il simbolo 0)
Dim.: siano ğ‘£0 e ğ‘¤0 elementi neutri allora avrei ğ‘£0 = ğ‘£0 + ğ‘¤0 = ğ‘¤0
2) âˆ€ğ‘£ âˆˆ ğ‘‰, âˆƒ! opposto per ğ‘£ (che indicheremo con âˆ’ğ‘£)
Dim.: Siano ğ‘£â€² e ğ‘£â€²â€² opposti di ğ‘£ ho: ğ‘£â€² = ğ‘£â€² + 0 = ğ‘£â€² + (ğ‘£ + ğ‘£â€²â€²) = (ğ‘£â€² + ğ‘£) + ğ‘£â€²â€² = 0 + ğ‘£â€²â€² = ğ‘£â€²â€²
Possiamo definire ora le seguenti notazioni:
â€¢ La scrittura ğ‘£ âˆ’ ğ‘¤ Ã¨ unâ€™abbreviazione di ğ‘£ + (âˆ’ğ‘¤)
â€¢ Vettore nullo: 0
â€¢ Lâ€™opposto del vettore nullo âˆ’0 non Ã¨ altro che 0
Esempi di spazi vettoriali
1) Spazio vettoriale numerico di ordine ğ‘›: (â„ğ‘›,+,â‹…)
â€¢ â‹… âˆ¶ â„ Ã— â„ğ‘› â†’ â„ğ‘› (â„, ğ‘£ = (ğ‘£1, â€¦ , ğ‘£ğ‘›)) â†¦ (â„ğ‘£1,â€¦ , â„ğ‘£ğ‘›)
â€¢ +: â„ğ‘› Ã— â„ğ‘› â†’ â„ğ‘› ((ğ‘£ğ‘–), (ğ‘¤ğ‘–)) â†¦ (ğ‘£ğ‘– + ğ‘¤ğ‘–)
9

2) Spazio vettoriale di una matrice di ordine ğ‘š, ğ‘›: (â„ğ‘š,ğ‘›,+,â‹…)
â€¢ â‹… âˆ¶ â„ Ã— â„ğ‘š,ğ‘› â†’ â„ğ‘š,ğ‘›
(â„, (ğ‘ğ‘–ğ‘—)) â†¦ (â„ğ‘ğ‘–ğ‘—)
â€¢ +: â„ğ‘š,ğ‘› Ã— â„ğ‘š,ğ‘› â†’ â„ğ‘š,ğ‘› ((ğ‘ğ‘–ğ‘—), (ğ‘ğ‘–ğ‘—)) â†¦ (ğ‘ğ‘–ğ‘— + ğ‘ğ‘–ğ‘—)
3) Spazio vettoriale dei polinomi ad una indeterminante ğ‘¥ sul campo reale: (â„[ğ’™], +,â‹…) dove:
â€¢ â„[ğ‘¥] = {ğ‘0 + ğ‘1ğ‘¥ + ğ‘2ğ‘¥2 +â‹¯+ ğ‘ğ‘›ğ‘¥ğ‘›|ğ‘ğ‘– âˆˆ â„, ğ‘› âˆˆ â„•}
â€¢ â‹… âˆ¶ â„ Ã— â„[ğ‘¥] â†’ â„[ğ‘¥]
(â„, ğ‘0 + ğ‘1ğ‘¥ +â‹¯+ ğ‘ğ‘›ğ‘¥ğ‘›) â†¦ â„ğ‘0 +â‹¯+ (â„ğ‘ğ‘›)ğ‘¥ğ‘›
â€¢ + âˆ¶ â„[ğ‘¥] Ã— â„[ğ‘¥] â†’ â„[ğ‘¥]
( ğ‘0 +â‹¯+ ğ‘ğ‘›ğ‘¥ğ‘›, ğ‘0 +â‹¯+ ğ‘ğ‘šğ‘¥ğ‘š ) â†¦ (ğ‘0 + ğ‘0) + (ğ‘1 +
ğ‘1)ğ‘¥ +â‹¯+ (ğ‘ğ‘› + ğ‘ğ‘›)ğ‘¥ğ‘› + ğ‘ğ‘›+1ğ‘¥ğ‘›+1 +â‹¯+ ğ‘ğ‘šğ‘¥ğ‘š
assumendo che ğ‘› â‰¤ ğ‘š
Principio di identitÃ  dei polinomi:
ğ‘0 + ğ‘1ğ‘¥ + ğ‘2ğ‘¥2 +â‹¯+ ğ‘ğ‘›ğ‘¥ğ‘› = ğ‘0 + ğ‘1ğ‘¥ +â‹¯+ ğ‘ğ‘šğ‘¥ğ‘š â‡” ğ‘› = ğ‘š ğ‘’ ğ‘0 = ğ‘0,â€¦ , ğ‘ğ‘› = ğ‘ğ‘›
Osservazione:
â€¢ ğ‘(ğ‘¥), ğ‘(ğ‘¥) polinomi di gradi â‰¤ ğ‘› allora ğ‘(ğ‘¥) + ğ‘(ğ‘¥) ha grado al piÃ¹ ğ‘›
(Esempio: (3ğ‘¥ + 1) + (4ğ‘¥2 + 1) â‰¤ 2)
â€¢ â„ âˆˆ â„, â„ğ‘(ğ‘¥) ha grado â‰¤ ğ‘› piÃ¹ precisamente ha lo stesso grado di ğ‘(ğ‘¥) eccetto se moltiplicato
per il polinomio nullo. (Esempio: â„(3ğ‘¥ + 1) = (3â„)ğ‘¥ + â„)
Queste descritte sopra sono sottostrutture di â„[ğ‘¥], quindi possiamo definire ora un insieme â„ğ‘›[ğ‘¥] =
{ğ‘(ğ‘¥) âˆˆ â„[ğ‘¥]|ğ‘”ğ‘Ÿğ‘ğ‘‘ğ‘œ(ğ‘(ğ‘¥)) â‰¤ ğ‘›} dove + e â‹… sono operazioni ben definite una volta ristretto dominio e
codominio (in questo caso tutte le proprietÃ  descritte per â„[ğ‘¥] si mantengono anche per le sue
sottostrutture).
Avremo dunque un nuovo spazio vettoriale: (â„ğ’[ğ’™], +,â‹…):
â€¢ â‹… âˆ¶ â„ Ã— â„ğ‘›[ğ‘¥] â†’ â„ğ‘›[ğ‘¥]
â€¢ +: â„ğ‘›[ğ‘¥] Ã—â„ğ‘›[ğ‘¥] â†’ â„ğ‘›[ğ‘¥]
ESERCIZI: verificare per tutti gli esempi sopracitati che valgano le proprietÃ  di definizione di spazio vettoriale
Spazio della geometria euclidea ğ‘† (nel caso si parli di un piano si usa ğ‘†ğœ‹): Sia ğ‘‚ un punto di tale spazio
definiamo i seguenti oggetti:
â€¢ ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ—  segmento orientato di primo estremo ğ‘‚ e secondo ğ´
â€¢ Lâ€™insieme di tutti i segmenti orientati che partono da O e
si dirigono in punti arbitrari dello spazio S Ã¨ ğ‘†0 = {ğ‘‚ğ´|ğ´ âˆˆ ğ‘†}
A
O
â€¢ Sia ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ— , ğ‘‚ğµâƒ—âƒ—âƒ—âƒ—âƒ—  âˆˆ ğ‘†ğ‘‚ definisco ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ—  + ğ‘‚ğµâƒ—âƒ—âƒ—âƒ—âƒ—  = ğ‘‚ğ¶âƒ—âƒ—âƒ—âƒ—âƒ—  con la regola del parallelogrammo:
â€¢ Definisco ğµğ¶âƒ—âƒ—âƒ—âƒ—âƒ—  vettore equipollente di ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ—  se e solo se hanno direzione, modulo e verso equivalenti
4) Spazio vettoriale dei vettori geometrici applicati in un punto: (ğ‘†0,+,â‹…):
â€¢ +: ğ‘†ğ‘‚ Ã— ğ‘†ğ‘‚ â†’ ğ‘†ğ‘‚
(regola del parallelogrammo)
â€¢ â‹… âˆ¶ â„ Ã— ğ‘†ğ‘‚ â†’ ğ‘†ğ‘‚
(â„, ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ— ) â†¦ â„ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ— 
Esempio:
â€¢ Elemento neutro ğ‘‚ğ‘‚âƒ—âƒ—âƒ—âƒ—âƒ—âƒ— 
â€¢ Elemento opposto fornito dal vettore con stessa direzione e modulo ma verso opposto
Spazio vettoriale dei vettori geometrici liberi (ordinari) ğ‘†: diamo le seguenti definizioni:
â€¢ definisco vettore geometrico libero lâ€™insieme [ğ´ğµâƒ—âƒ—âƒ—âƒ—âƒ— ] = {ğ¶ğ·âƒ—âƒ—âƒ—âƒ—âƒ— |ğ¶ğ·âƒ—âƒ—âƒ—âƒ—âƒ—  ğ‘’ğ‘ğ‘¢ğ‘–ğ‘ğ‘œğ‘™ğ‘™ğ‘’ğ‘›ğ‘¡ğ‘’ ğ‘ğ‘‘ ğ´ğµâƒ—âƒ—âƒ—âƒ—âƒ— }
â€¢ prenderÃ  il nome di insieme quoziente ğ’± = {[ğ´ğµâƒ—âƒ—âƒ—âƒ—âƒ— ]|ğ´, ğµ âˆˆ ğ‘†} (al variare di ğ´, ğµ in ğ‘†)
â€¢ [ğ´ğµâƒ—âƒ—âƒ—âƒ—âƒ— ] = ğ´ğµ, quindi lâ€™elemento neutro sarÃ  il vettore nullo ğ‘‚ mentre lâ€™opposto âˆ’ğ´ğµ = [âˆ’ğ´ğµâƒ—âƒ—âƒ—âƒ—âƒ— ]
5) Spazio vettoriale dellâ€™insieme (ğ’±, +,â‹…)
â€¢ +: ğ’± Ã— ğ’± â†’ ğ’±
ğ´ğµ + ğ¶ğ· = ğ‘‚ğ¸
â€¢ â‹… âˆ¶ â„ Ã— ğ’± â†’ ğ’±
â„ â‹… ğ´ğµ = â„ğ´ğµ
10
fr NZ N
â€˜
â€˜

ProprietÃ  degli spazi vettoriali
Sia ğ‘‰ uno spazio vettoriale su â„: allora âˆ€ğ’—, ğ’˜, ğ’› âˆˆ ğ‘½ e âˆ€ğ’‰, ğ’Œ âˆˆ â„ avremo
1) ğ‘£ + ğ‘¤ = ğ‘§ â‡’ ğ‘£ = ğ‘§ âˆ’ ğ‘¤
Si dimostra semplicemente sommando ambo i membri per lâ€™opposto di ğ‘¤
2) ğ‘£ + ğ‘¤ = ğ‘¤ â‡’ ğ‘£ = ğ‘¤ âˆ’ ğ‘¤ = 0
3) 0 â‹… ğ‘£ = 0 = â„0
0ğ‘£ = (0 + 0)ğ‘£ = 0 â‹… ğ‘£ + 0 â‹… ğ‘£ â‡’ 0ğ‘£ = 0 in simil modo â„ â‹… 0 = â„ â‹… (0 + 0) = â„0 + â„0 â‡’ â„0 = 0
4) â„ğ‘£ = 0 â‡” â„ = 0 ğ‘œ ğ‘£ = 0
Dim.â‡ valida per la proprietÃ  3; â‡’: supponiamo â„ â‰  0 quindi â„ğ‘£ = 0 â‡’ â„âˆ’1(â„ğ‘£) = â„âˆ’10 â‡’
(â„âˆ’1â„)ğ‘£ = 0 sempre per la proprietÃ  3, se â„ = 0 la dimostrazione Ã¨ banale.
5) â„(âˆ’ğ‘£) = âˆ’(â„ğ‘£) = (âˆ’â„)ğ‘£
Dimostriamo che â„(âˆ’ğ‘£) Ã¨ lâ€™opposto di â„ğ‘£ quindi bisogna dimostrare che â„ğ‘£ + â„(âˆ’ğ‘£) = 0, dunque
mettendo â„ in evidenzia â„ (ğ‘£ + (âˆ’ğ‘£)) = â„(ğ‘£ âˆ’ ğ‘£) = â„ â‹… 0 = 0; quindi abbiamo dimostrato la prima
uguaglianza, similmente per la seconda dobbiamo dimostrare che (âˆ’â„)ğ‘£ sia lâ€™opposto di â„ğ‘£, per
uno degli assiomi dello spazio vettoriale posso scrivere (âˆ’â„)ğ‘£ + â„ğ‘£ = (âˆ’â„ + â„)ğ‘£ = 0ğ‘£ = 0
6) (âˆ’1)ğ‘£ = âˆ’(1ğ‘£) = âˆ’ğ‘£
Applicando piÃ¹ volte la proprietÃ  5: (âˆ’â„)(âˆ’ğ‘£) = âˆ’[â„(âˆ’ğ‘£)] = âˆ’[âˆ’â„ğ‘£] = â„ğ‘£
Lâ€™opposto dellâ€™opposto Ã¨ il vettore di partenza âˆ’(âˆ’ğ‘£) = ğ‘£
ğ‘£ + (âˆ’ğ‘£) = 0
7) ProprietÃ  associativa generalizzata ğ‘£1, â€¦ , ğ‘£ğ‘›: essendo le somme sempre suddivise in agglomerati di
tre oggetti posso estendere la proprietÃ  associativa (ğ‘£1 + ğ‘£2) + ğ‘£3 = ğ‘£1 + (ğ‘£2 + ğ‘£3) per ğ‘› elementi
poichÃ© il posizionamento delle parentesi non conta: ğ‘£1 + ğ‘£2 +â‹¯+ ğ‘£ğ‘› (quindi posso ometterle)
8) ProprietÃ  commutativa generalizzata: come in precedenza essendo ğ‘£ + ğ‘¤ = ğ‘¤ + ğ‘£ possiamo
generalizzarla per ğ‘› elementi poichÃ© lâ€™ordine degli addendi non conta.
9) ProprietÃ  distributiva generalizzata: (â„1 + â„2 +â‹¯+ â„ğ‘›)ğ‘£ = â„1ğ‘£ + â„2ğ‘£ +â‹¯+ â„ğ‘›ğ‘£
Essendo vera per ğ‘› = 2 (Ã¨ assioma), supponiamola vera per ğ‘›(â‰¥ 2) e dimostriamola vera per ğ‘› + 1:
(â„1 + â„2 +â‹¯+ â„ğ‘› + â„ğ‘›+1)ğ‘£ = (â„1 +â‹¯+ â„ğ‘›)ğ‘£ + â„ğ‘›+1ğ‘£ = â„1ğ‘£ +â‹¯+ â„ğ‘›ğ‘£ + â„ğ‘›+1ğ‘£ stessa cosa
(dimostrare come esercizio) per:
â„(ğ‘£1 + ğ‘£2 +â‹¯+ ğ‘£ğ‘›) = â„ğ‘£1 + â„ğ‘£2 +â‹¯+ â„ğ‘£ğ‘›
Definizioni
Combinazione lineare: Presi â„1, . . , â„ğ‘› âˆˆ â„ , ğ‘£1,â€¦ , ğ‘£ğ‘›, ğ‘£ âˆˆ ğ‘‰ e se Ã¨ possibile scrivere ğ‘£ = â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘›
allora ğ‘£ sarÃ  detto combinazione lineare dei vettori ğ‘£ğ‘– mediante gli scalari â„ğ‘–.
Esempio in â„3: (3,0,1) = 3(1,0,0) + 1(0,0,1), combinazione lineare di (1,0,0) e (0,0,1) mediante 3 e 1
ProporzionalitÃ : Siano ğ‘£, ğ‘¤ âˆˆ ğ‘‰ si dicono proporzionali se âˆƒâ„ â‰  0 âˆˆ â„ tale che ğ‘£ = â„ğ‘¤
La proporzionalitÃ  Ã¨ una relazione dâ€™equivalenza essendo:
1) riflessiva: ğ‘£ = 1 â‹… ğ‘£
2) simmetrica: ğ‘£ = â„ğ‘¤ con â„ â‰  0 â‡’ ğ‘¤ = â„âˆ’1ğ‘£
3) transitiva: sia â„, ğ‘˜ â‰  0 se ğ‘£ = â„ğ‘¤ e ğ‘¤ = ğ‘˜ğ‘¢ allora ğ‘£ = (â„ğ‘˜)ğ‘¢
Sottospazi vettoriali
Sia (ğ‘‰, +,â‹…) spazio vettoriale e sia ğ» âŠ† ğ‘‰ diverso dal vuoto, ğ» Ã¨ detto stabile (o chiuso) rispetto allâ€™addizione
se âˆ€ğ‘£, ğ‘¤ âˆˆ ğ» â‡’ ğ‘£ + ğ‘¤ âˆˆ ğ» (la loro somma Ã¨ ancora in ğ») mentre ğ» Ã¨ detto stabile (o chiuso) rispetto alla
moltiplicazione per uno scalare se âˆ€â„ âˆˆ â„, âˆ€ğ‘£ âˆˆ ğ» â‡’ â„ğ‘£ âˆˆ ğ». Se ğ» Ã¨ stabile rispetto alla moltiplicazione e
allâ€™addizione significa che le operazioni + âˆ¶ ğ» Ã— ğ» â†’ ğ» e â‹… âˆ¶ â„Ã— ğ» â†’ ğ» sono ben definite.
Definizione: Se ğ» Ã¨ chiuso (o stabile)rispetto a somma e prodotto allora Ã¨ detto sottospazio vettoriale
Se ğ» Ã¨ sottospazio di ğ‘‰ allora valgono per ğ» tutte le proprietÃ  dello spazio vettoriale ğ‘‰. Si indica con ğ» â‰¤ ğ‘‰.
Tutti i sottospazi sono anche sottoinsieme, ma il viceversa non Ã¨ vero (ad esempio âˆ… â‰° ğ‘‰).
11

Teorema: Se ho un sottospazio vettoriale con le operazioni ristrette allora esso Ã¨ anche uno spazio vettoriale.
Sia ğ» â‰¤ ğ‘‰ âŸ¹ (ğ», +ğ¼ğ» ,â‹…ğ¼ğ») Ã¨ spazio vettoriale.
Dimostrazione: (ğ»; +ğ¼ğ») Ã¨ sia associativa che commutativa (praticamente tutte le proprietÃ  che non sono
esistenziali sono automaticamente soddisfatte per la stabilitÃ  dellâ€™operazione); ha lo stesso elemento neutro
di ğ‘‰ e contiene anche gli opposti (ğ‘£ âˆˆ ğ» â‰  âˆ… â‡’ (âˆ’1)ğ‘£ = âˆ’ğ‘£ğ¼ğ‘‰ ) che appartengono ad ğ» poichÃ© ho lo stesso
elemento neutro 0. 1 â‹…ğ¼ğ»
ğ‘£ = 1 â‹… ğ‘£ = ğ‘£ e cosÃ¬ via sono automaticamente verificate anche le altre proprietÃ .
Esempi di sottospazi vettoriali
1) Sia ğ‘‰ spazio vettoriale ha sempre i sottospazi banali: {0} e ğ‘‰
2) Spazio vettoriale â„3: sono sottospazi {(0,0,0)} e â„3
3) Spazio vettoriale â„2: sottospazio ğ» = {(ğ‘¥, ğ‘¦)|ğ‘¥ = ğ‘¦}, infatti non Ã¨ vuoto, Ã¨ stabile rispetto alla somma
poichÃ© âˆ€ğ‘£, ğ‘¤ âˆˆ ğ» posto ğ‘£ = (ğ‘¥, ğ‘¦) âˆˆ ğ», ğ‘¤ = (ğ‘§, ğ‘¡) âˆˆ ğ» â‡’ (ğ‘¥, ğ‘¦) + (ğ‘§, ğ‘¡) = (ğ‘¥ + ğ‘§, ğ‘¦ + ğ‘¡) âˆˆ ğ» essendo
infatti ğ‘¥ + ğ‘§ = ğ‘¦ + ğ‘§ = ğ‘¦ + ğ‘¡; inoltre ğ» Ã¨ stabile anche rispetto al prodotto essendo âˆ€â„ âˆˆ â„, âˆ€ğ‘£ âˆˆ ğ» â‡’
ğ‘£ = (ğ‘¥, ğ‘¦) âˆˆ ğ» â‡’ â„(ğ‘¥, ğ‘¦) = (â„ğ‘¥, â„ğ‘¦) âˆˆ ğ» essendo â„ğ‘¥ = â„ğ‘¦ poichÃ© ğ‘¥ = ğ‘¦.
4) ğ» = {3ğ‘¥ + 1,0} â‰° â„[ğ‘¥] infatti: (3ğ‘¥ + 1) + (3ğ‘¥ + 1) = 6ğ‘¥ + 2 âˆ‰ ğ»
5) ğ» = {(ğ‘¥, ğ‘¦, 0,0) âˆˆ â„4|ğ‘¥ = ğ‘¦2} â‰° â„4 poichÃ© (1,1,0,0) âˆˆ ğ» + (1,1,0,0) âˆˆ ğ» = (2,2,0,0) âˆ‰ ğ» per 2 â‰  22
f
Esercizio: determinare se ğ» = {(ğ‘
ğ‘
ğ‘
ğ‘‘
) âˆˆ â„2| (ğ‘
ğ‘
ğ‘
ğ‘‘
) (1 1\
0 1J) = (1 1\7s
\0 17X
) (ğ‘
ğ‘
Soluzione: sviluppiamo il prodotto righe per colonne in ambo i due membri: (ğ‘
â€˜
\
ğ‘
da cui possiamo ricavare le seguenti informazioni: { ğ‘ + ğ‘‘ = ğ‘‘ â‡’ ğ‘ = 0
&
ğ‘ + ğ‘ = ğ‘ + ğ‘‘ â‡’ ğ‘ = ğ‘‘
come ğ» = {(ğ‘
Cs
ğ‘
uN
0 ğ‘
ğ‘
Ny
ğ‘‘yd
)} Ã¨ sottospazio vettoriale.
ğ‘ + ğ‘
ğ‘ + ğ‘‘
) = (ğ‘ + ğ‘
ğ‘
ğ‘ + ğ‘‘
ğ‘‘
)
e quindi riscrivere lâ€™insieme ğ»
) |ğ‘. ğ‘ âˆˆ â„}; ora resta da verificare che non sia vuoto (quindi si controlla che esista
NOI
a |
Y
J
lâ€™elemento neutro rispetto la somma), ed in questo caso Ã¨ la matrice (0 0\
â€˜
\0 0J) âˆˆ ğ», e che ğ» sia stabile rispetto
/
alla somma ed al prodotto, risulta infatti: (
\
ğ‘1 ğ‘1
0 ğ‘1
â„ (ğ‘
f
ğ‘
XN
0 ğ‘
) = (â„ğ‘ â„ğ‘
N
7
f
XN
0 â„ğ‘
\
/
) + (
/
\
ğ‘2 ğ‘2
0 ğ‘2
\
/
) = (
J
\
ğ‘1 + ğ‘2 ğ‘1 + ğ‘2
0
ğ‘1 + ğ‘2
) âˆˆ ğ», ed anche
) âˆˆ ğ». Di conseguenza abbiamo dimostrato che ğ» Ã¨ sottospazio vettoriale.
\
7
Esempio: Spazio vettoriale dei vettori geometrici applicati in ğ‘‚â†’
Supponendo di trovarci nel sottospazio vettoriale formato
dai vettori di ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ— , possiamo affermare che esso contiene
tutti i vettori situati nella retta passante per i punti ğ‘‚ ed ğ´
(vedi figura a destra).
Lo stesso ragionamento si puÃ² fare per un piano ğœ‹:
supponendo di trovarci nel sottospazio formato dai vettori
âƒ— ğ‘‚ğ¶âƒ—âƒ—âƒ—âƒ—  e ğ‘‚ğ´âƒ—âƒ—âƒ—âƒ—âƒ— 
allora ad esso appartengono tutti quei vettori
contenuti nello stesso piano (figura in basso).
, { â€˜s. oR
Esune
â€˜
/
/
\y
â€œOo.
â€˜\
â€˜
\
$
MGAIY am
HoH,ZI
ly
Esempio 1
â€”_â€”_â€”_
t
a
hyo ely
Hy=4Coy) /yeR
Osservazione:
lâ€™unione di
sottospazi vettoriali non Ã¨ in
genere un sottospazio.
Lâ€™esempio uno ci mostra,
geometricamente parlando, che
lâ€™unione delle due rette non Ã¨
sottospazio vettoriale, lâ€™esempio
due Ã¨ un esempio piÃ¹ concreto.
12

Alcune proprietÃ  e definizioni di sottospazi vettoriali (sottospazio generato)
1) ğ‘Š â‰¤ ğ‘‰ Ã¨ stabile rispetto alla somma di n oggetti:
Siano ğ‘¤1,â€¦ , ğ‘¤ğ‘› âˆˆ ğ‘Š si ha ğ‘¤1 + ğ‘¤2 âˆˆ ğ‘Š â‡’ (ğ‘¤1 + ğ‘¤2) + ğ‘¤3 âˆˆ ğ‘Š iterando questo ragionamento
avremo che ğ‘¤1 +â‹¯+ ğ‘¤ğ‘› âˆˆ ğ‘Š. Da questa proprietÃ  possiamo osservare che presi ğ‘› scalari, â„1,â€¦ , â„ğ‘›,
qualunque combinazione lineare ğ‘Š contiene ogni combinazione lineare dei suoi elementi:
â„1ğ‘¤1,â€¦ , â„ğ‘›ğ‘¤ğ‘› âˆˆ ğ‘Š â‡’ â„1ğ‘¤1 +â‹¯+ â„ğ‘›ğ‘¤ğ‘› âˆˆ ğ‘Š
2) sia â„’ una famiglia di sottospazi di ğ‘‰, lâ€™intersezione dei sottospazi della famiglia â€œelle tondoâ€: â‹‚ ğ¿
ğ¿âˆˆâ„’ Ã¨ un
sottospazio, piÃ¹ precisamente lâ€™intersezione di una qualunque famiglia di sottospazi Ã¨ un sottospazio ( a
differenza dellâ€™unione). Esempio: {(0, ğ‘¦)|ğ‘¦ âˆˆ â„} âˆ© {(ğ‘¥, 0)|ğ‘¥ âˆˆ â„} = {(0,0)} â‰¤ â„2
Dimostrazione: lâ€™elemento neutro (lâ€™insieme nullo) Ã¨ sempre contenuto in ogni intersezione, la somma Ã¨
stabile; infatti, siano ğ‘£, ğ‘¤ âˆˆ â‹‚ ğ¿
ğ¿âˆˆâ„’ â‡’ ğ‘£, ğ‘¤ âˆˆ ğ¿ âˆ€ğ¿ âˆˆ â„’ â‡’ ğ‘£ + ğ‘¤ âˆˆ ğ¿ âˆ€ğ¿ âˆˆ â„’ â‡’ ğ‘£ + ğ‘¤ âˆˆ â‹‚ ğ¿
ğ¿âˆˆâ„’ , sia
invece, per il prodotto, ğ‘£ âˆˆ â‹‚ ğ¿
ğ¿âˆˆâ„’ , â„ âˆˆ â„ â‡’ ğ‘£ âˆˆ ğ¿ âˆ€ğ¿ âˆˆ â„’ â‡’ â„ğ‘£ âˆˆ ğ¿ âˆ€ğ¿ âˆˆ â„’ â‡’ â„ğ‘£ âˆˆ â‹‚ ğ¿
ğ¿âˆˆâ„’
Problema: Siano ğ», ğ¾ â‰¤ ğ‘‰. Qual Ã¨ il piÃ¹ piccolo sottospazio che contiene sia ğ» che ğ¾? (i.c., ğ» âˆª ğ¾). Cerco
quindi un sottoinsieme contenete sia ğ» che ğ¾, ovvero ğ‘‰ âŠ‡ ğ» âˆª ğ¾, prendo poi lâ€™intersezione di tutti i
sottospazi ğ¿ di ğ‘‰ che contengono ğ» âˆª ğ¾, Ã¨ questo insieme, chiamato sottospazio generato da ğ» e ğ¾, oltre
ad essere la risposta del problema Ã¨ anche il piÃ¹ piccolo sottospazio che contiene sia ğ» che ğ¾.
In simboli: âŒ©ğ», ğ¾âŒª = âŒ©ğ» âˆª ğ¾âŒª = ğ» + ğ¾ = {â„ + ğ‘˜|â„ âˆˆ ğ», ğ‘˜ âˆˆ ğ¾}; ed Ã¨ il piÃ¹ piccolo sottoinsieme, infatti:
1) 0 = 0 âˆˆ ğ» + 0 âˆˆ ğ¾; quini ha elemento neutro.
2) La somma Ã¨ chiusa poichÃ© presi ğ‘¤, ğ‘¤1 âˆˆ ğ» + ğ¾ posso scrivere che âˆƒâ„, â„1 âˆˆ ğ», âˆƒğ‘˜, ğ‘˜1 âˆˆ ğ¾ tale che
ğ‘¤ = â„ + ğ‘˜ e ğ‘¤1 = â„1 + ğ‘˜1 allora ğ‘¤ + ğ‘¤1 = (â„ + ğ‘˜) + (â„1 + ğ‘˜1) = (â„ + â„1)
+ (ğ‘˜ + ğ‘˜1) âˆˆ ğ» + ğ¾
âŸ    
âˆˆ ğ»
3) Il prodotto Ã¨ anchâ€™esso chiuso, e si dimostra allo stesso modo: âˆ€ğ‘¥ âˆˆ â„
â€¢ ğ‘¥â„ âˆˆ ğ» â‡’ ğ‘¥â„
âˆˆ ğ»
+ 0
âˆˆ ğ¾
â€¢ ğ‘˜ âˆˆ ğ» â‡’ 0
âˆˆ ğ»
+ ğ‘¥ğ‘˜
âˆˆ ğ¾
âˆˆ ğ» + ğ¾ â‡’ ğ» âŠ† ğ» + ğ¾
âˆˆ ğ» + ğ¾ â‡’ ğ¾ âŠ† ğ» + ğ¾
4) resta da dimostrare che sia il piÃ¹ piccolo (affinchÃ© sia sottospazio generato)
â€¢ ğ¿ â‰¤ ğ‘‰ âˆ¶ ğ» âˆª ğ¾ âŠ† ğ¿
âˆ€â„ âˆˆ ğ», ğ‘˜ âˆˆ ğ¾ â‡’ â„, ğ‘˜ âˆˆ ğ¿ â‡’ â„ + ğ‘˜ âˆˆ ğ¿ â‡’ ğ» + ğ¾ âŠ† ğ¿ ed Ã¨ quindi contenuto in tutti i
sottospazi che contengono lâ€™unione di ğ» e ğ¾; verificando cosÃ¬ lâ€™uguaglianza âŒ©ğ», ğ¾âŒª = âŒ©ğ» âˆª ğ¾âŒª
Esempio
Hye }ee) [xeAS H,=4ley)/yeRY
Hat, =) Colt Con)/ xR, yerRÂ§
nets 2 Gye li
(m=(0)+ (2,9) â‚¬ Nyt Hy
â‚¬ My Ã© H,
Generalizzazione: Siano ğ»1,â€¦ , ğ»ğ‘› sottospiazi, il sottospazio generato degli ğ‘› sottospazi non Ã¨ altro che la
somma dei sottospazi, in simboli: âŒ©ğ»1,â€¦ , ğ»ğ‘›âŒª = ğ»1 +â‹¯+ ğ»ğ‘› = {â„1 + â„2 +â‹¯+ â„ğ‘›|â„ğ‘– âˆˆ ğ»ğ‘–}
Osservazione: ğ» â‰¤ ğ‘‰ â‡’ âŒ©ğ»âŒª = ğ», il piÃ¹ piccolo sottospazio generato da ğ» Ã¨ ğ» stesso, allo stesso modo se
ho ğ‘£1, â€¦ , ğ‘£ğ‘› âˆˆ ğ‘‰ il sottospazio generato âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª = {â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘›|â„ğ‘– âˆˆ â„} non Ã¨ altro che lâ€™insieme
di tutte le possibili combinazioni lineari dei vettori ğ‘£1,â€¦ , ğ‘£ğ‘› con gli scalari che variano in maniera arbitraria.
13
âŸ    
âˆˆ ğ¾

Somma diretta di sottospazi vettoriali
Sia ğ‘‰ spazio vettoriale e ğ»1, ğ»2 â‰¤ ğ‘‰ due sottospazi, ğ»1 + ğ»2 Ã¨ detta somma di ğ»1 e ğ»2 (generalizzabile per
ğ‘› elementi ğ»1 +â‹¯ğ»ğ‘›), la somma di due sottospazi si dice somma diretta se la loro intersezione (non vuota)
Ã¨ la piÃ¹ piccola possibile, ovvero il singleton dellâ€™elemento neutro, quindi Ã¨ somma diretta e si denota con
ğ»1â¨ğ»2 se ğ»1 âˆ© ğ»2 = {0}. Ad esempio sia ğ»1 = {(ğ‘¥, 0)|ğ‘¥ âˆˆ â„} e ğ»2 = {(0, ğ‘¥)|ğ‘¥ âˆˆ â„}, lâ€™insieme â„2 = ğ»1 +
ğ»2 Ã¨ somma diretta, infatti ğ»1 âˆ© ğ»2 = {(0,0)}, quindi si scriverÃ  â„2 = ğ»1â¨ğ»2.
ğ»1 e ğ»2 sono detti supplementari se ğ‘‰ = ğ»1 + ğ»2, mentre saranno complementari se ğ‘‰ = ğ»1â¨ğ»2
Somma diretta di piÃ¹ sottospazi: supponiamo di avere ğ‘› spazi vettoriali, allora ğ»1,â€¦ , ğ»ğ‘› sono in somma
diretta se lâ€™intersezione di un qualunque ğ»ğ‘– con il sottospazio generato da tutti gli altri sia singleton
dellâ€™elemento neutro, dunque se ğ»ğ‘– âˆ© âŸ¨ğ»ğ‘—|ğ‘— â‰  ğ‘–âŸ© = {0}, piÃ¹ precisamente se ğ»1 âˆ© âŒ©ğ»2, ğ»3,â€¦ , ğ»ğ‘›âŒª = {0};
ğ»2 âˆ© âŒ©ğ»1, ğ»3,â€¦ , ğ»ğ‘›âŒª = {0} e cosÃ¬ via per tutti gli ğ»ğ‘–.
Esempio 1: ğ»1 = {(ğ‘¥, 0)|ğ‘¥ âˆˆ â„}, ğ»2 = {(0, ğ‘¥)|ğ‘¥ âˆˆ â„} e ğ»3 = {(ğ‘¥, ğ‘¥)|ğ‘¥ âˆˆ â„} non sono in somma diretta
anche se presi a due a due generano lâ€™elemento neutro, infatti ğ»3 âˆ© âŒ©ğ»1, ğ»2âŒª = ğ»3 âˆ©â„2 = ğ»3 â‰  {(0,0)}
Esempio 2: ğ»1 = {(ğ‘¥, 0,0)|ğ‘¥ âˆˆ â„}, ğ»2 = {(0, ğ‘¥, 0)|ğ‘¥ âˆˆ â„} e ğ»3 = {(0,0, ğ‘¥)|ğ‘¥ âˆˆ â„} avremo che lâ€™insieme
ğ»1 âˆ© âŒ©ğ»2, ğ»3âŒª = {(0,0,0)} dato che âŒ©ğ»2, ğ»3âŒª = ğ»2 + ğ»3 = {(0, ğ‘¥, ğ‘¦)|ğ‘¥, ğ‘¦ âˆˆ â„} in modo analogo si procede
con gli altri insiemi e dunque possiamo scrivere ğ»1â¨ğ»2â¨ğ»3.
Esempio 3: âŒ©ğ‘Ÿ, ğ‘ âŒª = ğ‘Ÿ + ğ‘  Ã¨ tutto il piano, inoltre sapendo che ogni vettore
geometrico si puÃ² scrivere come somma di un elemento che sta in ğ‘  ed uno che sta
in ğ‘Ÿ, (i sottospazi ğ‘  e ğ‘Ÿ sono supplementari; la loro somma fa tutto lo spazio) e che la
loro intersezione Ã¨ intuitivamente il vettore degenere ğ‘‚ğ‘‚âƒ—âƒ—âƒ—âƒ—âƒ—âƒ— , risulterÃ  ğ‘… âˆ© ğ‘† = {ğ‘‚ğ‘‚âƒ—âƒ—âƒ—âƒ—âƒ—âƒ— }.
Di conseguenza Ã¨ anche complementare (lâ€™intersezione Ã¨ insieme banale): ğ‘Ÿâ¨ğ‘ .
Dipendenza ed indipendenza lineare
Sia ğ‘‰ spazio vettoriale e siano ğ‘£1, ğ‘£2,â€¦ , ğ‘£ğ‘› âˆˆ ğ‘‰, essi sono detti linearmente dipendenti (o legati) se e solo se
esistono ğ‘› scalari non tutti nulli tali che la loro combinazione lineare sia il vettore nullo: â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› = 0.
Se tali scalari non esistono allora tali vettori sono detti linearmente indipendenti ( o liberi), questâ€™ultimo caso
implica come unica soluzione 0ğ‘£1 +â‹¯+ 0ğ‘£ğ‘› = 0, quindi che â„1 = â„2 = â‹¯ = â„ğ‘› = 0 âˆ€â„ğ‘– âˆˆ â„
Esempi: (1,0), (0,1) âˆˆ â„2 sono linearmente indipendenti infatti â„1(1,0) + â„2(0,1) = (0,0) â‡’ â„1 = â„2 = 0;
(0,0), (1,0) sono linearmente dipendenti : 3(0,0) + 0(1,0) = (0,0), lâ€™elemento neutro implica la dipendenza
(1,0), (2,0): âˆ’ 2(1,0) + 1(2,0) = (0,0), se ci sono due elementi proporzionali implica la dipendenza.
Osservazione: se un sistema di vettori contiene in sÃ© un sistema di vettori linearmente dipendenti allora
anche il sistema totale piÃ¹ grande sarÃ  linearmente dipendente (metto lo scalare a 0 per i vettori non
contenuti nel sistema dipendente).
Diremo che un vettore ğ‘£ dipende da ğ‘£1, ğ‘£2, â€¦ , ğ‘£ğ‘› per definizione, se ğ‘£ Ã¨ combinazione lineare dei ğ‘£ğ‘– ovvero
se âˆƒğ’‰ğŸ, â€¦ , ğ’‰ğ’ âˆˆ â„ âˆ¶ ğ’— = ğ’‰ğŸğ’—ğŸ + ğ’‰ğ’ğ’—ğ’. Di seguito alcune proprietÃ :
â€¢ 0 dipende sempre da qualunque sistema ğ‘£1,â€¦ , ğ‘£ğ‘›
0 = 0ğ‘£1 +â‹¯+ 0ğ‘£ğ‘›
â€¢ ğ‘£ğ‘– dipende sempre da ğ‘£1,â€¦ , ğ‘£ğ‘›
ğ‘£ğ‘– = 0ğ‘£1 +â‹¯+ 0ğ‘£ğ‘–âˆ’1 + 1ğ‘£ğ‘– + 0ğ‘£ğ‘–+1 +â‹¯+ 0ğ‘£ğ‘›
â€¢ Sia ğ‘£ dipendente da ğ‘£1,â€¦ , ğ‘£ğ‘› e ciascun ğ‘£ğ‘– dipendente da ğ‘¤1,â€¦ , ğ‘¤ğ‘š, allora (una sorta di proprietÃ 
transitiva) ğ‘£ dipende da ğ‘¤1,â€¦ , ğ‘¤ğ‘š
Dimostrazione: per ipotesi âˆƒâ„ğ‘– âˆˆ â„ âˆ¶ ğ‘£ = â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› e, sempre per definizione, âˆƒğ‘˜ğ‘–ğ‘— âˆˆ â„ âˆ¶
ğ‘£ğ‘– = ğ‘˜ğ‘–1ğ‘¤1 +â‹¯+ ğ‘˜ğ‘–ğ‘šğ‘¤ğ‘š dove ğ‘£ğ‘– = ğ‘£1, â€¦ , ğ‘£ğ‘›, di conseguenza posso scrivere il mio vettore ğ‘£ come
segue ğ‘£ = â„1(ğ‘˜11ğ‘¤1 +â‹¯+ ğ‘˜1ğ‘šğ‘¤ğ‘š) +â‹¯+ â„ğ‘›(ğ‘˜ğ‘›1ğ‘¤1 +â‹¯+ ğ‘˜ğ‘›ğ‘šğ‘¤ğ‘š); utilizzando poi la proprietÃ 
distributiva generalizzata (mettendo in evidenza i ğ‘¤ğ‘–) avrÃ² ğ‘£ = ğ‘1ğ‘¤1 +â‹¯+ ğ‘ğ‘šğ‘¤ğ‘š
14

â€¢ Se ğ‘£, ğ‘¤ dipendono da ğ‘£1,â€¦ , ğ‘£ğ‘› allora ğ‘£ + ğ‘¤ dipende da ğ‘£1,â€¦ , ğ‘£ğ‘›
Dimostrazione:
ğ‘£ = â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘›
ğ‘¤ = ğ‘˜1ğ‘£1 +â‹¯+ ğ‘˜ğ‘›ğ‘£ğ‘›
â‡’ ğ‘£ + ğ‘¤ = (â„1 + ğ‘˜1)ğ‘£1 +â‹¯+ (â„ğ‘› + ğ‘˜ğ‘›)ğ‘£ğ‘›
â€¢ ğ‘£ dipende da ğ‘£1,â€¦ , ğ‘£ğ‘› â‡” ğ‘£ âˆˆ âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›âŒª
Per dimostrare la precedente equivalenza bisogna verificare che (come precedentemente osservato)
âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª = {â„1 ğ‘£1 +â‹¯+ â„ğ‘› ğ‘£ğ‘›|â„ğ‘– âˆˆ â„}, a tal scopo dimostriamo che lâ€™insieme delle combinazioni
lineari ğ» = {â„1 ğ‘£1 +â‹¯+ â„ğ‘› ğ‘£ğ‘›|â„ğ‘– âˆˆ â„} sia effettivamente un sottospazio: Ã¨ evidente che contenga
lâ€™elemento neutro poichÃ© esso Ã¨ sempre dipendente da qualunque sistema, anche la stabilitÃ  della
somma Ã¨ evidente per la proprietÃ  precedente, in maniera simile si dimostra la stabilitÃ  rispetto al
prodotto, infatti se ğ‘£ dipende da ğ‘£1, â€¦ , ğ‘£ğ‘› allora anche â„ğ‘£ = (â„â„1)ğ‘£1 +â‹¯+ (â„â„ğ‘›)ğ‘£ğ‘› dipenderÃ  da
ğ‘£1,â€¦ , ğ‘£ğ‘›. Inoltre, ğ» contiene i vettori ğ‘£1,â€¦ , ğ‘£ğ‘›
infatti ğ‘£ğ‘– dipende da ğ‘£1,â€¦ , ğ‘£ğ‘›; dunque abbiamo
dimostrato che ğ» oltre ad essere un sottospazio, contiene ğ‘£1,â€¦ , ğ‘£ğ‘›. Prendiamo ora un sottospazio
ğ‘Š che contiene âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª, se ğ‘Š contiene i vettori ğ‘£1, â€¦ , ğ‘£ğ‘› allora esso deve contenere anche tutte
le sue combinazioni lineari e quindi ğ» âŠ† ğ‘Š; abbiamo cosÃ¬ dimostrato che ğ» Ã¨ il piÃ¹ piccolo
sottospazio che rispetto allâ€™inclusione le contiene, ovvero che ğ» = âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›âŒª.
Osservazioni:
â€¢
ğ‘Š1 = âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª
ğ‘Š2 = âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª
â‡’ ğ‘Š1 + ğ‘Š2 = âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª
Dimostrazione: ğ‘Š1 + ğ‘Š2 = {ğ‘ + ğ‘ | ğ‘ âˆˆ ğ‘Š1 ğ‘’ ğ‘ âˆˆ ğ‘Š2} e sappiamo che ğ‘Š1 + ğ‘Š2 âŠ‡ ğ‘Š1 âˆª ğ‘Š2 =
âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª âˆª âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª; lâ€™unione dei due sottospazi generati sono contenuti dunque in ğ‘Š1 + ğ‘Š2
e quindi lâ€™insieme ğ‘Š1 + ğ‘Š2 contiene tutte le sue combinazioni lineari, ciÃ² vuol dire che contiene tutte
le combinazioni lineari di ğ‘£1,â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘š ovvero il sottospazio generato âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª,
abbiamo cosÃ¬ dimostrato che ğ‘Š1 + ğ‘Š2 âŠ‡ âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª, rimane da verificare lâ€™altra
inclusione (al fine di dimostrare la tesi per doppia inclusione): prendiamo un oggetto ğ‘£ âˆˆ ğ‘Š1 + ğ‘Š2
quindi ğ‘£ = ğ‘ + ğ‘ = (â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘›) + (ğ‘˜1ğ‘¤1 +â‹¯ğ‘˜ğ‘šğ‘¤ğ‘š) âˆˆ âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª, allora se
ogni elemento ğ‘£ = ğ‘ + ğ‘ âˆˆ ğ‘Š1 + ğ‘Š2 allora ğ‘Š1 + ğ‘Š2 âŠ† âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª.
â€¢ Il sottospazio generato da sottospazi generati non Ã¨ altro che il sottospazio generato dai singoli
elementi, ovvero ğ‘Š = âŒ©âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›âŒª, âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒªâŒª = âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª.
La dimostrazione Ã¨ banale ricordando che ğ‘Š1 + ğ‘Š2 = âŒ©ğ‘Š1, ğ‘Š2âŒª.
â€¢ âŒ©ğ‘£, ğ‘£, 0, ğ‘¤âŒª = âŒ©ğ‘£, ğ‘¤âŒª (praticamente posso eliminare gli elementi nulli o ripetuti)
La dimostrazione Ã¨ evidente per la definizione successiva
Sistemi di vettori equivalenti
Sistemi di vettori che dipendono gli uni dagli altri (e viceversa) sono detti equivalenti. PiÃ¹ formalmente posso
dire che il sistema ğ‘£1, â€¦ , ğ‘£ğ‘› Ã¨ equivalente a ğ‘¤1,â€¦ , ğ‘¤ğ‘š se ogni ğ‘£ğ‘– dipendono da ğ‘¤1,â€¦ , ğ‘¤ğ‘š e ogni ğ‘¤ğ‘—
dipendono da ğ‘£1,â€¦ , ğ‘£ğ‘›.
Esempi: â„2âŒ©(0,1), (0,2), (0,0)âŒª; posso ridurlo, essendo uno nullo e lâ€™altro proporzionale, alla coppia (0,1),
quindi âŒ©(0,1), (0,2), (0,0)âŒª = âŒ©(0,1)âŒª = {(0, ğ‘¥)|ğ‘¥ âˆˆ â„}. I seguenti sottospazi sono equivalenti: âŒ©(0,1), (1,0)âŒª
e âŒ©(1,1), (1,0)âŒª, essendo (0,1) âŸ· (0,1) + (1,0) = (1,1), quindi anche (1,1) dipende da (0,1) e (1,0).
Sia ğ‘† âŠ† ğ‘‰ il piÃ¹ piccolo sottospazio a contenere ğ‘†, posso definire il sottospazio generato âŒ©ğ‘†âŒª = â‹ƒ ğ¿
ğ¿âˆˆâ„’
ricordando che â„’ = {ğ¿ â‰¤ ğ‘‰|ğ‘† âŠ† ğ¿}.
Esercizio: Sia âŒ©{ğ‘£ âˆˆ â„|ğ‘£ ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘œ ğ‘ğ‘ğ‘Ÿğ‘–}âŒª = ğ», come si caratterizza questo sottospazio?
Soluzione: Essendo 1 contenuto nel sottospazio generato (posso scrivere ad esempio
1
2 â‹… 2) allora ğ» Ã¨ tutto
â„ potendo scrivere qualunque ğ‘Ÿ come 1ğ‘Ÿ. Quindi il sottospazio generato da oggetti pari (in realtÃ  qualsiasi
oggetto diverso da 0), formano tutto â„.
15

Relazione tra dipendenza e linearmente dipendenza
Sia ğ‘£1,â€¦ , ğ‘£ğ‘› âˆˆ ğ‘‰ (con ğ‘› â‰¥ 2, poichÃ© se ğ‘› = 1 allora per essere linearmente dipendente deve essere
lâ€™elemento nullo) allora:
I.
ğ‘£1,â€¦ , ğ‘£ğ‘› sono linearmente dipendenti âŸº âˆƒğ‘– âˆ¶ ğ‘£ğ‘– dipende dai rimanenti.
Dimostriamo prima lâ€™implicazione â‡’: per ipotesi, essendo i vettori linearmente dipendenti, esiste
â„1,â€¦ , â„ğ‘› âˆˆ â„ non tutti nulli, tale che â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› = 0, supponiamo che â„1 â‰  0 allora posso
scrivere â„1ğ‘£1 = âˆ’â„2ğ‘£2 +â‹¯âˆ’ â„ğ‘›ğ‘£ğ‘›, moltiplicando ambo i membri per il reciproco â„1
âˆ’1 risulterÃ 
ğ‘£1 = (âˆ’â„1
âˆ’1â„2)ğ‘£2 +â‹¯+ (âˆ’â„1
âˆ’1â„ğ‘›)ğ‘£ğ‘›, ovvero che ğ‘£1 Ã¨ combinazione lineare di ğ‘£2, â€¦ , ğ‘£ğ‘›, ovvero
che ğ‘£1 dipende dai rimanenti. Resta ora da provare lâ€™implicazione â‡: Supponiamo che esista almeno
un vettore dipendente dai rimanenti, quindi che âŸº âˆƒğ‘– âˆ¶ ğ‘£ğ‘– dipendente da ğ‘£1, â€¦ , ğ‘£ğ‘–âˆ’1, ğ‘£ğ‘–+1,â€¦ , ğ‘£ğ‘›,
supponiamo che sia ğ‘– = 1, allora: âˆƒâ„2,â€¦ , â„ğ‘› âˆˆ â„ âˆ¶ ğ‘£1 = â„2ğ‘£2 +â‹¯+ â„ğ‘›ğ‘£ğ‘›, portando tutti i membri
a sinistra avremo: 1ğ‘£1 âˆ’ â„2ğ‘£2 +â‹¯âˆ’ â„ğ‘›ğ‘£ğ‘› = 0 ovvero che ğ‘£1,â€¦ , ğ‘£ğ‘› sono linearmente dipendenti.
II.
ğ‘£1,â€¦ , ğ‘£ğ‘› Ã¨ indipendente âŸº nessun ğ‘£ğ‘– dipende dai rimanenti.
Si dimostra sostanzialmente negando la precedente.
Esempi (tipologie di svolgimento degli esercizi):
1) (1,0,0), (1,2,3), (0,0,1) sono linearmente indipendenti; infatti scrivendo una generica combinazione
lineare â„1(1,0,0) + â„2(1,2,3) + â„3(0,0,1) = (0,0,0) avrÃ² (â„1 + â„2, 2â„2, 3â„2 + â„3) = (0,0,0) da cui
troverÃ² il seguente sistema di equazioni: {
â„1 + â„2 = 0
2â„2 = 0
3â„2 + â„3 = 0
2) (4,1,4), (4,1,3) sono indipendenti poichÃ© non sono proporzionali e tutti diversi da zero.
3) (1,0,0), (1,3,0), (3,4,4) sono linearmente indipendenti; infatti (1,0,0) = â„(1,3,0) + ğ‘˜(3,4,4) Ã¨ valida
solo se â„ = ğ‘˜ = 0 e quindi ho un assurdo, di conseguenza (1,0,0) non dipende dagli altri tue, il
ragionamento Ã¨ valido anche per gli altri due elementi, quindi Ã¨ un sistema indipendente.
4) (1, âˆ’
1
2 , 0), (4,3,1), (1,2,
1
2) + linearmente dipendente potendo scrivere il terzo come combinazione
lineare degli altri due; infatti: (4,3,1) = 2 (1, âˆ’
1
2 , 0) + 2(1,2,
1
2)
5) Spazio vettori geometrici applicati in ğ‘‚: due vettori sono dipendenti se e
solamente se sono proporzionali (giacciono sulla stessa retta) quindi tre vettori
âƒ— ğ‘‚ğ‘ƒâƒ—âƒ—âƒ—âƒ— , ğ‘‚ğ‘„
âƒ—âƒ—âƒ—âƒ—âƒ—âƒ— , ğ‘‚ğ‘…âƒ—âƒ—âƒ—âƒ—âƒ—  sono dipendenti se e solo se giacciono su di uno stesso piano:
âƒ— ğ‘‚ğ‘ƒâƒ—âƒ—âƒ—âƒ—  = ğ›¼ğ‘‚ğ‘„âƒ—âƒ—âƒ—âƒ—âƒ—âƒ—  + ğ›½ğ‘‚ğ‘…âƒ—âƒ—âƒ—âƒ—âƒ—  (vedi figura).
Relazione tra un sistema piÃ¹ piccolo ed uno piÃ¹ grande:
â€œyvMy W yew, â€”
â€œArwdi
Vv
Vv
=a
â†¦ â„1 = â„2 = â„3 = 0.
af
Se il vettore piÃ¹ piccolo Ã¨ linearmente dipendente (quindi posso scriverlo come combinazione lineare di
vettori non tutti nulli) allora posso scrivere il sistema piÃ¹ grande: â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› + 0ğ‘¤1 +â‹¯+ 0ğ‘¤ğ‘› = 0;
mentre, se il sistema piÃ¹ grande Ã¨ indipendente allora anche il sistema piÃ¹ piccolo Ã¨ indipendente.
Proposizione: siano ğ‘£1,â€¦ , ğ‘£ğ‘› vettori linearmente indipendenti allora ogni vettore ğ‘£ che dipende da ğ‘£1,â€¦ , ğ‘£ğ‘›
vi dipende in maniera univoca. Ovvero posso ottenere ogni combinazione lineare in un singolo modo.
Dimostrazione: Bisogna verificare che â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› = ğ‘˜1ğ‘£1 +â‹¯+ ğ‘˜ğ‘›ğ‘£ğ‘›, e che â„ğ‘– = ğ‘˜ğ‘–, posso scrivere:
(â„1 âˆ’ ğ‘˜1)ğ‘£1 +â‹¯+ (â„ğ‘› âˆ’ ğ‘˜ğ‘›)ğ‘£ğ‘› = 0, essendo linearmente indipendenti, lâ€™unica combinazione lineare Ã¨
quella di scalari tutti nulli, ne segue â„ğ‘– âˆ’ ğ‘˜ğ‘– = 0 e dunque â„ğ‘– = ğ‘˜ğ‘–.
16
3

Proposizione: Siano ğ», ğ¾ â‰¤ ğ‘‰ non triviali (0 â‰  â„ âˆˆ ğ» e 0 â‰  ğ‘˜ âˆˆ ğ¾), ğ» âˆ© ğ¾ = {0}, allora i vettori â„ e ğ‘˜ sono
indipendenti.
Dimostrazione: supponiamo per assurdo che â„ e ğ‘˜ siano dipendenti, quindi ğ›¼â„ + ğ›½ğ‘˜ = 0 con ğ›¼, ğ›½ âˆˆ â„ non
entrambi nulli, supponiamo ğ›¼ diverso da zero (uno dei due deve esserlo al fine della dipendenza) quindi
posso scrivere â„ = (âˆ’ğ›¼âˆ’1ğ›½ )ğ‘˜ âˆˆ ğ» âˆ© ğ¾, ora, poichÃ© â„ deve essere diverso dal vettore nullo per ipotesi, ed
essendo che ğ» âˆ© ğ¾ contiene solo il vettore nullo (sempre per ipotesi) abbiamo trovato un assurdo.
Proposizione: Siano ğ»1,â€¦ , ğ»ğ‘› sottospazi non banali di ğ‘‰, 0 â‰  ğ‘£1 âˆˆ ğ»1,â€¦ , 0 â‰  ğ‘£ğ‘› âˆˆ ğ»ğ‘›, il sistema costituito
da ğ‘£1,â€¦ , ğ‘£ğ‘› Ã¨ indipendente. (i sottospazi sono in somma diretta)
Dimostriamo per assurdo che i vettori siano linearmente dipendenti:
â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› = 0
(â„1,â€¦ , â„ğ‘›) â‰  (0,â€¦ ,0)
]
â„1â‰ 0
â‡’    ğ‘£1 =
(âˆ’â„1
âˆ’1â„2)ğ‘£2 +â‹¯+ (âˆ’â„1
âˆ’1â„ğ‘›)ğ‘£ğ‘› âˆˆ ğ»1 âˆ© (ğ»2 +â‹¯+ ğ»ğ‘›) = {0} e questo significa che i sottospazi sono in
somma diretta che per definizione Ã¨ il singleton dellâ€™elemento neutro, ciÃ² denota un assurdo che contraddice
il fatto che qeusti oggetti siano linearmente dipendenti.
Prendiamo ad esempio i seguenti insiemi: ğ»1 = {(0, ğ‘¥)|ğ‘¥ âˆˆ â„}, ğ»2 = {(ğ‘¥, 0)|ğ‘¥ âˆˆ â„}, ğ»3 = âŒ©(1,1)âŒª;
sappiamo che ğ»1 e ğ»2sono in somma diretta quindi formano un sistema indipendente, supponiamo (0,1) e
(1,0) allora (0,1) (1,0) (1,1) sono dipendenti per gli scalari 1,1, âˆ’1 rispettivamente.
Proposizione: Siano ğ»1 e ğ»2 sottospazi di ğ‘‰ in somma diretta, sia ğ‘£ âˆˆ ğ»1â¨ğ»2 allora âˆƒ! ğ‘£1 âˆˆ ğ»1, ğ‘£2 âˆˆ ğ»2 âˆ¶
ğ‘£ = ğ‘£1 + ğ‘£2
Dimostrazione: supponiamo di poter scrivere ğ‘£ in due modi: ğ‘£ = ğ‘£1 + ğ‘£2 = ğ‘£1
â€² + ğ‘£2
â€² â‡’ (ğ‘£1 âˆ’ ğ‘£1
â€² ) +
(ğ‘£2 âˆ’ ğ‘£2
â€² ) = 0; essendo il primo oggetto una differenza di due oggetti in ğ»1 quellâ€™oggetto appartiene ad ğ»1,
allo stesso modo ğ‘£2 âˆ’ ğ‘£2
â€² âˆˆ ğ»2. Supponendo i due oggetti entrambi diversi da zero avremo un assurdo poichÃ©
per ipotesi i vettori sono in somma diretta (la loro somma Ã¨ pari al singleton del vettore nullo); di conseguenza
lâ€™unica soluzione Ã¨ che ğ‘£1 = ğ‘£1
â€² e ğ‘£2 = ğ‘£2
â€² , come volevasi dimostrare.
Osservazione: la precedente proposizione ci fa capire che la somma diretta implica lâ€™unicitÃ  di scrittura (posso
scrivere ogni vettore appartenente alla somma diretta in un unico modo). Viceversa: âˆ€ğ‘” âˆˆ ğ»1 + ğ»2 e âˆƒ! ğ‘£1 âˆˆ
ğ»1, ğ‘£2 âˆˆ ğ»2 âˆ¶ ğ‘” = ğ‘£1 + ğ‘£2 â‡’ ğ»1 âˆ© ğ»2 = {0} (quindi la mia somma Ã¨ somma diretta)
Dim.: ğ‘£ âˆˆ ğ»1 âˆ© ğ»2 â‡’ ğ‘£ = ğ‘£âŸ
âˆˆğ»1
+ 0âŸ
âˆˆğ»2
= 0âŸ
âˆˆğ»1
+ ğ‘£âŸ
âˆˆğ»2
; ovvero lâ€™unicitÃ  di scrittura ğ‘£ = 0 e 0 = ğ‘£
Mettendo insieme le precedenti proposizioni posso scrivere la seguente proposizione: siano ğ»1, ğ»2 â‰¤ ğ‘‰, se
ğ»1 âˆ© ğ»2 = {0} â‡” âˆ€ğ‘£ âˆˆ ğ»1 + ğ»2, âˆƒ! â„1 âˆˆ ğ»1, â„2 âˆˆ ğ»2 âˆ¶ ğ‘£ = â„1 + â„2. La quale posso generalizzarla in:
ğ‘¯ğŸ,â€¦ , ğ‘¯ğ’ ğ’”ğ’ğ’ğ’ ğ’Šğ’ ğ’”ğ’ğ’ğ’ğ’‚ ğ’…ğ’Šğ’“ğ’†ğ’•ğ’•ğ’‚ âŸº âˆ€ğ’— âˆˆ ğ‘¯ğŸ +â‹¯+ ğ‘¯ğ’, âˆƒ! ğ’‰ğ’Š âˆˆ ğ‘¯ğ’Š âˆ¶ ğ’— = ğ’‰ğŸ +â‹¯+ ğ’‰ğ’
Dimostrazione: lâ€™implicazione â‡’ Ã¨ giÃ  stata dimostrata, rimane da dimostrare quindi lâ€™implicazione â‡.
Prendiamo un elemento ğ‘£ âˆˆ ğ»1 âˆ© (ğ»2 +â‹¯+ ğ»ğ‘›) e dimostriamo che sia uguale allâ€™elemento neutro (non
consideriamo gli altri sottospazi generati poichÃ© si procede in modo analogo). Ricordando che âˆƒâ„2 âˆˆ ğ»2,
â€¦ , â„ğ‘› âˆˆ ğ»ğ‘›
âˆ¶ ğ‘£ = â„2 +â‹¯+ â„ğ‘› posso scrivere ğ‘£ = ğ‘£âŸ
âˆˆğ»1
e quindi per lâ€™unicitÃ  di scrittura comporta che ğ‘£ = 0
Proposizione: Supponiamo di avere ğ‘£1, ğ‘£2, â€¦ , ğ‘£ğ‘¡ indipendente e ğ‘£ âˆˆ ğ‘‰ che non dipende dai ğ‘£ğ‘– allora se
aggiungo il vettore ğ‘£ al precedente sistema ottengo un sistema indipendente, quindi ğ‘£1,â€¦ , ğ‘£ğ‘¡, ğ‘£ indipendete
Dimostrazione: prendiamo una combinazione lineare e poniamola uguale al vettore nullo: â„1ğ‘£1 + â„2ğ‘£2 +
â‹¯+ â„ğ‘¡ğ‘£ğ‘¡ + â„ğ‘£ = 0, in questo modo avremo due possibili casi. Caso â„ â‰  0: ğ‘£ = (âˆ’â„âˆ’1â„1)ğ‘£1 +â‹¯+
(âˆ’â„âˆ’1â„ğ‘¡)ğ‘£ğ‘¡ il che Ã¨ assurdo essendo che ğ‘£ non dipende dagli altri vettori. Mentre per il caso â„ = 0: â„1ğ‘£1 +
â„2ğ‘£2 +â‹¯+ â„ğ‘¡ğ‘£ğ‘¡ + â„ğ‘£ = 0 â‡’ â„1 = â„2 = â‹¯ = â„ğ‘¡ = 0 (per definizione).
17
+ 0âŸ
âˆˆğ»2
+â‹¯+ 0âŸ
âˆˆğ»ğ‘›
= 0 + ğ‘£ = 0âŸ
âˆˆğ»1
+ â„2âŸ
âˆˆğ»2
+â‹¯+ â„ğ‘›âŸ
âˆˆğ»ğ‘›

Corollario: Sia ğ‘£1,â€¦ , ğ‘£ğ‘¡ indipendente, ğ‘£ âˆˆ ğ‘‰, se ğ‘£1,â€¦ , ğ‘£ğ‘¡, ğ‘£ Ã¨ dipendente allora ğ‘£ dipende da ğ‘£1,â€¦ , ğ‘£ğ‘¡.
La dimostrazione Ã¨ una sorta di negazione della proposizione precedente ((ğ‘ â‡’ ğ‘) â‡” (Â¬ğ‘ â‡’ Â¬ğ‘)).
Esempio: Partiamo da (1,2,0) che Ã¨ indipendente â‡’
(1,2,0), (3,2,0) ancora indipendente poichÃ© (3,2,0)
non dipende da (1,2,0). Allora, per lo stesso motivo,
si ha che (1,2,0), (3,2,0), (0,0,1) Ã¨ indipendente.
(42,9) , (3)49)
L pmolig. (mm prep)
Anhp,
Vettori finitamente generabili
Uno spazio vettoriale ğ‘‰ Ã¨ detto finitamente generabile se esistono ğ‘£1, â€¦ , ğ‘£ğ‘›
âˆ¶ ğ‘‰ = âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘› âŒª, dove
âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘› âŒª Ã¨ detto sistema di generatori. Quindi uno spazio vettoriale Ã¨ finitamente generabile se ogni
elemento di V puÃ² essere scritto come combinazione lineare di elementi di ğ‘£1, â€¦ , ğ‘£ğ‘›.
Altre definizioni associate:
â€¢ Un sistema di generatori indipendente Ã¨ detto base.
â€¢ Un riferimento Ã¨ una base ordinata
ğ‘’1,â€¦ , ğ‘’ğ‘› ğ‘ğ‘ğ‘ ğ‘’ â‡’ (ğ‘’1, â€¦ , ğ‘’ğ‘›) ğ‘Ÿğ‘–ğ‘“ğ‘’ğ‘Ÿğ‘–ğ‘šğ‘’ğ‘›ğ‘¡ğ‘œ
Esempi:
1) â„2 (1,0) (0,1)
I.
(ğ‘¥, ğ‘¦) = ğ‘¥(1,0) + ğ‘¦(0,1) formano un sistema di generatori indipendenti e dunque (1,0) e (0,1)
sono una base per â„2.
II.
III.
(1,0), (2,0) non Ã¨ un sistema di generatori poichÃ© (ğ‘¥, ğ‘¦) = â„1(1,0) + â„2(2,0) = (â„1 + 2â„2, 0)
dunque (0,1) âˆ‰ âŒ©(1,0), (2,0)âŒª
(
u
(1,0), (1,1) Ã¨ un sistema di generatori perchÃ© (ğ‘¥, ğ‘¦) = â„(1,0) + ğ‘˜(1,1) â‡’ {
â„ + ğ‘˜ = ğ‘¥
ğ‘˜ = ğ‘¦
(1 1
0 1
|
ğ‘¥
ğ‘¦) â‡’ âˆƒ! ğ‘ ğ‘œğ‘™ğ‘¢ğ‘§ğ‘–ğ‘œğ‘›ğ‘’ âˆ€(ğ‘¥, ğ‘¦) âˆˆ â„2 (sono anche indipendenti)
2) I vettori (1,0,0), (0,2,0), (0,0, âˆ’1), (0,0,0) sono un sistema di generatori per â„3? Prendiamo un generico
sistema (ğ‘¥, ğ‘¦, ğ‘§) = â„1(1,0,0) + â„2(0,2,0) + â„3(0,0,âˆ’1) + â„4(0,0,0) dunque avrÃ² un sistema {
(
(
â„1 = ğ‘¥
2â„2 = ğ‘¦
âˆ’â„3 = ğ‘§
con soluzione unica e questo vorrebbe dire che il sistema (avendo unicitÃ ) Ã¨ un sistema indipendente di
generatori. Ãˆ dunque una possibile base di â„3 Ã¨ (1,0,0), (0,2,0), (0,0,âˆ’1)
3) Spazio vettoriale dei vettori geometrici applicati in ğ‘‚ Ã¨ finitamente generabile
poichÃ© supponendo di prendere un vettore ğ‘‚ğ‘…âƒ—âƒ—âƒ—âƒ—âƒ—  in qualunque parte del piano
(vedi figura), essa puÃ² essere ottenuta come combinazione lineare di ğ‘‚ğ‘ƒâƒ—âƒ—âƒ—âƒ—âƒ—  e ğ‘‚ğ‘„âƒ—âƒ—âƒ—âƒ—âƒ—âƒ— .
a
amis os >
Vig
a
vy
P
â€œLOB,
4) Lo spazio di polinomi â„ğ‘›[ğ‘¥] Ã¨ finitamente generabile? Supponiamo di avere gli ğ‘› + 1 polinomi
1, ğ‘¥, ğ‘¥2, â€¦ , ğ‘¥ğ‘›, dunque ogni polinomio di grado al piÃ¹ ğ‘› posso scriverlo come combinazione lineare
ğ‘ğ‘›ğ‘¥ğ‘› + ğ‘ğ‘›âˆ’1ğ‘¥ğ‘›âˆ’1 +â‹¯+ ğ‘0 = ğ‘ğ‘›ğ‘¥ğ‘› +â‹¯+ ğ‘01; di conseguenza Ã¨ finitamente generabile.
5) Lo spazio dei polinomi â„[ğ‘¥] non Ã¨ finitamente generabile poichÃ© se lo fosse esisterebbero
ğ‘1(ğ‘¥),â€¦ , ğ‘ğ‘›(ğ‘¥) âˆ¶ â„[ğ‘¥] = âŒ©ğ‘ğ‘–(ğ‘¥)âŒª ciÃ² vuol dire che ğ‘…[ğ‘¥] = {ğ›¼1ğ‘1(ğ‘¥) +â‹¯+ ğ›¼ğ‘›ğ‘ğ‘›(ğ‘¥)|ğ›¼ğ‘– âˆˆ â„} ma ciÃ²
significherebbe che se prendo il grado massimo dei polinomi, la combinazione lineare associata non
supererebbe mai il suo grado, ciÃ² significa che un grado superiore al suddetto non apparterrebbe a : â„[ğ‘¥]
6) (1,0) Ã¨ indipendente ma non Ã¨ una base poichÃ© non posso generare altro elemento oltre allo zero nel
secondo elemento.
18
dunque
(00,4)
am olf.

Teorema di esistenza delle basi: Sia ğ‘‰ uno spazio vettoriale non nullo, se Ã¨ finitamente generabile allora ğ‘‰
ammette basi.
Dimostrazione: sia ğ‘£1,â€¦ , ğ‘£ğ‘› un sistema di generatori, se ğ‘£1,â€¦ , ğ‘£ğ‘› Ã¨ indipendete allora Ã¨ base. Se invece il
sistema Ã¨ dipendente allora âˆƒğ‘– âˆ¶ ğ‘£ğ‘– dipenda dai rimanenti, supponiamo che sia ğ‘£1, allora esso puÃ² essere
rimosso dal sistema, dunque avrÃ² ğ‘£2, â€¦ , ğ‘£ğ‘›
che sarÃ  ancora un sistema di generatori poichÃ© ğ‘‰ =
âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª â‰¤ âŒ©ğ‘£2,â€¦ , ğ‘£ğ‘›âŒª âˆ‹ ğ‘£2, â€¦ , ğ‘£ğ‘› â‡’ âŒ©ğ‘£2,â€¦ , ğ‘£ğ‘›âŒª = ğ‘‰. Iterando questo procedimento troverÃ² sempre
almeno un sistema indipendente e quindi una base.
Osservazione: Da ogni sistema di generatori si puÃ² estrarre una base
Ad esempio: (1,0), (2,0), (3,4), (5,6), (1,1) Ã¨ un sistema di generatori per â„2, essendo (ğ‘¥, ğ‘¦) = ğ‘¦(1,1) +
(ğ‘¥ âˆ’ ğ‘¦)(1,0) + 0(2,0) + 0(3,4) + 0(5,6); da questo sistema di generatori si puÃ² estrarre una base, (2,0) Ã¨
proporzionale a (1,0) e si puÃ² rimuovere, allo stesso modo (3,4), (5,6) essendo entrambi scrivibili come
â„(1,1) âˆ’ 1(1,0), di conseguenza rimarrÃ² con i vettori (1,0)(1,1), che formano una base.
Dimensione di uno spazio vettoriale
Lemma di Steinitz: Se ho ğ‘š vettori linearmente indipendenti contenuti in un sottospazio generato da ğ‘›
vettori allora il numero di generatori Ã¨ maggiore o uguale del numero di vettori indipendenti.
ğ‘£1, â€¦ , ğ‘£ğ‘š âˆˆ âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘›âŒª â‡’ ğ‘š â‰¤ ğ‘›
Corollario (diretta conseguenza del lemma di Steinitz): Sia ğ‘‰ â‰  {0} spazio vettoriale, tutte le basi hanno lo
stesso ordine detto dimensione di ğ‘‰. (la dimensione Ã¨ un concetto ben definito per il lemma di Steinitz)
Dimostrazione: Siano ğ‘£1, â€¦ , ğ‘£ğ‘› e ğ‘¤1,â€¦ , ğ‘¤ğ‘š due basi, essendo ğ‘£1, â€¦ , ğ‘£ğ‘› una base allora ğ‘£1,â€¦ , ğ‘£ğ‘› Ã¨ un sistema
di vettori linearmente indipendente ed Ã¨ contenuto in ğ‘‰ = âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘šâŒª essendo ğ‘¤1,â€¦ , ğ‘¤ğ‘š base e quindi
anche un sistema di generatori. Per il lemma di Steinitz avrÃ² che ğ‘› â‰¤ ğ‘š, ovviamente posso scrivere anche il
contrario, ovvero ğ‘¤1, â€¦ , ğ‘¤ğ‘š âˆˆ ğ‘‰ = âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª, di conseguenza avrÃ² anche ğ‘š â‰¤ ğ‘›, ovvero ğ‘š = ğ‘›.
dim (ğ‘‰) Ã¨ la cardinalitÃ  di una base, se ğ‘‰ = {0} âŸ¹ dim(ğ‘‰) = 0 (poichÃ© lâ€™insieme vuoto si puÃ² vedere come
un sistema indipendente di vettori costituito dal solo elemento neutro) mentre se ğ‘‰ non Ã¨ finitamente
generabile â‡’ dim(ğ‘‰) = âˆ.
Proposizioni della dimensione (ğ‘½ â‰  {ğŸ} ğ’‡ğ’Šğ’ğ’Šğ’•ğ’‚ğ’ğ’†ğ’ğ’•ğ’† ğ’ˆğ’†ğ’ğ’†ğ’“ğ’‚ğ’ƒğ’Šğ’ğ’†, ğğ¢ğ¦ ğ‘½ = ğ’):
â€¢ ğ‘£1,â€¦ , ğ‘£ğ‘š indipendente â‡’ ğ‘š â‰¤ ğ‘› (il numero di oggetti non puÃ² superare la dimensione di ğ‘‰)
Dim.: Sia ğ‘’1,â€¦ , ğ‘’ğ‘› una base di ğ‘‰ğ‘› allora essendo ğ‘£1,â€¦ , ğ‘£ğ‘š un sistema di vettori linearmente indipendente
ğ‘£1,â€¦ , ğ‘£ğ‘š âˆˆ âŒ©ğ‘’1,â€¦ , ğ‘’ğ‘›âŒª = ğ‘‰ğ‘› â‡’ ğ‘š â‰¤ ğ‘› per il lemma di Steinitz
â€¢ ğ‘£1,â€¦ , ğ‘£ğ‘› indipendente â‡’ ğ‘£1,â€¦ , ğ‘£ğ‘› formano una base (quindi anche un sistema di generatori)
Basta dimostrare che ğ‘£1,â€¦ , ğ‘£ğ‘› sia anche un sistema di generatori, per farlo supponiamo per assurdo che
ğ‘£1,â€¦ , ğ‘£ğ‘› non siano un sistema di generatori quindi âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª < ğ‘‰ ma allora âˆƒğ‘£ âˆˆ ğ‘‰ âˆ– âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘›âŒª e
quindi ğ‘£ non dipende da ğ‘£1,â€¦ , ğ‘£ğ‘› e quindi ğ‘£, ğ‘£1,â€¦ , ğ‘£ğ‘› Ã¨ un sistema indipendente di cardinalitÃ  ğ‘› + 1
che Ã¨ assurdo poichÃ© contraddice la proposizione precedente.
â€¢ ğ‘£1,â€¦ , ğ‘£ğ‘› sistema di generatori â‡’ ğ‘£1,â€¦ , ğ‘£ğ‘› formano una base (quindi Ã¨ anche indipendente)
Si dimostra per assurdo poichÃ© se non fossero indipendenti potremmo estrarre una base di cardinalitÃ 
minore di ğ‘› (in modo analogo alla dimostrazione precedente)
â€¢ ğ‘£1,â€¦ , ğ‘£ğ‘š indipendenti â‡’ âˆƒğ‘¤ğ‘š+1, â€¦ , ğ‘¤ğ‘›: ğ‘£1, â€¦ , ğ‘£ğ‘š, ğ‘¤ğ‘š+1,â€¦ , ğ‘¤ğ‘› formano una base (Ogni sistema di
vettori linearmente indipendenti si puÃ² completare in una base)
Dim.: se ğ‘š = ğ‘› allora Ã¨ base per la seconda preposizione. Se ğ‘š < ğ‘› â‡’ âŒ©ğ‘£1, â€¦ , ğ‘£ğ‘šâŒª < ğ‘‰, ma allora
âˆƒğ‘¤ğ‘š+1 âˆˆ ğ‘‰ âˆ– âŒ©ğ‘£1,â€¦ , ğ‘£ğ‘šâŒª â‡’ ğ‘£1, â€¦ , ğ‘£ğ‘š, ğ‘¤ğ‘š+1 Ã¨ indipendente; se Ã¨ base ho concluso, altrimenti continuo
sino a trovare la base ğ‘£1, â€¦ , ğ‘£ğ‘š, ğ‘¤ğ‘š+1,â€¦ , ğ‘¤ğ‘› (finirÃ² poichÃ© per la prima proposizione ho un numero finito
di vettori linearmente indipendenti, ovvero ğ‘›).
19

Proposizione: Sia ğ‘‰ spazio vettoriale, i seguenti enunciati sono tra loro equivalenti per ğ‘£1,â€¦ , ğ‘£ğ‘›:
1) Base
2) Massimale rispetto allâ€™indipendenza (se preso un sistema piÃ¹ grande allora perde la proprietÃ  di
indipendenza)
3) Minimale rispetto allâ€™essere un sistema di generatori (se preso un sistema piÃ¹ piccolo allora perde la
proprietÃ  di essere un sistema di generatori)
4) Sistema indipendente di cardinalitÃ  massima (tutti gli altri sistemi indipendenti hanno cardinalitÃ 
minore o uguale di n)
5) Sistema di generatori di cardinalitÃ  minima (tutti gli altri sistemi di generatori hanno cardinalitÃ 
maggiore o uguale di n)
Dimostrazione: 1 â‡’ 2: supponiamo ci sia un sistema di vettore contenente ğ‘£1,â€¦ , ğ‘£ğ‘›, che essendo base
implica ğ‘£1,â€¦ , ğ‘£ğ‘›, ğ‘¤1,â€¦ , ğ‘¤ğ‘š
dipendente. 2 â‡’ 1:
ğ‘£1,â€¦ , ğ‘£ğ‘› massimale indipendente, usando il
completamento ad una base perderei il concettÃ² di massimale se esistesse una base con cardinalitÃ  > ğ‘›.
Segue da questâ€™ultima preposizione anche che 4 â‡’ 1, mentre la 1 â‡’ 4 Ã¨ analoga alla 1 â‡’ 2. 1 â‡’ 3: essendo
ğ‘£1,â€¦ , ğ‘£ğ‘› base, se non sarÃ  minimale rispetto alla generazione ci sarÃ  un sottosistema proprio di ğ‘£1,â€¦ , ğ‘£ğ‘›
che Ã¨ ancora un sistema di generatori, da cui possiamo allora estrarre una base e trarne dimensioni diverse.
3 â‡’ 1: ğ‘£1,â€¦ , ğ‘£ğ‘› minimale rispetto alla generazione allora estraiamo una base che deve coincidere con
ğ‘£1,â€¦ , ğ‘£ğ‘›. 1 â‡’ 5: essendo ğ‘£1,â€¦ , ğ‘£ğ‘› base se per assurdo esistesse un sistema di generatori ğ‘¤1,â€¦ , ğ‘¤ğ‘š con
ğ‘š < ğ‘› allora Ã¨ possibile estrarre da ğ‘¤1,â€¦ , ğ‘¤ğ‘š una base che avrÃ  perciÃ² cardinalitÃ  < ğ‘› (assurdo). La 5 â‡’ 1
si dimostra banalmente dalla 3 â‡’ 1. Per doppia implicazione abbiamo dimostrato che: 1 â‡” 2 â‡” 3 â‡” 4 â‡” 5
Proposizione: Sia ğ‘Š â‰¤ ğ‘‰ğ‘› allora:
1) ğ‘Š Ã¨ finitamente generabile e dimğ‘Š â‰¤ ğ‘›
Dim.: Se per assurdo ğ‘Š non fosse finitamente generabile allora se ğ‘¤1 âˆˆ ğ‘Š, ğ‘Š â‰  âŒ©ğ‘¤1âŒª e quindi
esisterebbe un ğ‘¤2 âˆˆ ğ‘Š âˆ– âŒ©ğ‘¤1âŒª â‡’ ğ‘¤1, ğ‘¤2 indipendenti. Segue sempre che ğ‘Š â‰  âŒ©ğ‘¤1, ğ‘¤2âŒª, di
conseguenza possiamo iterare questo processo fino allâ€™assurdo di trovare ğ‘› + 1 vettori indipendenti.
Presa una base di ğ‘Š(â‰  {0}) ğ‘¤1,â€¦ , ğ‘¤ğ‘¡ allora ğ‘¤1, â€¦ , ğ‘¤ğ‘¡ sono indipendenti anche in ğ‘‰, quindi ğ‘¡ â‰¤ ğ‘›
2) dimğ‘Š = ğ‘› â‡” ğ‘Š = ğ‘‰ğ‘›
La â‡ Ã¨ ovvia poichÃ© se ğ‘‰ğ‘› = ğ‘Š allora dimğ‘Š = dimğ‘‰ = ğ‘›. Lâ€™implicazione â‡’ si dimostra prendendo
una base di ğ‘Š, sia ğ‘¤1,â€¦ , ğ‘¤ğ‘› che essendo base Ã¨ anche un sistema indipendente di cardinalitÃ  ğ‘› in
ğ‘‰ e quindi base per ğ‘‰
Corollario: Siano ğ‘Š, ğ‘ â‰¤ ğ‘‰ğ‘› allora se
1) ğ‘Š â‰¤ ğ‘ â‡’ dimğ‘Š â‰¤ dimğ‘
2) ğ‘Š â‰¤ ğ‘ e dimğ‘Š = dimğ‘ â‡’ ğ‘Š = ğ‘
Le dimostrazioni sono analoghe a quelle precedenti. Basti considerare ğ‘ come ğ‘‰
Esempio: <(1,0,0),(0,1,0)> e <(0,1,0),(0,0,1)> sono due sottospazi che hanno la stessa dimensione ma non
sono contenuti uno nellâ€™altro; eccetto per la dimensione R^1 sono infiniti gli esempi di questo tipo. Si prenda
ad esempio â„2 avremo âŒ©(1,0)âŒª âŒ©(1,1)âŒª âŒ©(1,2)âŒª â€¦ âˆ sottospazi della stessa dimensione.
Si prendano ğ»1,â€¦ , ğ»ğ‘› â‰¤ ğ‘‰ sottospazi in somma diretta allora dim(ğ»1â¨â€¦â¨ğ»ğ‘›) = dimğ»1 +â‹¯+ dimğ»ğ‘›.
Dimostrazione: Siano ğ‘’11,â€¦ , ğ‘’1ğ‘š1 base di ğ»1, ğ‘’21,â€¦ , ğ‘’2ğ‘š2 base di ğ»2, â€¦ , ğ‘’ğ‘›1,â€¦ , ğ‘’ğ‘›ğ‘šğ‘› base di ğ»ğ‘› (il primo
pedice identifica lo spazio vettoriale, il secondo il numero dellâ€™elemento). Dimostriamo che lâ€™unione delle
basi ğ‘’11,â€¦ , ğ‘’1ğ‘š1, ğ‘’21,â€¦ , ğ‘’2ğ‘š2,â€¦ , ğ‘’ğ‘›1,â€¦ , ğ‘’ğ‘›ğ‘šğ‘›
sia essa stessa una base: che sia un sistema di generatori Ã¨
scontato perchÃ© comunque si prendano un vettore del sottospazio somma esso si puÃ² ottenere mediante il
sistema ğ‘’11,â€¦ , ğ‘’1ğ‘š1,â€¦ , ğ‘’ğ‘›1,â€¦ , ğ‘’ğ‘›ğ‘šğ‘›. Ora ci resta da dimostrare che formi anche un sistema indipendente
per ğ»1â¨â€¦â¨ğ»ğ‘›, ovvero che â„11ğ‘’11 +â‹¯+ â„1ğ‘š1ğ‘’1ğ‘š1 +â‹¯+ â„ğ‘›1ğ‘’ğ‘›1 +â‹¯+ â„ğ‘›ğ‘šğ‘› ğ‘’ğ‘›ğ‘šğ‘› = 0, isolando i
vettori nel seguente modo â„11ğ‘’11 +â‹¯+ â„1ğ‘š1ğ‘’1ğ‘š1 + (â€¦+ â„ğ‘›1ğ‘’ğ‘›1 +â‹¯+ â„ğ‘›ğ‘šğ‘›ğ‘’ğ‘›ğ‘šğ‘›)
posso scrivere
âŸ                    
âˆˆğ»2+â‹¯+ğ»ğ‘›
20

â„11ğ‘’11 +â‹¯+ â„1ğ‘š1ğ‘’1ğ‘š1 = â‹¯âˆ’ â„ğ‘›1ğ‘’ğ‘›1 +â‹¯âˆ’ â„ğ‘›ğ‘šğ‘›ğ‘’ğ‘›ğ‘šğ‘› ed in questa forma Ã¨ evidente che questâ€™oggetto
scrivibile in due modi (come se stesso e come la combinazione lineare soprascritta) appartiene allâ€™ insieme
ğ»1 âˆ© (ğ»2 +â‹¯+ ğ»ğ‘›) = {0} (per definizione fa il singleton dellâ€™elemento neutro). CiÃ² significa che lâ€™oggetto
a sinistra Ã¨ lâ€™elemento neutro e dunque â„11ğ‘’11 +â‹¯+ â„ğ‘›ğ‘šğ‘›ğ‘’ğ‘›ğ‘šğ‘› = 0 â‡’ â„11 = â‹¯ = â„1ğ‘›1 = 0. Isolando ora
gli altri insiemi seguendo lo stesso ragionamento avrÃ² come da tesi â„11 = â‹¯ = â„1ğ‘›1 = â‹¯ = â„ğ‘›ğ‘šğ‘› = 0.
Relazione di Grassmann
Essa ci dice praticamente la dimensione del sottospazio somma quando i due sottospazi non sono
necessariamente in somma diretta (vale anche per ğ‘› sottospazi).
ğ‘¯, ğ‘² â‰¤ ğ‘½ğ’
ğğ¢ğ¦ ğ‘¯ + ğğ¢ğ¦ ğ‘² = ğğ¢ğ¦(ğ‘¯ âˆ© ğ‘²) + ğğ¢ğ¦(ğ‘¯ + ğ‘²)
Dimostrazione: se ğ» âˆ© ğ¾ = {0} â‡’ ğ»â¨ğ¾ ed Ã¨ dimostrata banalmente per la proposizione precedente.
Supponiamo dunque ğ» âˆ© ğ¾ â‰  {0} â‡’ dimğ» âˆ© ğ¾ = ğ‘¡, prendiamo una base di ğ» âˆ© ğ¾ ed andiamo a
completarla sia come base di ğ» che di ğ¾, avremo dunque che esistono ğ‘’1,â€¦ , ğ‘’ğ‘¡ base di ğ» âˆ© ğ¾,
ğ‘’1,â€¦ , ğ‘’ğ‘¡, â„ğ‘¡+1,â€¦ , â„ğ‘Ÿ base di ğ» e ğ‘’1,â€¦ , ğ‘’ğ‘¡, ğ‘˜ğ‘¡+1,â€¦ , ğ‘˜ğ‘  base di ğ¾ (ovviamente puÃ² anche succedere che i ğ‘¡
vettori siano una base anche di ğ» e/o di ğ¾). Mettendo insieme i precedenti oggetti e considerandolo un
singolo insieme avrÃ² ğ‘’1,â€¦ , ğ‘’ğ‘¡, â„ğ‘¡+1,â€¦ , â„ğ‘Ÿ, ğ‘˜ğ‘¡+1, â€¦ , ğ‘˜ğ‘  sono ğ‘Ÿ + ğ‘  âˆ’ ğ‘¡ elementi (vedi figura) ora dobbiamo
dimostrare che ğ‘Ÿ + ğ‘  âˆ’ ğ‘¡ = dimğ» + dimğ¾ âˆ’ dimğ» âˆ© ğ¾ sia
effettivamente dim(ğ» + ğ¾). Dobbiamo dimostrare dunque che
sia una base, quindi che sia un sistema di generatori e linearmente
indipendente. 1) sistema di generatori: per definizione esiste ğ‘£ âˆˆ
ğ» + ğ¾ â‡’ âˆƒâ„ âˆˆ ğ», ğ‘˜ âˆˆ ğ¾ âˆ¶ ğ‘£ = â„ + ğ‘˜ dove â„ Ã¨ combinazione
lineare di ğ‘’1,â€¦ , ğ‘’ğ‘¡, â„ğ‘¡+1,â€¦ , â„ğ‘Ÿ e ğ‘˜ combinazione lineare di
ğ‘’1,â€¦ , ğ‘’ğ‘¡, ğ‘˜ğ‘¡+1,â€¦ , ğ‘˜ğ‘  e dunque avrÃ² che ğ‘£ Ã¨ combinazione lineare
di ğ‘’1,â€¦ , ğ‘’ğ‘¡, â„ğ‘¡+1,â€¦ , â„ğ‘Ÿ, ğ‘˜ğ‘¡+1,â€¦ , ğ‘˜ğ‘ . 2) sistema linearmente indipendente: prendiamo una combinazione
lineare generica ğ‘1ğ‘’1 +â‹¯+ ğ‘ğ‘¡ğ‘’ğ‘¡ + ğ‘ğ‘¡+1â„ğ‘¡+1 +â‹¯+ ğ‘ğ‘Ÿâ„ğ‘Ÿ + ğ‘ğ‘¡+1ğ‘˜ğ‘¡+1 +â‹¯+ ğ‘ğ‘ ğ‘˜ğ‘  = 0 e scriviamo (come
con la dimostrazione precedente) , ğ‘¥ = ğ‘1ğ‘’1 +â‹¯+ ğ‘ğ‘¡ğ‘’ğ‘¡ + ğ‘ğ‘¡+1â„ğ‘¡+1 +â‹¯+ ğ‘ğ‘Ÿâ„ğ‘Ÿ
= âˆ’ğ‘ğ‘¡+1ğ‘˜ğ‘¡+1 +â‹¯âˆ’ ğ‘ğ‘ ğ‘˜ğ‘ 
âŸ                          
ğ»
dunque ğ‘¥ âˆˆ ğ» âˆ© ğ¾ = âŒ©ğ‘’1,â€¦ , ğ‘’ğ‘¡âŒª e in particolare ğ‘¥
= ğ‘1ğ‘’1 +â‹¯+ ğ‘ğ‘¡ğ‘’ğ‘¡
= âˆ’ğ‘ğ‘¡+1ğ‘˜ğ‘¡+1 +â‹¯âˆ’ ğ‘ğ‘ ğ‘˜ğ‘ 
âŸ              
ğ¾
ottenendo cosÃ¬ che ğ‘1ğ‘’1 +
â‹¯+ ğ‘ğ‘¡ğ‘’ğ‘¡ + ğ‘ğ‘¡+1ğ‘˜ğ‘¡+1 +â‹¯+ ğ‘ğ‘ ğ‘˜ğ‘  = 0 da cui (essendo una base) posso dedurre ğ‘1 = â‹¯ = ğ‘ğ‘¡ = ğ‘ğ‘¡+1 = â‹¯ =
ğ‘ğ‘  = 0 ma allora ğ‘1ğ‘’1 +â‹¯+ ğ‘ğ‘¡ğ‘’ğ‘¡ + ğ‘ğ‘¡+1â„ğ‘¡+1 +â‹¯+ ğ‘ğ‘Ÿâ„ğ‘Ÿ = 0 â‡’ ğ‘1 = â‹¯ = ğ‘ğ‘¡ = ğ‘ğ‘¡+1 = â‹¯ = ğ‘ğ‘Ÿ = 0.
Osservazione: Grassmann si usa usualmente per calcolare la dimensione dellâ€™intersezione poichÃ© nella
maggior parte dei casi la dimensione della somma Ã¨ â€œvisivamenteâ€ calcolabile.
Proposizione: Sia ğ‘‰ğ‘› uno spazio vettoriale di dimensione ğ‘› e â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘›) un riferimento (base ordinata,
quindi ho lâ€™unicitÃ  di scrittura), avrÃ²: âˆ€ğ‘£ âˆˆ ğ‘‰ğ‘› âˆƒ! â„1,â€¦ , â„ğ‘› âˆˆ â„ âˆ¶ ğ‘£ = â„1ğ‘’1 +â‹¯+ â„ğ‘›ğ‘’ğ‘› (considero un
riferimento cosÃ¬ posso definire una n-upla nellâ€™ordine assegnato), e questa n-upla (â„1,â€¦ , â„ğ‘›) si chiamerÃ 
n-upla dei componenti nel riferimento â„›.
21

Per passare da componenti in un riferimento â„› a componenti di un altro riferimento â„›â€² si eseguono
(meccanicamente) i seguenti passi:
DCm) > Neh)2) wf ot Vu
'
24, Obed 6,16)
veVv
Ey7 @2c)4 48Wc! CryXn) ae O
:
'
.
:
'
CaF O C4 than2)
YER Gas Xan =(matt
Wo
Cy ky eta) ia
'
heOia)Si HOpthem ) S,
2
FX,+ TR
ylel
1
le
Le,
1 ;
Sa My rate XaBam pany RPXp Bit
Az(s;,) X> (!
\/%
â€˜) x(\ XS AX
x
Ni molto ol: foray
Forma canonica
Sia â„ğ‘›, si definisce base canonica o riferimento canonico di uno spazio vettoriale lâ€™insieme delle seguenti
basi: ğ‘’1 = (1,0,â€¦ ,0), ğ‘’2 = (0,1,â€¦ ,0), â€¦ , ğ‘’ğ‘› = (0,0,â€¦ ,1); (per la base canonica non Ã¨ rilevante lâ€™ordine) di
conseguenza ogni vettore appartenente allo spazio vettoriale si puÃ² scrivere come combinazione lineare della
base canonica. Altri esempi:
â€¢ Base canonica di â„ğ‘›[ğ‘¥]: 1, ğ‘¥, ğ‘¥2,â€¦ , ğ‘¥ğ‘›
â€¢ Base dello spazio delle matrici â„2,3: (1 0 0
0 0 0
(0 0 0
0 0 1
) , (0 1 0
0 0 0
) , (0 0 1
0 0 0
) (concetto analogo per quanto riguarda matrici â„ğ‘›,ğ‘š
Metodi per estrarre una base da un sottospazio generato
Sia, ad esempio, il seguente sottospazio ğ» = âŒ©(1,0,1,2), (âˆ’1,2,3,0), (3, âˆ’2,âˆ’1,4), (âˆ’2,4,6,0)âŒª â‰¤ â„4, tra i
generatori di questo sottospazio generato Ã¨ evidente la proporzionalitÃ  tra il secondo e il quarto vettore,
dunque ğ» = âŒ©(1,0,1,2), (âˆ’1,2,3,0), (3,âˆ’2, âˆ’1,4)âŒª, mentre il terzo Ã¨ dipendente dai primi due essendo
(3, âˆ’2,âˆ’1,4) = 2(1,0,1,2) âˆ’ 1(âˆ’1,2,3,0), quindi rimarrÃ  ğ» = âŒ©(1,0,1,2), (âˆ’1,2,3,0)âŒª, di conseguenza
essendo dimğ» = 2 qualunque coppia non proporzionale dei quattro vettore definiti allâ€™inizio sono una base
per ğ». PiÃ¹ precisamente: tutti i sistemi indipendenti di ordine 2 sono una base per ğ».
22
) , (0 0 0
1 0 0
) , (0 0 0
0 1 0
),
one forenele gli
hed
tossegye

Un altro metodo Ã¨ quello di posizionare i vettori in una matrice e trasformarla in una matrice equivalente a
gradini: (
1
âˆ’1
3
âˆ’2
0
2
âˆ’2
4
1
3
âˆ’1
6
2
0
4
0
)~(
1
0
0
0
0
2
0
0
1
4
0
0
2
2
0
0
) in tal modo non ho alterato il sottospazio generato dalle righe e ciÃ²
significa che il sottospazio generato dalle righe della matrice a gradini Ã¨ lo stesso di quello generato dalla
matrice iniziale, ed Ã¨ evidente che la dimensione di ğ» sia 2 (le righe nulle sono ininfluenti ed Ã¨ evidente la
non proporzionalitÃ  tra la prima e la seconda riga), piÃ¹ precisamente dimğ» = numero di pivot di un sistema
a gradini equivalente.
Corollario: Due matrici a gradini equivalenti hanno lo stesso numero di pivot.
4. Matrici e Sistemi lineari
Determinante di una matrice quadrata
Il determinante esiste solo e solamente per matrici quadrate; il determinante si definisce per ricorsione
sullâ€™ordine della matrice in questione: per ğ‘› = 1 la matrice ğ´ = (ğ‘) ha determinante det ğ´ = ğ‘; supposto di
averlo definito per matrici di ordine ğ‘› âˆ’ 1 definiamolo per matrici di ordine ğ‘›, al fine di poterlo fare si
definiscono i seguenti concetti:
â€¢ âˆ€ğ‘ğ‘–ğ‘— di ğ´ la matrice complementare di ğ‘ğ‘–ğ‘— Ã¨ ğ´(ğ‘–, ğ‘—) e si definisce nel seguente modo:
(praticamente si cancella la riga ğ‘– e la colonna ğ‘— dalla matrice ğ´)
â€¢ Complemento algebrico di ğ‘ğ‘–ğ‘—: ğ´ğ‘–ğ‘— = (âˆ’1)ğ‘–+ğ‘— det ğ´(ğ‘–, ğ‘—);
Ãˆ possibile usare il determinante nella definizione di complemento algebrico poichÃ© essendo ğ´(ğ‘–, ğ‘—)
una matrice complementare ha ordine minore di ğ´ (abbiamo supposto di aver dato la definizione di
determinante per matrici di ordine ğ‘› âˆ’ 1)
ğ‘11ğ´11 + ğ‘12ğ´12 +â‹¯+ ğ‘1ğ‘›ğ´1ğ‘› = ğ‘21ğ´21 + ğ‘22ğ´22 +â‹¯+ ğ‘2ğ‘›ğ´2ğ‘› = â‹¯ = ğ‘ğ‘›1ğ´ğ‘›1 + ğ‘ğ‘›2ğ´ğ‘›2 +â‹¯+
ğ‘ğ‘›ğ‘›ğ´ğ‘›ğ‘› = ğğğ­ ğ‘¨ = ğ‘1ğ‘›ğ´1ğ‘› +â‹¯+ ğ‘ğ‘›ğ‘›ğ´ğ‘›ğ‘› = â‹¯ = ğ‘12ğ´12 +â‹¯+ ğ‘ğ‘›2ğ´ğ‘›2 = ğ‘11ğ´11 +â‹¯+ ğ‘ğ‘›1ğ´ğ‘›1
Esempio: det (ğ‘
ğ‘
ğ‘
ğ‘‘
) = ğ‘ğ´11 + ğ‘ğ´12 = ğ‘ğ‘‘ âˆ’ ğ‘ğ‘ infatti se ğ´ = (1 2
3 4
) â‡’ det ğ´ = 4 âˆ’ 6 = âˆ’2
Matrici 3x3: regola di Sorrus: Prendiamo il determinante di una generica matrice 3x3 |(
ğ‘11 ğ‘12 ğ‘13
ğ‘21 ğ‘22 ğ‘23
ğ‘31 ğ‘32 ğ‘33
ad essa si duplica prima e seconda colonna e li posizioniamo dopo la seconda colonna:
(
ğ‘11 ğ‘12 ğ‘13
ğ‘21 ğ‘22 ğ‘23
ğ‘31 ğ‘32 ğ‘33
|
ğ‘11 ğ‘12
ğ‘21 ğ‘22
ğ‘31 ğ‘32
) dopodichÃ© il determinante della mia matrice di partenza sarÃ  uguale al
prodotto tra le diagonali (quelle in verde) meno il prodotto tra le antidiagonali (quelle in nero), ovvero:
Art
"
64810,
Q),0,4 QO.
â€”
%
a ata &.0
4u%â€™4
Sp Ub 44
23
\|
/|
)|,
nN
_Â»es_
a ONS

Osservazione: Se una matrice ha una riga o colonna tutta nulla allora il suo determinante Ã¨ zero
ProprietÃ  del determinante:
1) det ğ´ = det ğ´ğ‘¡
2) Se una riga dipende dalle rimanenti allora il determinante Ã¨ zero
(Corollario: se il determinante Ã¨ diverso da zero allora le righe sono indipendenti)
3) Teorema di Cauchy-Binet: ğ´, ğµ âˆˆ â„ğ‘›
det(ğ´ğµ) = det(ğ´) â‹… det(ğµ)
4) Se moltiplico una singola riga (o colonna) per uno scalare â„ allora il determinante della matrice risultante
Ã¨ â„ â‹… det ğ´ (con â„ âˆˆ â„ e ğ´ âˆˆ â„ğ‘›)
5) Se scambiamo due righe o due colonne il determinante cambia segno
6) Se aggiungo ad una riga (o colonna) un multiplo di unâ€™altra riga (o colonna) il determinante non cambia
7) Sia ğ´ una matrice quadrata e sia ğ· una matrice a gradini equivalente ad ğ´ allora |ğ´| â‰  0 â‡” |ğ·| â‰  0
Definizione: ğ´ âˆˆ â„ğ‘› Ã¨ detta invertibile se e solo se âˆƒğµ âˆˆ â„ğ‘›: ğ´ğµ = ğ¼ğ‘› = ğµğ´
Proposizione: Una matrice ğ´ Ã¨ invertibile se e solamente se ha determinante diverso da zero e la sua
inversa Ã¨ ğ´âˆ’1 =
|ğ´| ( â‹® â‹± â‹® ) (matrice trasposta dei complementi algebrici)
1
ğ´11 â‹¯ ğ´ğ‘›1
ğ´1ğ‘› â‹¯ ğ´ğ‘›ğ‘›
Corollario: Siano ğ´, ğµ âˆˆ â„ğ‘› se ğ´ğµ = ğ¼ğ‘› allora sia ğ´ che ğµ sono invertibili e ğµ = ğ´âˆ’1 (inversa di ğ´)
Dimostrazione: Applicando Cauchy-Binet: det(ğ´) det(ğµ) = det(ğ´ğµ) = det(ğ¼ğ‘›) = 1 ne segue det ğ´ â‰  0 e
anche det ğµ â‰  0 e dunque ğ´ e ğµ sono invertibili, ma allora ğ´ğµ = ğ¼ğ‘› â‡’ (ğ´ğµ)ğµâˆ’1 = ğ¼ğ‘›ğµâˆ’1 â‡’ ğ´ = ğµâˆ’1,
ovviamente anche ğµ = ğ´âˆ’1 essendo lâ€™inversa dellâ€™inversa la matrice stessa.
Definizione: Sia ğ´ âˆˆ â„ğ‘›,ğ‘š (si noti la generalitÃ  della matrice, non Ã¨ valido solo per una matrice quadrata)
definisco rango di riga la dimensione del sottospazio generato dalle righe, e rango di colonna la dimensione
del sottospazio generato dalle colonne.
A> (Â°-2) ) (A)eo>", (A)
On, 2, Q,, vee
Qig Gir Say
he Qe
ae
em|@ [
Qs an
Mm, an
am
Minore di una matrice
Sia 0 < â„ â‰¤ min{ğ‘š, ğ‘›}, fissato â„ allora prenderÃ² le â„-righe e le â„-colonne e cancello tutte le altre, la
sottomatrice quadrata rimanente Ã¨ definita come la matrice minore di ordine â„. Ad esempio:
24

Sia ğ´ âˆˆ â„ğ‘›,ğ‘š una matrice rettangolare:
ğ‘ğ‘–1, â€¦ , ğ‘ğ‘–â„ ğ‘Ÿğ‘–ğ‘”â„ğ‘’
ğ‘ğ‘—1, â€¦ , ğ‘ğ‘—â„ ğ‘ğ‘œğ‘™ğ‘œğ‘›ğ‘›ğ‘’
] â‡’ ğ´(ğ‘–1, â€¦ , ğ‘–â„; ğ‘—1,â€¦ , ğ‘—â„), cosÃ¬ facendo (poichÃ©
il determinante Ã¨ possibile solo per matrici quadrate) posso definire il determinante del minore, e lo indico
con |ğ´|(ğ‘–1,â€¦ , ğ‘–â„; ğ‘—1,â€¦ , ğ‘—â„).
Un minore si dice di ordine massimo se il suo ordine coincide con il minimo del numero di righe e colonne di
quella matrice rettangolare (min{ğ‘›, ğ‘š}); una matrice non quadrata ha sempre piÃ¹ di un minore di ordine
massimo, mentre una matrice quadrata ha un solo minore di ordine massimo ed Ã¨ la matrice stessa.
Supponiamo che ğ´(ğ‘–1,â€¦ , ğ‘–â„; ğ‘—1,â€¦ , ğ‘—â„) non sia di ordine massimo, allora esisterÃ  un
indice di riga ğ‘– â‰  ğ‘–1,â€¦ , ğ‘–â„ ed un indice di colonna ğ‘— â‰  ğ‘—1,â€¦ , ğ‘—â„ cosÃ¬ da poter comporre
un minore ğ´(ğ‘–, ğ‘–1, â€¦ , ğ‘–â„; ğ‘—, ğ‘—1,â€¦ , ğ‘—â„); un minore cosÃ¬ composto si definisce orlato del
minore. Ãˆ ovviamente possibile orlare un orlato.
Definizione: Un minore si dice fondamentale se il suo determinante Ã¨ diverso da 0 e se il determinante di
ogni suo orlato Ã¨ uguale a 0.
Non ci sono sempre minori fondamentali, ad esempio la matrice nulla non ha minori fondamentali, ma, se la
matrice non Ã¨ nulla allora esiste sempre almeno un minore fondamentale. Il minore fondamentale non Ã¨
necessariamente unico.
Se un minore di ordine massimo ha determinante diverso da zero allora esso Ã¨ un minore fondamentale
(banalmente: lâ€™implicazione Ã¨ vera se non posso fare un orlato, e dunque sarÃ  un minore fondamentale).
Teorema degli orlati: Sia ğ´ âˆˆ â„ğ‘›ğ‘š una matrice rettangolare e ğ´(ğ‘–1,â€¦ , ğ‘–â„; ğ‘—1,â€¦ , ğ‘—â„) Ã¨ un minore
fondamentale allora le righe ğ‘–1, â€¦ , ğ‘–â„, ğ‘—1,â€¦ , ğ‘—â„ sono un base del sottospazio generato da tutte le righe
(formano un sistema di vettori indipendenti).
Osservazioni: il teorema degli orlati ci dice che trovato un minore fondamentale (ed esiste sempre) non solo
le righe (o colonne) formano un sistema di vettori indipendenti ma essi sono anche una base di tutte le righe
(o colonne) della matrice. Unâ€™altra conseguenza che tutti i minori fondamentali hanno lo stesso ordine.
Corollari derivanti dal teorema degli orlati:
â€¢ ğ‘Ÿ(ğ´) si chiama semplicemente rango della matrice poichÃ© il rango di riga Ã¨ sempre uguale al rango
di colonna, inoltre il rango di ğ´ Ã¨ uguale al numero di pivot di una matrice a gradini equivalente per
righe.
â€¢ Tutti i minori fondamentali hanno lo stesso ordine
â€¢ Il determinante di una matrice quadrata Ã¨ diversa da zero se e solo se le righe (o colonne) sono
indipendenti. ğ´ âˆˆ â„ğ‘›
|ğ´| â‰  0 â‡” righe (o colonne) sono indipendenti
â€¢ ğ´ âˆˆ â„ğ‘›
Non Ã¨ necessario dimostrare che |ğ´| â‰  0 â‡’ righe indipendenti. Per lâ€™implicazione â‡ supponiamo
che le righe siano indipendenti, allora ğ‘Ÿğ‘Ÿ(ğ´) = ğ‘›, e prendiamo un minore fondamentale di ğ´,
questâ€™ultima essendo una matrice quadrata ha un unico minore fondamentale di ordine ğ‘›, questo
minore fondamentale Ã¨ ğ´ stesso e dunque per definizione |ğ´| â‰  0
det ğ´ = 0 â‡” righe (o colonne) dipendenti
25
v
4:
co
aune
omYe

Criteri di compatibilitÃ  di sistemi di equazioni lineari
ğ‘†: {
ğ‘11ğ‘¥1 + ğ‘12ğ‘¥2 +â‹¯+ ğ‘1ğ‘šğ‘¥ğ‘š = ğ‘1
ğ‘21ğ‘¥1 + ğ‘22ğ‘¥2 +â‹¯+ ğ‘2ğ‘šğ‘¥ğ‘š = ğ‘2
â‹®
ğ‘ğ‘›1ğ‘¥1 + ğ‘ğ‘›2ğ‘¥2 +â‹¯+ ğ‘ğ‘›ğ‘šğ‘¥ğ‘š = ğ‘ğ‘›
essere scritta come ğ¶ = (
ğ‘11
â‹®
ğ‘ğ‘›1
) ğ‘¥1 +â‹¯+ (
ğ‘1ğ‘š
â‹®
ğ‘ğ‘›ğ‘š
) ğ‘¥ğ‘š; quindi se câ€™Ã¨ una soluzione la colonna dei termini noti
Ã¨ combinazione dei sistemi lineari delle colonne della matrice incompleta.
Primo criterio di compatibilitÃ  (utile per dimostrare il teorema di RouchÃ©-Capelli): ğ‘† Ã¨ compatibile se e
soltanto se la colonna dei termini noti Ã¨ combinazione lineare delle colonne della matrice incompleta.
Teorema di RouchÃ©-Capelli: ğ‘† Ã¨ compatibile â‡” matrice completa ed incompleta hanno lo stesso rango. (il
sistema ammette soluzione se e solamente se il rango della matrice completa Ã¨ uguale al rango della matrice
incompleta).
Dimostrazione: â‡ âˆ¶ ğ‘Ÿ(ğ´) = ğ‘Ÿ(ğ´â€²) = â„; avendo lo stesso rango dimostriamo che il sistema sia compatibile.
Prendiamo â„ colonne indipendenti di ğ´, che sono indipendenti anche come colonne di ğ´â€™ e quindi queste â„
colonne di ğ´ sono una base anche per la matrice completa. Di conseguenza la colonna dei termini noti ğ¶ si
scrive come combinazione lineare delle colonne di ğ´ ed ho dimostrato lâ€™implicazione per il primo criterio di
compatibilitÃ . Dimostriamo ora la â‡’ âˆ¶ Supponiamo che ğ‘† sia compatibile quindi bisogna mostrare che i ranghi
siano uguali, Prendiamo â„ colonne indipendenti di ğ´ e prendiamo il sottospazio generato da tutte le colonne
della matrice incompleta: ğ‘‰ = âŒ©ğ‘1,â€¦ , ğ‘ğ‘›âŒª = âŒ©ğ‘ğ‘–1, â€¦ , ğ‘ğ‘–â„âŒª, ğ¶ âˆˆ ğ‘‰, il sottospazio generato da tutte le colonne
della matrice completa Ã¨ uguale al sottospazio di tutte le colonne della matrice incompleta poichÃ© lâ€™unica
colonna che potrebbe aggiungere un elemento al sottospazio generato da tutte le colonne sono le incognite
ğ‘¥, che possiamo rimuovere poichÃ© dipendente dalle altre colonne essendo S compatibile. Ma allora â„ =
ğ‘Ÿ(ğ´) = ğ‘Ÿ(ğ´â€™) come volevasi dimostrare.
Esercizio: Sistema a tre equazioni e tre incognite: {
matriciale (
2 1 1
1 âˆ’2 2
3 1 1
| ) e determiniamo un minore fondamentale per la matrice incompleta: 2
4
1
5
ğ‘ ğ‘– ğ‘£ğ‘ ğ‘ğ‘‘
â†’     
ğ‘œğ‘Ÿğ‘™ğ‘ğ‘Ÿğ‘’
(2 1
1 âˆ’2
âŸ      
det(âˆ’4âˆ’1)=âˆ’5
) â†’ (
2 1 1
1 âˆ’2 2
3 1 1
)
âŸ        
âˆ’4+6+1âˆ’(âˆ’6+1+4)=4
Ã¨ essa stessa ed ha rango 3, il rango della matrice completa Ã¨ anche 3 (min{3,4}) di conseguenza per il
teorema di RouchÃ©-Capelli questo sistema Ã¨ compatibile.
N.B.: Il teorema di RouchÃ©-Capelli si comporta molto bene anche per la determinazione dei valori di un
parametro â„ per cui il sistema ğ‘† sia compatibile o meno, prendiamo ad esempio il seguente sistema: ğ‘† =
{
2ğ‘¥ + ğ‘¦ + â„ğ‘§ = 4
ğ‘¥ âˆ’ 2ğ‘¦ + 2ğ‘§ = 1
3ğ‘¥ + ğ‘¦ + ğ‘§ = 5
(
2 1 â„
1 âˆ’2 2
3 1 1
4
1
5
e prendiamo la matrice incompleta ğ´ = (
2 1 â„
1 âˆ’2 2
3 1 1
) e la matrice completa ğ´â€² =
); determiniamone ora i determinanti in funzione del parametro â„: 2 â†’ (2 1
1 âˆ’2
) âŸ¶ ğ´ âˆ¶
|ğ´| = âˆ’4 + 6 + â„ âˆ’ (âˆ’6â„ + 1 + 4) = 7â„ âˆ’ 3, quindi |ğ´| = 0 â‡” â„ =
3
7 (nel caso ci fossero piÃ¹ orlati si deve
prendere il valore comune di â„ per cui tutti gli orlati abbiano determinante nullo) . Per â„ =
3
7 si ha ğ‘Ÿ(ğ´) = 2
di conseguenza il minore fondamentale della matrice incompleta
2ğ‘¥ + ğ‘¦ + ğ‘§ = 4
ğ‘¥ âˆ’ 2ğ‘¦ + 2ğ‘¥ = 1
3ğ‘¥ + ğ‘¦ + ğ‘§ = 5
, scriviamo questo sistema nella forma
ğ´ğ‘‹ = ğ¶, osserviamo che la colonna dei termini noti ğ¶ puÃ²
26
ma No

ma ğ‘Ÿ(ğ´â€²) = 3 poichÃ© |(
2 1 4
1 âˆ’2 1
3 1 5
\l
/|
)| â‰  0 e quindi il sistema Ã¨ incompatibile per â„ =
sistema sarÃ  compatibile essendo ğ‘Ÿ(ğ´) = ğ‘Ÿ(ğ´â€²) = 3.
Risoluzione di sistemi lineari in situazioni particolari
Metodo migliore ed alternativo rispetto a quello visto per quanto riguarda la riduzione a gradini di un sistema.
Prendiamo un sistema di ğ‘› equazioni ed ğ‘š incognite ğ‘† âˆ¶
{
ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘šğ‘¥ğ‘š = ğ‘1
â‹®
ğ‘ğ‘›1ğ‘¥1 +â‹¯+ ğ‘ğ‘›ğ‘šğ‘¥ğ‘š = ğ‘ğ‘›
questo sistema sia compatibile (che si puÃ² capire con RouchÃ©-Capelli) e calcoliamone le soluzioni. Prima di
tutto calcoliamo un minore fondamentale della matrice incompleta ğ´ che sarÃ  anche un minore
fondamentale della matrice completa ğ´â€² (essendo il sistema compatibile) ed eliminiamone le righe al di fuori
del minore fondamentale (che possiamo trascurare perchÃ© tutte le righe al difuori del minore fondamentale
sono dipendenti dalle altre). Quelle che restano sono equazioni indipendenti e di conseguenza avremo il
numero di equazioni minore o uguale al numero di incognite. Vediamo i vari casi vari casi:
1) ğ’ equazioni ed ğ’ incognite: sappiamo giÃ  che esiste unâ€™unica soluzione per la riduzione a gradini, perÃ²
calcoliamola in maniera piÃ¹ veloce; se ci sono ğ‘› equazioni ed ğ‘› incognite sappiamo che la matrice
incompleta Ã¨ una matrice quadrata, e poichÃ© le righe della matrice quadrata sono indipendenti poichÃ©
fanno sempre parte del minore fondamentale di partenze, la matrice ğ´ ha determinante diverso da zero,
per cui ğ´ğ‘‹ = ğ¶ â‡” ğ‘‹ = ğ´âˆ’1ğ¶ (possiamo prendere lâ€™inverso di ğ´ perchÃ© sappiamo che Ã¨ diverso da 0),
date queste caratteristiche il sistema di incognite ğ‘‹ Ã¨ un sistema ben determinato; vado a sviluppare
ğ´11 â‹¯ ğ´ğ‘›1
lâ€™uguaglianza precedente: (
ğ‘¥1
â‹®
ğ‘¥ğ‘›
ğ‘1ğ´11+â‹¯+ğ‘ğ‘›ğ´ğ‘›1
|ğ´|
) = |ğ´| ( â‹® â‹± â‹® )(
1
ğ´1ğ‘› â‹¯ ğ´ğ‘›ğ‘›
, â€¦ , ğ‘¥ğ‘› =
ğ‘1ğ´1ğ‘›+â‹¯+ğ‘ğ‘›ğ´ğ‘›ğ‘›
|ğ´|
ausiliaria ğµ1 = (
ğ‘1
â‹®
ğ‘ğ‘›
ğ‘12 â‹¯ ğ‘1ğ‘›
\/\
J\ /
ğ‘1
â‹®
ğ‘ğ‘›
), piÃ¹ precisamente avremo che ğ‘¥1 =
, per capire cosa rappresentino questi ğ‘¥ğ‘– prendiamo la matrice
ğ‘ğ‘›2 â‹¯ ğ‘ğ‘›ğ‘›
â‹® â‹± â‹® ) che differisce da ğ´ per la prima colonna (dove al posto della prima
colonna di ğ´ ha i termini noti), sviluppando il determinante rispetto la prima colonna avremo |ğµ1| =
ğ‘1ğ´11 + ğ‘2ğ´21 +â‹¯+ ğ‘ğ‘›ğ´ğ‘›1 (che per definizione di complemento algebrico sono uguali sia per la
matrice ğµ1 che per ğ´), analogamente si trovano i casi ğ‘¥2,â€¦ , ğ‘¥ğ‘› con le matrici ğµ2, â€¦ , ğµğ‘›, di conseguenza
posso applicare direttamente il procedimento ğ‘¥1 =
|ğµ1|
|ğ´| , â€¦ , ğ‘¥ğ‘› =
sistema, le precedenti formule sono note come Regola di Cramer.
2) ğ’ equazioni < ğ’ incognite: Sia il sistema ğ‘† âˆ¶ {
ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘šğ‘¥ğ‘š = ğ‘1
â‹®
ğ‘ğ‘›1ğ‘¥1 +â‹¯+ ğ‘ğ‘›ğ‘šğ‘¥ğ‘š = ğ‘ğ‘›
riferimento da esempio ğ‘† = {
2ğ‘¥ + ğ‘¦ + ğ‘§ + 2ğ‘¡ = 0
ğ‘¥ + ğ‘¦ + ğ‘§ + ğ‘¡ = 0
e prendiamo (come nel caso precedente) un minore
fondamentale e portiamo a destra le incognite fuori dalle colonne del minore fondamentale, dunque
avremo ([2 1
1 1 1 1 0
] 1 2
| 0
) ovvero {
2ğ‘¥ + ğ‘¦ = âˆ’ğ‘§ âˆ’ 2ğ‘¡
ğ‘¥ + ğ‘¦ = âˆ’ğ‘§ âˆ’ ğ‘¡
. Consideriamo fissate le incognite esterne, quindi
avremo un sistema di due equazioni e due incognite {
2ğ‘¥ + ğ‘¦ = ğ‘1
ğ‘¥ + ğ‘¦ = ğ‘2
in cui le due equazioni in questione
sono indipendenti poichÃ© appartenenti alle righe di un minore fondamentale, di conseguenza ci troviamo
nel caso precedente di ğ‘› equazioni ed ğ‘› incognite; applichiamo Cramer: ğ‘¥ = ğ‘1 âˆ’ ğ‘2 e ğ‘¦ = 2ğ‘2 âˆ’ ğ‘1; ora
sostituendo avremo ğ‘¥ = ğ‘1 âˆ’ ğ‘2 = âˆ’ğ‘§ âˆ’ 2ğ‘¡ + ğ‘§ + ğ‘¡ = âˆ’ğ‘¡ e ğ‘¦ = 2ğ‘2 âˆ’ ğ‘1 = 2(âˆ’ğ‘§ âˆ’ ğ‘¡) + ğ‘§ + 2ğ‘¡ = âˆ’ğ‘§
dunque lâ€™insieme delle soluzioni sarÃ  ğ‘† = {(âˆ’ğ‘¡, âˆ’ğ‘§, ğ‘§, ğ‘¡)|ğ‘§, ğ‘¡ âˆˆ â„} e sostanzialmente ğ‘† Ã¨ indeterminato
e ha âˆ2 soluzioni.
27
, usiamo come sistema di
|ğµğ‘›|
|ğ´|
per trovarmi le soluzioni del
e supponiamo che
3
7, mentre per â„ â‰ 
3
7 il

Sistemi omogenei
Come giÃ  visto in precedenza un sistema omogeno Ã¨ un sistema che ha per incognite tutti zeri, ovvero un
sistema del tipo ğ‘† âˆ¶ ğ´ğ‘‹ = 0. PiÃ¹ precisamente ğ‘† âˆ¶ {
ğ‘11ğ‘¥1 +â‹¯+ ğ‘1ğ‘šğ‘¥ğ‘š = 0
â‹®
ğ‘ğ‘›1ğ‘¥1 +â‹¯+ ğ‘ğ‘›ğ‘šğ‘¥ğ‘š = 0
Proposizione: lâ€™insieme delle soluzioni rappresenta un sottospazio vettoriale di â„ğ‘š, ovvero ğ‘† â‰¤ â„ğ‘š
Dimostrazione: Per determinare che sia un sottospazio vettoriale bisogna dimostrare che ğ‘† â‰  âˆ…, che Ã¨ stabile
rispetto alla somma e che Ã¨ stabile rispetto al prodotto. Ogni sistema omogeneo ammette almeno la
soluzione banale (0, â€¦ ,0) âˆˆ ğ‘† e quindi ğ‘† non Ã¨ vuoto. Per verificare che sia stabile rispetto alla somma
prendiamo due soluzioni ğ‘Œ1, ğ‘Œ2 âˆˆ ğ‘† (sono n-uple) che essendo soluzioni del sistema omogeneo possiamo
scrivere ğ´ğ‘Œ1 = 0 ed ğ´ğ‘Œ2 = 0 â‡’ ğ´(ğ‘Œ1 + ğ‘Œ2) = ğ´ğ‘Œ1 + ğ´ğ‘Œ2 = 0 + 0 = 0 (stabile rispetto alla somma). La
stabilitÃ  rispetto il prodotto si dimostra prendendo un ğœ† âˆˆ â„; allora si ha che ğ´(ğœ†ğ‘Œ1) = ğœ†(ğ´ğ‘Œ1) = ğœ†0 = 0.
Trovare una base per il sottospazio delle soluzioni di un sistema omogeneo: sia ğ‘† = {
2ğ‘¥ + ğ‘¦ + ğ‘§ + 2ğ‘¡ = 0
ğ‘¥ + ğ‘¦ + ğ‘§ + ğ‘¡ = 0
il
nostro sistema omogeneo, allora (come fatto precedentemente) posso scrivere il mio sistema nel seguente
modo: {
2ğ‘¥ + ğ‘¦ = âˆ’ğ‘§ âˆ’ 2ğ‘¡
ğ‘¥ + ğ‘¦ = âˆ’ğ‘§ âˆ’ ğ‘¡ , avrÃ² quindi il sistema di soluzioni generico ğ‘† = {(ğ›¼(ğ‘§, ğ‘¡), ğ›½(ğ‘§, ğ‘¡), ğ‘§, ğ‘¡)|ğ‘§, ğ‘¡ âˆˆ â„},
allora potendo scegliere ğ‘§ e ğ‘¡ in maniera arbitraria scegliamo i valori che rendano i vettori indipendenti,
dunque
ğ‘§ = 1, ğ‘¡ = 0 â†’ (ğ›¼(1,0), ğ›½(1,0), 1,0)
ğ‘§ = 0, ğ‘¡ = 1 â†’ (ğ›¼(0,1), ğ›½(0,1), 0,1)
(usualmente si pone a 1 una variabile e 0 sulle altre prendendo
tutte le possibilitÃ , in questo caso ho solo due scelte). In questo modo i precedenti vettori sono anche un
sistema di generatori, prendiamo infatti una generica soluzione (ğ‘¥, ğ‘¦, ğ‘§, ğ‘¡âŸ) âˆˆ ğ‘†, avrÃ² (ğ›¼(ğ‘§, ğ‘¡), ğ›½(ğ‘§, ğ‘¡), ğ‘§, ğ‘¡âŸ)
che sono dunque due soluzioni del sistema, ma (come visto precedentemente) per Cramer esiste unâ€™unica
soluzione per il sistema {
2ğ‘¥ + ğ‘¦ = âˆ’ğ‘§ âˆ’ 2ğ‘¡
ğ‘¥ + ğ‘¦ = âˆ’ğ‘§ âˆ’ ğ‘¡ , questo vuol dire che le quadruple coincidono in tutto per tutto
(ogni volta che le quadruple di soluzioni coincidono sui valori al di fuori del minore fondamentale devono
coincidere su tutte le incognite) quindi esiste un'unica soluzione e allora ğ›¼(ğ‘§, ğ‘¡) = ğ‘¥ e ğ›½(ğ‘§, ğ‘¡) = ğ‘¦. Abbiamo
cosÃ¬ dimostrato che ğ‘† Ã¨ un sottospazio vettoriale, per dimostrare che sia un sistema di generatori prendiamo
ğ‘§(ğ›¼(1,0), ğ›½(1,0), 1,0) + ğ‘¡(ğ›¼(0,1), ğ›½(0,1), 0,1) = (âˆ—,âˆ—, ğ‘§, ğ‘¡) âˆˆ ğ‘† ed ha gli stessi identici valori della soluzione
(ğ‘¥, ğ‘¦, ğ‘§, ğ‘¡) allora per Cramer (âˆ—,âˆ—, ğ‘§, ğ‘¡) = (ğ‘¥, ğ‘¦, ğ‘§, ğ‘¡) e quindi questa quadrupla Ã¨ combinazione lineare dei
due vettori (ğ›¼(1,0), ğ›½(1,0), 1,0) e (ğ›¼(0,1), ğ›½(0,1), 0,1).
Relazione tra sistema generale ed omogeneo associato: in termini matriciali ğ‘† âˆ¶ ğ´ğ‘‹ = ğ¶ e ğ‘†0 âˆ¶ ğ´ğ‘‹ = 0 esiste
una relazione tra il sistema generale ğ‘† ed il sistema omogeneo ğ‘†0 per il teorema seguente:
Teorema: Fissato ğ‘Œ âˆˆ ğ‘† come soluzione del mio sistema completo ğ‘† allora:
1) âˆ€ğ‘ âˆˆ ğ‘† âˆƒğ‘0 âˆˆ ğ‘†0 âˆ¶ ğ‘ = ğ‘Œ + ğ‘0 (posso ottenere la soluzione ğ‘ a partire da ğ‘Œ e da una soluzione ğ‘0
del mio sistema omogeneo)
2) âˆ€ğ‘0 âˆˆ ğ‘†0 âˆ¶ ğ‘Œ + ğ‘0 âˆˆ ğ‘† (soluzione particolare del sistema ğ‘†, il punto 1 e 2 sono uno il viceversa
dellâ€™altro)
Dimostrazione: Punto 2: ğ´(ğ‘Œ + ğ‘0) = ğ´ğ‘Œ + ğ´ğ‘0 = ğ¶ + 0 = ğ¶ quindi soddisfa il sistema generale ğ‘† ed allora
ğ‘Œ + ğ‘0 appartiene ad ğ‘†. Per dimostrare il punto 1 prendiamo una qualunque soluzione ğ‘ di ğ‘† e sapendo che
anche ğ‘Œ âˆˆ ğ‘† scriviamo ğ´(ğ‘ âˆ’ ğ‘Œ) = ğ´ğ‘ âˆ’ ğ´ğ‘Œ = ğ¶ âˆ’ ğ¶ = 0 â‡’ ğ‘ âˆ’ ğ‘Œ âˆˆ ğ‘†0 e dunque ğ‘ = ğ‘Œ + (ğ‘ âˆ’ ğ‘ŒâŸ  
ğ‘0
).
Questo teorema ci dice che se voglio descrivere lâ€™insieme delle soluzioni del mio sistema generale S quello
che io devo andare a fare Ã¨ trovarmi una singola soluzione per S dopodichÃ© vado a considerare il sistema
omogeneo associato, di questâ€™ultimo vado a trovare lâ€™insieme delle soluzioni; e tutte le altre soluzioni si
28

possono descrivere come somma dellâ€™unica soluzione che mi sono trovato piÃ¹ una qualunque combinazione
lineare degli elementi della base dello spazio delle soluzioni del sistema omogeneo.
Esempio: Sia ğ‘† = {
2ğ‘¥ + ğ‘¦ + ğ‘§ + 2ğ‘¡ = 1
ğ‘¥ + ğ‘¦ + ğ‘§ + ğ‘¡ = 1
il sistema generico e ğ‘†0 = {
2ğ‘¥ + ğ‘¦ + ğ‘§ + 2ğ‘¡ = 0
ğ‘¥ + ğ‘¦ + ğ‘§ + ğ‘¡ = 0
il sistema
omogeneo associato, che abbiamo giÃ  precedentemente calcolato e quindi sappiamo che lâ€™insieme di
soluzioni di ğ‘†0 Ã¨ ğ‘†0 = âŒ©(0, âˆ’1,1,0), (âˆ’1,0,0,1)âŒª, cerchiamo ora una soluzione per ğ‘† (poniamo ğ‘§ = ğ‘¡ = 0):
ğ‘Œ âˆˆ ğ‘† âˆ¶
{
2ğ‘¥ + ğ‘¦ = 1
ğ‘¥ + ğ‘¦ = 1 â‡’ ğ‘¥ = 0, ğ‘¦ = 1 e allora abbiamo trovato che la quadrupla ğ‘Œ = (0,1,0,0) âˆˆ ğ‘† Ã¨
soluzione del sistema generale ğ‘†; dunque possiamo descrivere lâ€™insieme delle soluzioni ğ‘† = ğ‘Œ + ğ‘†0 ovvero
come somma di ğ‘Œ ed una soluzione di ğ‘†0 (cosÃ¬ abbiamo descritto tutte le soluzioni di ğ‘†).
Risoluzione sistema omogeneo con ğ’ âˆ’ ğŸ equazioni indipendenti ed ğ’ incognite
Sia il seguente sistema omogeneo generico: ğ‘† âˆ¶
{
ğ‘11ğ‘¥1 + ğ‘12ğ‘¥2 +â‹¯+ ğ‘1ğ‘›ğ‘¥ğ‘› = 0
â‹®
, il fatto che
ğ‘(ğ‘›âˆ’1),1ğ‘¥1 + ğ‘(ğ‘›âˆ’1),2ğ‘¥2 +â‹¯+ ğ‘(ğ‘›âˆ’1),ğ‘›ğ‘¥ğ‘› = 0
si abbia ğ‘› âˆ’ 1 equazioni indipendenti vuol dire sostanzialmente che la matrice incompleta (anche quella
completa poichÃ© lâ€™aggiunta della colonna di zeri Ã¨ ininfluente) ha tutte le righe che sono indipendenti, di
conseguenza avremo per la matrice ğ´ = (
ğ‘11
â‹®
â‹¯ ğ‘1ğ‘›
â‹®
â‹±
ğ‘(ğ‘›âˆ’1),1 â‹¯ ğ‘(ğ‘›âˆ’1),ğ‘›
) il rango massimo: ğ‘Ÿ(ğ´) = ğ‘› âˆ’ 1. Inoltre,
grazie alla teoria sino ad ora studiata quello che si trova Ã¨ che la dimensione delle soluzioni del sistema
dimğ‘† = 1 (essendo un sistema omogeneo la dimensione del sottospazio generato Ã¨ sostanzialmente il
numero di incognite meno il rango di un minore fondamentale della matrice incompleta), di conseguenza per
poter descrivere ğ‘† ci basta trovare una soluzione non nulla e tutti i vettori ad esso proporzionali saranno
tutti e soli vettori soluzioni di questo sistema.
In questo caso particolare, per trovare una soluzione del sistema si usa una formula che si ricava nel modo
seguente: prendiamo tutti i minori di ordine ğ‘› âˆ’ 1 di ğ´ (le sottomatrici quadrate di ordine ğ‘› âˆ’ 1):
ğ´1, ğ´2, â€¦ , ğ´ğ‘› e lasciamo fuori una singola colonna per avere ğ‘› âˆ’ 1 righe (dunque ho ğ‘› possibilitÃ ), di queste
colonne abbiamo la certezza che ce ne sia almeno una con determinante non nullo (poichÃ© il minore
fondamentale Ã¨ ğ´ stesso, essendo le righe indipendenti) quindi avrÃ² per ğœ†1 = det ğ´1 , â€¦ , ğœ†ğ‘› = det ğ´ğ‘›
almeno un ğœ†ğ‘– â‰  0; allora la n-upla dei determinanti dei minori presi a segni alterni Ã¨ effettivamente una
soluzione del mio sistema, quindi (ğœ†1,âˆ’ğœ†2,â€¦ , (âˆ’1)ğ‘›âˆ’1ğœ†ğ‘›) âˆˆ ğ‘†. Inoltre, poichÃ© questâ€™ultima Ã¨ una n-upla
non tutta nulla, lâ€™oggetto (ğœ†1,âˆ’ğœ†2,â€¦ , (âˆ’1)ğ‘›âˆ’1ğœ†ğ‘›) costituirÃ  una base per le soluzioni di ğ‘† e questo significa
che tutte le altre soluzioni le posso ottenere moltiplicando uno scalare per quella n-upla. Ora ci resta da
dimostrare che (ğœ†1, âˆ’ğœ†2,â€¦ , (âˆ’1)ğ‘›âˆ’1ğœ†ğ‘›) sia effettivamente soluzione per ğ‘†, a tal scopo utilizziamo la
seguente matrice ausiliaria ğ¶1 = (
ğ‘11 â€¦ ğ‘1ğ‘›
ğ‘11
â‹¯ ğ‘1ğ‘›
â‹®
â‹±
â‹®
ğ‘(ğ‘›âˆ’1),1 â‹¯ ğ‘(ğ‘›âˆ’1),ğ‘›
), che differisce dalla matrice ğ´ per la prima riga
duplicata, e questo significa che det ğ¶1 = 0 per il teorema degli orlati. Ora possiamo sviluppare il
determinante della matrice rispetto al prima riga, avremo quindi ğœ†1ğ‘11 âˆ’ ğœ†2ğ‘12 +â‹¯+ (âˆ’1)ğ‘›âˆ’1ğœ†ğ‘›ğ‘1ğ‘› = 0,
ma questa equazione rappresenta nientâ€™altro che la prima equazione del sistema ğ‘† (basta sostituire i ğœ†ğ‘– con
gli ğ‘¥ğ‘–), quindi non solo ho soddisfatto la prima equazioni del sistema ma questi oggetti rappresentano anche
la n-upla che volevamo dimostrare appartenente alle soluzioni di ğ‘†, e quindi ho dimostrato che la n-upla
(ğœ†1,âˆ’ğœ†2,â€¦ , (âˆ’1)ğ‘›âˆ’1ğœ†ğ‘›) Ã¨ quantomeno soluzione della prima equazione di ğ‘†, questo processo si puÃ² iterare
con altre matrici ausiliari e risulterÃ  che (ğœ†1,âˆ’ğœ†2,â€¦ , (âˆ’1)ğ‘›âˆ’1ğœ†ğ‘›) Ã¨ effettivamente soluzione per ğ‘†.
Esempio: ğ‘† âˆ¶
{
2ğ‘¥ + 2ğ‘¦ + 3ğ‘§ = 0
2ğ‘¥ + ğ‘¦ + 4ğ‘§ = 0
ğ´ = (2 2 3
2 1 4
) si ha che ğ‘† = âŒ© ( |2 3
1 4
| , âˆ’ |2 3
2 4
| , |2 2
2 1
| ) âŒª
29

5. Applicazioni Lineari
Definizione
Unâ€™applicazione lineare non Ã¨ nientâ€™altro che unâ€™applicazione che soddisfa delle proprietÃ , dunque siano
ğ‘‰, ğ‘‰â€² spazi vettoriali, ğ‘“ âˆ¶ ğ‘‰ â†’ ğ‘‰â€² viene detta lineare se soddisfa le seguenti proprietÃ :
1) LinearitÃ  rispetto la somma: âˆ€ğ‘£, ğ‘¤ âˆˆ ğ‘‰, ğ‘“(ğ‘£ + ğ‘¤) = ğ‘“(ğ‘£) + ğ‘“(ğ‘¤)
lâ€™immagine della somma Ã¨ uguale alla somma delle immagini
2) LinearitÃ  rispetto al prodotto: âˆ€ğœ† âˆˆ â„ e âˆ€ğ‘£ âˆˆ ğ‘‰, ğ‘“(ğœ†ğ‘£) = ğœ†ğ‘“(ğ‘£)
analogo del concetto di omomorfismo in algebra
Le applicazioni lineari sono conosciute anche con la nomenclatura di omomorfismi (lineari), altre
nomenclature sono:
â€¢ Se ğ‘‰ = ğ‘‰â€² si parla di endomorfismo
â€¢ Se ğ‘“ Ã¨ iniettiva di monomorfismo
â€¢ Se ğ‘“ Ã¨ suriettiva di epimorfismo
â€¢ Se ğ‘“ Ã¨ biettiva di isomorfismo
â€¢ Lâ€™endomorfismo biettivo si dice automorfismo
Esempi
1) ğ‘“: ğ‘‰ â†’ ğ‘‰, lâ€™applicazione che porta ogni vettore nel vettore nullo (ğ‘£ â†¦ 0), Ã¨ un endomorfismo detto
endomorfismo nullo (applicazione nulla). Ãˆ un applicazione lineare poichÃ© le due proprietÃ  sono
banalmente verificate (analogo ragionamento per la funzione identica (ğ‘£ â†¦ ğ‘£))
2) ğ‘“: (ğ‘¥, ğ‘¦) âˆˆ â„2 â†’ (ğ‘¥, ğ‘¥ + ğ‘¦, ğ‘¦) âˆˆ â„3 Ã¨ un applicazione lineare poichÃ© per (ğ‘¥, ğ‘¦), (ğ‘¥â€², ğ‘¦â€²) âˆˆ â„2 risulta
ğ‘“((ğ‘¥, ğ‘¦) + (ğ‘¥â€², ğ‘¦â€²)) = ğ‘“(ğ‘¥ + ğ‘¥â€², ğ‘¦ + ğ‘¦â€²) = (ğ‘¥ + ğ‘¥â€², ğ‘¥ + ğ‘¥â€² + ğ‘¦ + ğ‘¦â€², ğ‘¦ + ğ‘¦â€²) = (ğ‘¥, ğ‘¥ + ğ‘¦, ğ‘¦) +
(ğ‘¥â€², ğ‘¥â€² + ğ‘¦â€², ğ‘¦â€²) = ğ‘“(ğ‘¥, ğ‘¦) + ğ‘“(ğ‘¥â€², ğ‘¦â€²) (lineare rispetto la somma) mentre per (ğ‘¥, ğ‘¦) âˆˆ â„2 e â„ âˆˆ â„ si ha
ğ‘“(â„(ğ‘¥, ğ‘¦)) = ğ‘“(â„ğ‘¥, â„ğ‘¦) = (â„ğ‘¥, â„ğ‘¥ + â„ğ‘¦, â„ğ‘¦) = â„(ğ‘¥, ğ‘¥ + ğ‘¦, ğ‘¦) = â„ â‹… ğ‘“(ğ‘¥, ğ‘¦) (lineare rispetto il prodotto)
3) ğ‘“: â„2 â†’ â„, lâ€™applicazione Ã¨ la proiezione della prima coordinata ((ğ‘¥, ğ‘¦) â†¦ ğ‘¥), Ã¨ un applicazione lineare,
e le proprietÃ  sono banalmente verificate. Lâ€™applicazione non Ã¨ iniettiva poichÃ© ad esempio (1,2) e (1,3)
hanno la stessa immagine, ma Ã¨ suriettiva poichÃ© âˆ€ğ‘¦ âˆˆ â„ , âˆƒğ‘¥ âˆˆ â„ âˆ¶ (ğ‘¥, ğ‘¦) â†’ ğ‘¥; di conseguenza si tratta
di un epimorfismo (non monomorfismo).
4) ğ‘“: â„2[ğ‘¥] â†’ â„3, questa applicazione va dallo spazio dei polinomi di grado al piÃ¹ due in â„3, ed associa
ğ‘ğ‘¥2 + ğ‘ğ‘¥ + ğ‘ âŸ¼ (ğ‘, ğ‘, ğ‘). Questa applicazione Ã¨ lineare: ğ‘“((ğ‘ğ‘¥2 + ğ‘ğ‘¥ + ğ‘) + (ğ‘â€²ğ‘¥2 + ğ‘â€²ğ‘¥ + ğ‘â€²)) =
ğ‘“((ğ‘ + ğ‘â€²)ğ‘¥2 + (ğ‘ + ğ‘â€²)ğ‘¥ + (ğ‘ + ğ‘â€²)) = (ğ‘ + ğ‘â€², ğ‘ + ğ‘â€², ğ‘ + ğ‘â€²) = (ğ‘, ğ‘, ğ‘) + (ğ‘â€², ğ‘â€², ğ‘â€²) = ğ‘“(ğ‘ğ‘¥2 +
ğ‘ğ‘¥ + ğ‘) + ğ‘“(ğ‘â€²ğ‘¥2 + ğ‘â€²ğ‘¥ + ğ‘â€²), ed anche ğ‘“(ğ‘¢(ğ‘ğ‘¥2 + ğ‘ğ‘¥ + ğ‘)) = ğ‘“((ğ‘¢ğ‘)ğ‘¥2 + (ğ‘¢ğ‘)ğ‘¥ + (ğ‘¢ğ‘)) =
(ğ‘¢ğ‘, ğ‘¢ğ‘, ğ‘¢ğ‘) = ğ‘¢(ğ‘, ğ‘, ğ‘) = ğ‘¢ â‹… ğ‘“(ğ‘ğ‘¥2 + ğ‘ğ‘¥ + ğ‘). Ãˆ inoltre sia iniettiva che suriettiva, di conseguenza
questâ€™applicazione Ã¨ un isomorfismo (la proprietÃ  di isomorfismo ci sarÃ  utile in seguito)
5) ğ‘“: â„ â†’ â„ con ğ‘¥ â†¦ ğ‘¥2 non Ã¨ un applicazione lineare, infatti ğ‘“(1 + 2) = ğ‘“(3) = 9 â‰  ğ‘“(1) + ğ‘“(2) = 5
6) Sia una matrice ğ´ âˆˆ â„ğ‘šğ‘› di dimensioni arbitrarie definiamo la seguente applicazione lineare (ci sarÃ 
molto utile) ğ‘“: ğ‘‹ âˆˆ â„ğ‘› â†’ ğ´ğ‘‹ âˆˆ â„ğ‘š, Ã¨ sicuramente lineare poichÃ© ğ‘“(ğ‘‹1 + ğ‘‹2) = ğ´(ğ‘‹1 + ğ‘‹2) = ğ´ğ‘‹1 +
ğ´ğ‘‹2 = ğ‘“(ğ‘‹1) + ğ‘“(ğ‘‹2) e ğ‘“(â„ğ‘‹) = ğ´(â„ğ‘‹) = â„(ğ´ğ‘‹) = â„ â‹… ğ‘“(ğ‘‹)
Esempio con matrice concreta: ğ‘“: (ğ‘¥, ğ‘¦, ğ‘§) âˆˆ â„3 âŸ¼ (3 1 2
/
XN
2 0 1
\f \
) ( ) = (
ğ‘¥
7\ J
ğ‘¦
ğ‘§
3ğ‘¥ + ğ‘¦ + 2ğ‘§
2ğ‘¥ + ğ‘§
) âˆˆ â„2
7) Lâ€™applicazione (ğ‘
ğ‘
2ğ‘“ ((0 0
\*
0 0
ğ‘
ğ‘‘
) âˆˆ â„22 âŸ¼ (1 1
ğ‘
)) = 2 (1 1
7]
XN
0 0
) = (2 2
7
XN
0 0
)
7
30
ğ‘
) âˆˆ â„2 non Ã¨ lineare perchÃ© ğ‘“ (2 (0 0
0 0
)) = (1 1
0 0
) â‰ 

Proposizioni
â€¢ Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² un applicazione lineare, allora valgono le seguenti proposizioni:
I. âˆ€â„, ğ‘˜ âˆˆ â„, âˆ€ğ‘£, ğ‘¤ âˆˆ ğ‘‰, ğ‘“(â„ğ‘£ + ğ‘˜ğ‘¤) = â„ â‹… ğ‘“(ğ‘£) + ğ‘˜ â‹… ğ‘“(ğ‘¤)
ğ‘“(0ğ‘‰) = 0ğ‘‰â€²
II.
III.
IV.
ğ‘“(â„1ğ‘£1 + â„2ğ‘£2 +â‹¯+ â„ğ‘›ğ‘£ğ‘›) = â„1 â‹… ğ‘“(ğ‘£1) +â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘£ğ‘›)
ğ‘“(âˆ’ğ‘£) = âˆ’ğ‘“(ğ‘£)
Dimostrazione: (I) applichiamo la linearitÃ  rispetto la somma e poi la linearitÃ  rispetto il prodotto su
ciascun addento: ğ‘“(â„ğ‘£ + ğ‘˜ğ‘¤) = ğ‘“(â„ğ‘£) + ğ‘“(ğ‘˜ğ‘¤) = â„ â‹… ğ‘“(ğ‘£) + ğ‘˜ â‹… ğ‘“(ğ‘¤).
(II) la dimostrazione che
lâ€™elemento neutro viene mandato nellâ€™elemento neutro Ã¨ la seguente (si sfrutta la proprietÃ 
dellâ€™elemento neutro): ğ‘“(0) = ğ‘“(0 + 0) = ğ‘“(0) + ğ‘“(0) â‡’ ğ‘“(0) = ğ‘“(0) âˆ’ ğ‘“(0) = 0. (III) si dimostra
per induzione su ğ‘›: abbiamo giÃ  dimostrato lâ€™asserto vero per ğ‘› = 1 nel punto (I), supponiamolo vero
per ğ‘› âˆ’ 1 e scriviamo ğ‘“ (â„1ğ‘£1 + â„2ğ‘£2 +â‹¯
âŸ          + â„ğ‘›ğ‘£ğ‘›) = ğ‘“(â„1ğ‘£1 +â‹¯+ â„ğ‘›âˆ’1ğ‘£ğ‘›âˆ’1) + â„ğ‘› â‹… ğ‘“(ğ‘£ğ‘›) = â„1 â‹…
ğ‘“(ğ‘£1) +â‹¯+ â„ğ‘›âˆ’1 â‹… ğ‘“(ğ‘£ğ‘›âˆ’1) + â„ğ‘› â‹… ğ‘“(ğ‘£ğ‘›). (IV) ğ‘“(âˆ’ğ‘£) = ğ‘“(âˆ’1ğ‘£) = âˆ’1ğ‘“(ğ‘£) = âˆ’ğ‘“(ğ‘£)
â€¢ Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² un applicazione lineare
I.
ğ‘“ conserva la dipendenza: ğ‘£1,â€¦ , ğ‘£ğ‘¡ âˆˆ ğ‘‰ dipendente â‡’ ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘¡) dipendente in ğ‘‰â€²
(mentre la dipendenza lineare viene conservata lâ€™indipendenza non Ã¨ detto che lo sia)
Dim.: ğ‘£1,â€¦ , ğ‘£ğ‘¡ sono dipendenti quindi esistono ğ‘– scalari non tutti nulli tale che la combinazione
lineare corrispondente Ã¨ uguale allâ€™elemento neutro: â„1ğ‘£1 +â‹¯+ â„ğ‘¡ğ‘£ğ‘¡ = 0; applicando ora la
funzione ğ‘“ ad ambo i membri di questa uguaglianza avremo che ğ‘“(â„1ğ‘£1 +â‹¯+ â„ğ‘¡ğ‘£ğ‘¡) = â„1 â‹…
ğ‘“(ğ‘£1) +â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘£ğ‘›) = ğ‘“(0) = 0 (per la (III) e ğ‘™ğ‘ (II) della proposizione precedente).
II.
Se un vettore appartiene al sottospazio generato da un certo insieme ğ‘† allora lâ€™immagine di quel
vettore appartiene al sottospazio generato dallâ€™immagine di quel sottoinsieme (conseguenza
della I): ğ‘£ âˆˆ âŒ©ğ‘†âŒª â‡’ ğ‘“(ğ‘£) âˆˆ âŒ©ğ‘“(ğ‘†)âŒª
Dim.: Consideriamo lâ€™insieme finito ğ‘£ = â„1ğ‘ 1 +â‹¯+ â„ğ‘›ğ‘ ğ‘› con ğ‘† = {ğ‘ 1,â€¦ , ğ‘ ğ‘›}, applicando ğ‘“ ad
entrambi i membri: ğ‘“(ğ‘£) = â„1 â‹… ğ‘“(ğ‘ 1) +â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘ ğ‘›) e trovo che ğ‘“(ğ‘£) âˆˆ âŒ©ğ‘“(ğ‘ 1), â€¦ , ğ‘“(ğ‘ ğ‘›)âŒª
III.
IV.
ğ‘Š â‰¤ ğ‘‰ â‡’ ğ‘“(ğ‘Š) â‰¤ ğ‘‰â€² (lâ€™immagine di ogni sottospazio del dominio risulta essere un sottospazio
del codominio, se lâ€™applicazione non Ã¨ lineare allora Ã¨ solo sottoinsieme del codominio).
Dim.: Sappiamo per certo che ğ‘Š â‰  âˆ… poichÃ© essendo sottospazio contiene almeno lâ€™elemento
neutro, ma allora anche lâ€™immagine ğ‘“(ğ‘Š) â‰  âˆ… poichÃ© contiene lâ€™immagine dellâ€™elemento
neutro. Dunque, ci resta da dimostrare che sia stabile rispetto alla somma e al prodotto. Siano
ğ‘£â€², ğ‘¤â€² âˆˆ ğ‘“(ğ‘Š) â‡’ âˆƒğ‘£, ğ‘¤ âˆˆ ğ‘Š âˆ¶ ğ‘“(ğ‘£) = ğ‘£â€², ğ‘“(ğ‘¤) = ğ‘¤â€²; a questo punto dobbiamo dimostrare
che ğ‘£â€² + ğ‘¤â€² âˆˆ ğ‘“(ğ‘Š), a tal proposito dobbiamo trovare un oggetto allâ€™interno di ğ‘Š tale che la
sua immagine sia proprio ğ‘£â€² + ğ‘¤â€²; ossia ğ‘£ + ğ‘¤: ğ‘“(ğ‘£) + ğ‘“(ğ‘¤) = ğ‘“(ğ‘£ + ğ‘¤) = ğ‘£â€² + ğ‘¤â€² âˆˆ ğ‘“(ğ‘Š).
Allo stesso modo, per il prodotto: â„ğ‘£ = â„ â‹… ğ‘“(ğ‘£) = ğ‘“(â„ğ‘£) = â„ğ‘£â€² âˆˆ ğ‘“(ğ‘Š).
ğ‘Š = âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘›âŒª â‡’ ğ‘“(ğ‘Š) = âŒ©ğ‘“(ğ‘¤1),â€¦ , ğ‘“(ğ‘¤ğ‘›)âŒª (se ğ‘Š Ã¨ generato da ğ‘¤1,â€¦ , ğ‘¤ğ‘›
allora un
insieme di generatori per il sottospazio immagine viene dato dalle immagini dei generatori)
Dim.: ğ‘¤1,â€¦ , ğ‘¤ğ‘› âˆˆ ğ‘Š â‡’ ğ‘“(ğ‘¤1),â€¦ , ğ‘“(ğ‘¤ğ‘›) âˆˆ ğ‘“(ğ‘Š). Allora, se ci appartengono tutti gli oggetti del
tipo ğ‘“(ğ‘¤ğ‘–) anche il sottospazio generato da tutti gli ğ‘“(ğ‘¤ğ‘–) Ã¨ contenuto allâ€™interno di ğ‘“(ğ‘Š), in
simboli: âŒ©ğ‘“(ğ‘¤ğ‘–), â€¦ , ğ‘“(ğ‘¤ğ‘›)âŒª âˆˆ ğ‘“(ğ‘Š); abbiamo cosÃ¬ dimostrato una delle due inclusioni. A questo
punto dimostriamo che ogni elemento di ğ‘“(ğ‘Š) âˆˆ âŒ©ğ‘“(ğ‘¤1),â€¦ , ğ‘“(ğ‘¤ğ‘›)âŒª, ovvero che ogni elemento
ğ‘¤â€² âˆˆ ğ‘“(ğ‘Š) si puÃ² scrivere come combinazione lineare degli elementi ğ‘“(ğ‘¤1), â€¦ , ğ‘“(ğ‘¤ğ‘›). A tal
proposito sia ğ‘¤â€² âˆˆ ğ‘“(ğ‘Š) â‡’ âˆƒğ‘¤ âˆˆ ğ‘Š âˆ¶ ğ‘¤â€² = ğ‘“(ğ‘¤), essendo ğ‘¤ âˆˆ ğ‘Š = âŒ©ğ‘¤1,â€¦ , ğ‘¤ğ‘›âŒª sappiamo
che certi scalari â„ğ‘– âˆˆ â„ âˆ¶ ğ‘¤ = â„1ğ‘¤1 +â‹¯+ â„ğ‘›ğ‘¤ğ‘›; ma allora si ha ğ‘¤â€² = ğ‘“(â„1ğ‘¤1 +â‹¯+ â„ğ‘›ğ‘¤ğ‘›) =
â„1 â‹… ğ‘“(ğ‘¤1) +â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘¤ğ‘›) e dunque ğ‘¤â€² si puÃ² scrivere come combinazione lineare dei ğ‘“(ğ‘¤ğ‘–)
e di conseguenza, per doppia inclusione, ğ‘“(ğ‘Š) = âŒ©ğ‘“(ğ‘¤1),â€¦ , ğ‘“(ğ‘¤ğ‘›)âŒª.
31

Concetto di Ker e sue proprietÃ 
Definizione: Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² un applicazione lineare, denotiamo il sottospazio immagine di ğ‘“ con Im ğ‘“ ed Ã¨
lâ€™insieme {ğ‘“(ğ‘£) | ğ‘£ âˆˆ ğ‘‰} = ğ‘“(ğ‘‰) = Im ğ‘“; un altro insieme utile Ã¨ il cosiddetto ker (nucleo, dal tedesco
kernel) che Ã¨ lâ€™insieme di tutti gli oggetti del dominio che vengono portati nellâ€™elemento neutro, ovvero
ğ¤ğğ« ğ’‡ = {ğ’— âˆˆ ğ‘½ âˆ¶ ğ’‡(ğ’—) = ğŸ}. Inoltre, il ker Ã¨ anche un sottospazio vettoriale.
Proposizione: ker ğ‘“ â‰¤ ğ‘‰
Im ğ‘“ â‰¤ ğ‘‰â€²
Dimostrazione: Im ğ‘“ poichÃ© coincide con ğ‘“(ğ‘‰) Ã¨ sottospazio vettoriale per la proposizione vista
precedentemente. ker ğ‘“ â‰  âˆ… poichÃ© 0 âˆˆ ker ğ‘“ per definizione. Siano ora ğ‘£, ğ‘¤ âˆˆ ker ğ‘“ â‡’ ğ‘£ + ğ‘¤ âˆˆ ker ğ‘“ ciÃ²
significa che ğ‘“(ğ‘£) = 0 = ğ‘“(ğ‘¤) â‡’ ğ‘“(ğ‘£ + ğ‘¤) = ğ‘“(ğ‘£) + ğ‘“(ğ‘¤) = 0 + 0 = 0 â‡’ ğ‘“(ğ‘£ + ğ‘¤) âˆˆ ker ğ‘“; allo stesso
modo per ğœ† âˆˆ â„ si ha ğ‘“(ğœ†ğ‘£) = ğœ† â‹… ğ‘“(ğ‘£) = ğœ†0 = 0 â‡’ ğ‘“(ğœ†ğ‘£) âˆˆ ker ğ‘“.
Corollario: Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² lineare, con ğ‘‰ spazio vettoriale finitamente generato. Se prendo una base ğ‘’1,â€¦ , ğ‘’ğ‘›
di ğ‘‰ allora Im ğ‘“ = âŒ©ğ‘“(ğ‘’1),â€¦ , ğ‘“(ğ‘’ğ‘›)âŒª (Ã¨ generato ma non Ã¨ detto che sia essa stessa base).
Essendo un corollario della proposizione IV vista precedentemente la dimostrazione Ã¨ inutile.
Proposizione: Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² lineare allora ğŸ) ğ‘“ ğ‘ ğ‘¢ğ‘Ÿğ‘–ğ‘’ğ‘¡ğ‘¡ğ‘–ğ‘£ğ‘ â‡” Im ğ‘“ = ğ‘‰â€²
ğŸ) ğ‘“ ğ‘–ğ‘›ğ‘–ğ‘’ğ‘¡ğ‘¡ğ‘–ğ‘£ğ‘ â‡” ker ğ‘“ = {0}
Dimostrazione: la prima Ã¨ ovvia e precedentemente osservata. La seconda ci dice che una funzione Ã¨ iniettiva
se il ker Ã¨ il singleton dellâ€™elemento neutro e lo si dimostra per doppia implicazione. â‡’: sappiamo che 0 âˆˆ
ker ğ‘“ â‡’ {0} âŠ† ker ğ‘“, supponiamo che ğ‘£ âˆˆ ker ğ‘“ â‡’ ğ‘“(ğ‘£) = 0 ma anche ğ‘“(0) = 0 dunque per lâ€™iniettivitÃ 
abbiamo che ğ‘£ = 0 e questo comporta anche lâ€™inclusione di ker ğ‘“ âŠ† {0}. â‡: prendiamo due oggetti ğ‘“(ğ‘£) e
ğ‘“(ğ‘¤) âˆˆ ker ğ‘“, dunque sarÃ  ğ‘“(ğ‘£) = ğ‘“(ğ‘¤) â‡’ ğ‘“(ğ‘£) âˆ’ ğ‘“(ğ‘¤) = 0 â‡’ ğ‘“(ğ‘£ âˆ’ ğ‘¤) = 0 â‡’ ğ‘£ âˆ’ ğ‘¤ = 0 â‡’ ğ‘£ = ğ‘¤.
Proposizione (correlazione tra indipendenza e iniettivitÃ  di una funzione): Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² un monomorfismo
(omomorfismo iniettivo) succede che lâ€™indipendenza viene conservata, dunque: ğ‘£1, â€¦ , ğ‘£ğ‘› âˆˆ ğ‘‰ indipendenti
â‡’ ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘›) indipendenti. (In particolare: base di ğ‘‰ â‡’ base di ğ‘“(ğ‘‰))
Dimostrazione: Prendiamo una combinazione lineare dei vettori immagine ed eguagliamola allâ€™elemento
neutro: â„1 â‹… ğ‘“(ğ‘£1) +â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘£ğ‘›) = 0, affinchÃ© questi vettori siano indipendenti bisogna dimostrare che
tutti gli scalari siano necessariamente pari a zero. Per la proprietÃ  di linearitÃ  di ğ‘“ si ha che il primo membro
si puÃ² rileggere come ğ‘“(â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘›) e quindi â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› âˆˆ ker ğ‘“, ed appartenendo al ker deve
essere pari allâ€™elemento neutro e dunque per lâ€™iniettivitÃ  abbiamo â„1ğ‘£1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› = 0 ed essendo questi
vettori indipendenti allora â„1 = â‹¯ = â„ğ‘› = 0 e quindi ğ‘“(ğ‘£1),â€¦ , ğ‘“(ğ‘£ğ‘›) sono indipendenti.
Teorema: Se ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ allora la seguente uguaglianza Ã¨ vera: dim(ker ğ‘“) + dim(Im ğ‘“) = ğ‘›
Dimostrazione: Se il ker ğ‘“ = ğ‘‰ğ‘› â‡’ ğ‘› + 0 = ğ‘› essendo Im ğ‘“ pari al singleton dellâ€™elemento neutro. Mentre
per ker ğ‘“ = {0} significa che ğ‘“ Ã¨ iniettiva ed allora presa una base del dominio ğ‘’1,â€¦ , ğ‘’ğ‘› di ğ‘‰ allora (per la
precedente proposizione) ğ‘“(ğ‘’1),â€¦ , ğ‘“(ğ‘’ğ‘›) Ã¨ base di Im ğ‘“ e quindi avendo trovato una base di dimensione ğ‘›
si ha che dim(ker ğ‘“) + dim(Im ğ‘“) = 0 + ğ‘› = ğ‘›. Supponiamo ora che il {0} < ker ğ‘“ < ğ‘‰ğ‘›: sia ğ‘£1, â€¦ , ğ‘£ğ‘¡ base
di ker ğ‘“ e completiamola in una base di ğ‘‰ğ‘› aggiungendo almeno un vettore: ğ‘£1, â€¦ , ğ‘£ğ‘¡, ğ‘£ğ‘¡+1,â€¦ , ğ‘£ğ‘› base di ğ‘‰ğ‘›.
Quello da dimostrare Ã¨ che dim(Im ğ‘“) = ğ‘› âˆ’ ğ‘¡ che Ã¨ il numero di vettori usati per completare la base di ğ‘‰ğ‘›,
quindi bisogna dimostrare che ğ‘“(ğ‘£ğ‘¡+1),â€¦ , ğ‘“(ğ‘£ğ‘›) sia una base di Im ğ‘“: prendiamo il sistema di generatori
per Im ğ‘“ = âŒ©ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘¡), ğ‘“(ğ‘£ğ‘¡+1),â€¦ , ğ‘“(ğ‘£ğ‘›)âŒª, ma essendo ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘¡) pari allâ€™elemento neutro
possono essere rimossi dal sistema di generatori e dunque si ha che Im ğ‘“ = âŒ©ğ‘“(ğ‘£ğ‘¡+1),â€¦ , ğ‘“(ğ‘£ğ‘›)âŒª; rimane da
dimostrare che ğ‘“(ğ‘£ğ‘¡+1),â€¦ , ğ‘“(ğ‘£ğ‘›) sono indipendenti: â„ğ‘¡+1 â‹… ğ‘“(ğ‘£ğ‘¡+1) +â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘£ğ‘›) = ğ‘“(â„ğ‘¡+1ğ‘£ğ‘¡+1 +
â‹¯+ â„ğ‘›ğ‘£ğ‘›) = 0 â‡’ â„ğ‘¡+1ğ‘£ğ‘¡+1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› âˆˆ ker ğ‘“ e quindi questo vettore puÃ² essere riscritto come
combinazione lineare della base ğ‘£1, â€¦ , ğ‘£ğ‘¡ e quindi âˆƒâ„1,â€¦ , â„ğ‘¡ âˆˆ â„ âˆ¶ â„ğ‘¡+1ğ‘£ğ‘¡+1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› = â„1ğ‘£1 +â‹¯+
â„ğ‘¡ğ‘£ğ‘¡; portando a sinistra entrambi i membri avremo che : â„ğ‘¡+1ğ‘£ğ‘¡+1 +â‹¯+ â„ğ‘›ğ‘£ğ‘› âˆ’ â„1ğ‘£1 +â‹¯âˆ’ â„ğ‘¡ğ‘£ğ‘¡ = 0 ed
essendo ğ‘£1, â€¦ , ğ‘£ğ‘¡, ğ‘£ğ‘¡+1,â€¦ , ğ‘£ğ‘› base si ha che â„1 = â‹¯ = â„ğ‘¡ = â„ğ‘¡+1 = â„ğ‘› = 0. E questo dimostra che questi
vettori sono indipendenti ed un sistema di generatori e dunque una base di dimensione ğ‘› âˆ’ ğ‘¡.
32

Isomorfismo coordinato
Lâ€™isomorfismo coordinato Ã¨ quel concetto per il quale uno spazio vettoriale ha una forma un poâ€™ piÃ¹ semplice,
ad esempio sia ğ‘‰ğ‘› uno spazio vettoriale di dimensione ğ‘› e prendiamo un riferimento â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘›) allora
posso considerare la seguente applicazione ğ¶â„› âˆ¶ ğ‘£ = â„1ğ‘’1 +â‹¯+ â„ğ‘›ğ‘’ğ‘› âˆˆ ğ‘‰ğ‘› â†¦ (â„1, â„2, â€¦ , â„ğ‘›) âˆˆ â„ğ‘›, questa
applicazione porta un vettore ğ‘£ in una n-upla determinata, avendo il vettore ğ‘£ lâ€™unicitÃ  di scrittura. ğ¶â„› Ã¨
dunque ben definita ed Ã¨ anche lineare (dimostrare la sua linearitÃ  per esercizio), inoltre si ha che ker ğ¶â„› =
{ğ‘£ âˆˆ ğ‘‰ğ‘›
âˆ¶ ğ¶â„›(ğ‘£) = (0, â€¦ ,0)} = {0} e quindi ğ‘£ = 0ğ‘’1 +â‹¯+ 0ğ‘’ğ‘› = 0 di conseguenza si ha che lâ€™isomorfismo
coordinato Ã¨ iniettivo. Dimostriamo anche la sua suriettivitÃ : Im ğ¶â„› = âŒ©ğ¶â„›(ğ‘’1),â€¦ , ğ¶â„›(ğ‘’ğ‘›)âŒª dove ğ¶â„›(ğ‘’1) Ã¨ il
primo vettore del riferimento canonico di â„ğ‘› e cosÃ¬ via per gli altri, e dunque avremo che Im ğ¶â„› =
âŒ©(1,0,â€¦ ,0),â€¦ , (0,â€¦ ,0,1)âŒª = â„ğ‘› e quindi lâ€™applicazione Ã¨ suriettiva.
Teorema: Ogni spazio vettoriale finitamente generato (diverso da 0) di dimensione ğ‘› Ã¨ isomorfo ad â„ğ‘›
Proposizione: Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² isomorfismo lineare (applicazione lineare biettiva, quindi ha unâ€™inversa) allora
lâ€™inversa ğ‘“âˆ’1: ğ‘‰â€² â†’ ğ‘‰ Ã¨ anchâ€™essa un isomorfismo lineare.
Dimostrazione: Iniziamo col dimostrare che ğ‘“âˆ’1 sia lineare rispetto alla somma, siano ğ‘£â€², ğ‘¤â€² âˆˆ ğ‘‰â€² (dominio
di ğ‘“âˆ’1 e codominio di ğ‘“) dobbiamo dimostrare che ğ‘“âˆ’1(ğ‘£â€² + ğ‘¤â€²) = ğ‘“âˆ’1(ğ‘£â€²) + ğ‘“âˆ’1(ğ‘¤â€²), poichÃ© ğ‘£â€², ğ‘¤â€² âˆˆ
ğ‘‰â€² e data la suriettivitÃ  di ğ‘“ possiamo dire che âˆƒğ‘£, ğ‘¤ âˆˆ ğ‘‰ âˆ¶ ğ‘£â€² = ğ‘“(ğ‘£) e ğ‘¤â€² = ğ‘“(ğ‘¤); a questo punto possiamo
scrivere ğ‘“âˆ’1(ğ‘£â€² + ğ‘¤â€²) = ğ‘“âˆ’1 (ğ‘“(ğ‘£) + ğ‘“(ğ‘¤)) = ğ‘“âˆ’1 (ğ‘“(ğ‘£ + ğ‘¤)) = ğ‘£ + ğ‘¤ = ğ‘“âˆ’1(ğ‘£â€²) + ğ‘“âˆ’1(ğ‘¤â€²); ora in
modo analogo dimostriamo la linearitÃ  rispetto al prodotto: sia ğœ† âˆˆ â„ si ha ğ‘“âˆ’1(ğœ†ğ‘£â€²) = ğ‘“âˆ’1 (ğœ† â‹… ğ‘“(ğ‘£)) =
ğ‘“âˆ’1 (ğ‘“(ğœ†ğ‘£)) = ğœ†ğ‘£ = ğœ† â‹… ğ‘“âˆ’1(ğ‘£â€²). Lâ€™altra implicazione si dimostra praticamente con la proposizione stessa.
Corollario: Sia ğ‘“: ğ‘‰ â†’ ğ‘‰â€² un isomorfismo lineare allora:
I.
ğ‘£1,â€¦ , ğ‘£ğ‘› sono indipendente se e solamente se le loro corrispettive immagini sono indipendenti.
In simboli: ğ‘£1,â€¦ , ğ‘£ğ‘› indipendenti â‡” ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘›) indipendenti.
Lâ€™implicazione da sinistra a destra Ã¨ vera per la correlazione tra indipendenza e iniettivitÃ  di una
funzione, da destra a sinistra invece (essendo ğ‘“ un isomorfismo) posso per la proposizione
precedente dire che le immagini di ğ‘“(ğ‘£1),â€¦ , ğ‘“(ğ‘£ğ‘›) sono anchâ€™esse indipendenti.
II.
III.
ğ‘£1,â€¦ , ğ‘£ğ‘› dipendenti â‡” ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘›) dipendenti.
In generale la dipendenza lineare viene conservata, in piÃ¹ se Ã¨ isomorfismo allora vale anche il
contrario, la dimostrazione Ã¨ semplicemente la negazione della precedente.
Sia ğ‘Š â‰¤ ğ‘‰ allora ğ‘¤1,â€¦ , ğ‘¤ğ‘› base di ğ‘Š â‡” ğ‘“(ğ‘£1), â€¦ , ğ‘“(ğ‘£ğ‘›) base di ğ‘“(ğ‘Š).
Lâ€™implicazione da sinistra a destra Ã¨ dimostrata in una proposizione precedente, per lâ€™altra
implicazione utilizziamo di nuovo il corollario, per cui sapendo che ğ‘“ Ã¨ un isomorfismo basta
applicare ğ‘“âˆ’1 per dimostrare lâ€™implicazione, essendo ğ‘“âˆ’1 anchâ€™esso un isomorfismo lineare.
Esempio: Sia ğ‘Š â‰¤ â„2[ğ‘¥] dove ğ‘Š = âŒ©ğ‘¥2 + 2ğ‘¥, ğ‘¥ âˆ’ 1, 2ğ‘¥2 + 3ğ‘¥, ğ‘¥2 + 3ğ‘¥ âˆ’ 2âŒª, lâ€™idea Ã¨ quella di utilizzare
la coordinazione associata allo spazio dei polinomi â„2[ğ‘¥] che Ã¨ â„3, prendendo come riferimento ğ‘¥2 + ğ‘¥ + 1
e di conseguenza posso scrivere ğ‘“(ğ‘Š) = âŒ©(1,2,0), (0,1, âˆ’1), (2,3,0), (1,3, âˆ’2)âŒª; utilizzando la III del
precedente corollario sappiamo che ğ‘“(ğ‘Š) Ã¨ anchâ€™esso un isomorfismo e che Ã¨ generato dalle terne descritte
precedentemente, a questo punto, per trovare una base del sottospazio ğ‘Š basta trovare una base di ğ‘“(ğ‘Š)
e invertirla.
Teorema: Un applicazione lineare ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘š
â€² risulta essere â€œnotaâ€ quando sono noti i corrispondenti dei
vettori di una base (significa che conosco come agiscono tutti i vettori del dominio ogni volta che conosce
come agisce sui vettori di una base)
Dimostrazione: Supponiamo che ğ‘’1,â€¦ , ğ‘’ğ‘› sia una base del dominio ğ‘‰ğ‘› e supponiamo che siano noti le basi
ğ‘“(ğ‘’1), â€¦ , ğ‘“(ğ‘’ğ‘›), allora conosco anche lâ€™applicazione lineare valutata in un vettore ğ‘£ âˆˆ ğ‘‰ğ‘› poichÃ© posso
33

scrivere ğ‘£ come combinazione della base ğ‘’1,â€¦ , ğ‘’ğ‘› e dunque ğ‘“(ğ‘£) = ğ‘“(â„1ğ‘’1 +â‹¯+ â„ğ‘›ğ‘’ğ‘›) = â„1 â‹… ğ‘“(ğ‘’1) +
â‹¯+ â„ğ‘› â‹… ğ‘“(ğ‘’ğ‘›); e di conseguenza Ã¨ noto.
Forma canonica delle applicazioni lineari e matrice di passaggio
Prendiamo un applicazione lineare ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘š
â€² ed un riferimento del dominio e uno del codominio,
rispettivamente â„› = (ğ‘’1, â€¦ , ğ‘’ğ‘›) di ğ‘‰ğ‘› e â„›â€² = (ğ‘’1
â€² ,â€¦ , ğ‘’ğ‘š
â€² ) di ğ‘‰ğ‘š. Per ogni vettore del dominio scriviamo la su
immagine come combinazione lineare dei ğ‘’1
â€² ,â€¦ , ğ‘’ğ‘š
â€²
â€² +â‹¯+ ğ‘ğ‘šğ‘›ğ‘’ğ‘š
ğ‘1ğ‘›ğ‘’1
, quindi: ğ‘“(ğ‘’1) = ğ‘11ğ‘’1
â€² +â‹¯+ ğ‘ğ‘š1ğ‘’ğ‘š
â€²
,â€¦ , ğ‘“(ğ‘’ğ‘›) =
â€² . A questo punto possiamo creare una matrice con i coefficienti nel seguente modo:
ğ´ = ( â‹® â‹± â‹® ) âˆˆ â„ğ‘š,ğ‘› ; questa matrice Ã¨ molto utile per poter descrivere la funzione ğ‘“ e prende il
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘š1 â‹¯ ğ‘ğ‘šğ‘›
nome di matrice associata ad ğ’‡ nei riferimenti ğ“¡ ed ğ“¡â€²; usualmente descritta con il simbolo ğ‘€â„›â„›â€²(ğ‘“). Il
procedimento cosÃ¬ descritto per la definizione Ã¨ anche il metodo in cui va calcolata la matrice associata. In
particolare, se la funzione ğ‘“ Ã¨ un endomorfismo (dominio uguale al codominio) e â„› = â„›â€² allora sarÃ  ğ‘€â„›(ğ‘“).
ProprietÃ  della matrice associata: Sia ğ‘£ âˆˆ ğ‘‰ğ‘›, se definiamo con ğ‘‹ la colonna delle componenti di ğ‘£ nel
riferimento del dominio â„› e con ğ‘‹â€² i vettori colonna delle componenti di ğ‘“(ğ‘£) in â„›â€² allora ğ‘‹ e ğ‘‹â€² sono legati
dalla seguente relazione: ğ‘‹â€² = ğ´ğ‘‹ (Quindi se mi viene fornita la matrice associata e conosco le componenti
del vettore nel riferimento del dominio allora posso ottenere le componenti nel riferimento di arrivo a
prescindere da come Ã¨ definita la funzione ğ‘“).
Dimostrazione: ğ‘‹â€² = (ğ‘¥1
â€² ,â€¦ , ğ‘¥ğ‘š
â€² ) âˆˆ â„ğ‘š e ğ‘‹ = (ğ‘¥1,â€¦ , ğ‘¥ğ‘›) âˆˆ â„ğ‘› (sono entrambi colonne, ma per praticitÃ  le
scrivo in riga per considerarli come oggetti in â„ğ‘š e â„ğ‘›) poichÃ© lo spazio del codominio e del dominio sono
rispettivamente ğ‘š ed ğ‘›. Sia ğ‘£ âˆˆ ğ‘‰ğ‘› per ipotesi (ğ‘‹ componenti di ğ‘£ in â„›) posso scriverla come combinazione
lineare: ğ‘£ = ğ‘¥1ğ‘’1 +â‹¯+ ğ‘¥ğ‘›ğ‘’ğ‘›. A questo punto applico ğ‘“ ad entrambi i membri dellâ€™uguaglianza, risulterÃ 
dunque ğ‘“(ğ‘£) = ğ‘¥1 â‹… ğ‘“(ğ‘’1) +â‹¯+ ğ‘¥ğ‘› â‹… ğ‘“(ğ‘’ğ‘›), ma essendo ğ‘“(ğ‘’1) = ğ‘11ğ‘’1
â€² +â‹¯+ ğ‘ğ‘š1ğ‘’ğ‘š
â€²
,â€¦ , ğ‘“(ğ‘’ğ‘›) =
â€² +â‹¯+ ğ‘ğ‘šğ‘›ğ‘’ğ‘š
ğ‘1ğ‘›ğ‘’1
â€²
otteniamo ğ‘“(ğ‘£) = ğ‘¥1(ğ‘11ğ‘’1
â€² +â‹¯+ ğ‘ğ‘š1ğ‘’ğ‘š
â€² ) +â‹¯+ ğ‘¥ğ‘›(ğ‘1ğ‘›ğ‘’1
â€² +â‹¯+ ğ‘ğ‘šğ‘›ğ‘’ğ‘š
â€² ) =
(ğ‘¥1ğ‘11 +â‹¯+ ğ‘¥ğ‘›ğ‘1ğ‘›)ğ‘’1
â€² +â‹¯+ (ğ‘¥1ğ‘ğ‘š1 +â‹¯+ ğ‘¥ğ‘›ğ‘ğ‘šğ‘›)ğ‘’ğ‘š
â€²
anche ğ‘“(ğ‘£) = ğ‘¥1
â€² ğ‘’1
â€² +â‹¯+ ğ‘’ğ‘š
â€²
e poichÃ© ho lâ€™unicitÃ  di scrittura e posso scrivere
â€² risulterÃ  che ğ‘¥1
ğ‘¥ğ‘š
â€² = ğ‘¥1ğ‘11 +â‹¯+ ğ‘¥ğ‘›ğ‘1ğ‘›,â€¦ , ğ‘¥ğ‘š
â€² = ğ‘¥1ğ‘ğ‘š1 +â‹¯+ ğ‘¥ğ‘›ğ‘ğ‘šğ‘›;
abbiamo cosÃ¬ scoperto che ğ´ğ‘‹ = ( â‹® â‹± â‹® )(
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘š1 â‹¯ ğ‘ğ‘šğ‘›
\f \ f
J\ J
ğ‘¥1
â‹®
ğ‘¥ğ‘›
) = (
ğ‘¥1ğ‘11 +â‹¯+ ğ‘¥ğ‘›ğ‘1ğ‘›
â‹®
\ğ‘¥1ğ‘ğ‘š1 +â‹¯+ ğ‘¥ğ‘›ğ‘ğ‘šğ‘›
) = ( â‹® ) = ğ‘‹â€².
â€²
ğ‘¥1
â€²
ğ‘¥ğ‘š
Osservazione: la proprietÃ  della matrice associata Ã¨ in realtÃ  una proprietÃ  caratterizzante la matrice, nel
senso che se ho una matrice ğ´ di ğ‘› righe ed ğ‘š colonne e questa matrice Ã¨ tale da avere la seguente proprietÃ :
ğ‘‹â€² = ğ´ğ‘‹ dove ğ‘‹ = ğ¶â„›(ğ‘£) (colonna delle componenti di ğ‘£ nel riferimento â„›) e ğ‘‹â€² = ğ¶â„›â€² (ğ‘“(ğ‘£)) per ogni ğ‘£
allora la matrice ğ´ = ğ‘€â„›â„›â€²(ğ‘“).
Proposizione: La matrice (quadrata) di passaggio da â„› ad â„›â€² Ã¨ invertibile (la sua inversa risulta essere proprio
la matrice di passaggio da â„›â€² ad â„›).
Dimostrazione: â„› â†’ â„›â€² ricordando che la matrice di passaggio si costruisce per colonne prendendo le
componenti del vecchio riferimento (in questo caso â„›) nel nuovo riferimento. Quindi se â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘›) la
matrice ğ´ la costruisco con ğ¶â„›â€²(ğ‘“(ğ‘’1) ) per la prima colonna, â€¦ e ğ¶â„›â€²(ğ‘“(ğ‘’ğ‘›)) per la n-sima colonna. La
matrice ğ´ Ã¨ invertibile perchÃ© essendo i vettori ğ‘’1,â€¦ , ğ‘’ğ‘›
indipendenti ed essendo la coordinazione un
isomorfismo anche le loro immagini saranno indipendenti; quindi, i vettori rappresentati le colonne di ğ´ sono
indipendenti, di conseguenza tutte le colonne di ğ´ sono indipendenti ed essendo il rango di ğ´ massimo (per
il teorema degli orlati) segue che det(ğ´) â‰  0, quindi ğ´ Ã¨ invertibile.
Corollario: Se ğ‘ƒ Ã¨ la matrice di passaggio da â„› â†’ â„›â€², allora ğ‘ƒâˆ’1 Ã¨ di passaggio da â„›â€² â†’ â„›.
Dimostrazione: ğ‘ƒ Ã¨ di passaggio, allora prendo le componenti ğ‘‹ = ğ¶â„›(ğ‘£) e ğ‘‹â€² = ğ¶â„›â€²(ğ‘“(ğ‘£)) con ğ‘£ âˆˆ ğ‘‰ğ‘›, e
quindi ğ‘‹â€² = ğ‘ƒğ‘‹, moltiplicando entrambi i membri per ğ‘ƒâˆ’1 si ottiene ğ‘ƒâˆ’1ğ‘‹â€² = ğ‘‹. Scriviamo in maniera
34

generica la matrice ğ‘ƒâˆ’1 = ( â‹® â‹± â‹® ) e andiamo a dimostrare che ğ‘ƒâˆ’1 sia effettivamente la matrice
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘›1 â‹¯ ğ‘ğ‘›ğ‘›
di passaggio da â„›â€² â†’ â„›. Siano â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘›) e â„›â€² = (ğ‘’1
â€² ,â€¦ , ğ‘’ğ‘›
â€² ), allora la matrice di passaggio da â„›â€² â†’ â„›
(chiamiamola ğµ) sarÃ  ğµ = ( â‹® â‹± â‹® ) essendo
ğ‘¥11 â‹¯ ğ‘¥1ğ‘›
ğ‘¥ğ‘›1 â‹¯ ğ‘¥ğ‘›ğ‘›
â€² = ğ‘¥11ğ‘’1 +â‹¯+ ğ‘¥ğ‘›1ğ‘’ğ‘›
ğ‘’1
â‹®
â€² = ğ‘¥1ğ‘›ğ‘’1 +â‹¯+ ğ‘¥ğ‘›ğ‘›ğ‘’ğ‘›
ğ‘’ğ‘›
le componenti del vettore ğ‘’1
â€² che nel riferimento â„› sono ğ‘¥11ğ‘’1 +â‹¯+ ğ‘¥ğ‘›1ğ‘’ğ‘›, dâ€™altro canto le componenti di
â€²
ğ‘’1
nel riferimento â„›â€² sono ( ) allora la avrÃ²: ğ‘ƒ (
1
0
â‹®
0
( â‹® â‹± â‹® )( ) = (
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘›1 â‹¯ ğ‘ğ‘›ğ‘›
1
0
â‹®
0
ğ‘¥11
ğ‘¥21
â‹®
ğ‘¥ğ‘›1
) = ( ) â‡’ (
1
0
â‹®
0
âŸ          
ğ‘‹â€²=ğ‘ƒğ‘‹
ğ‘¥11
ğ‘¥21
â‹®
ğ‘¥ğ‘›1
) = ğ‘ƒâˆ’1 ( ) â‡’ (
1
0
â‹®
0
âŸ            
ğ‘ƒâˆ’1ğ‘‹â€²=ğ‘‹
ğ‘11
ğ‘21
â‹®
ğ‘ğ‘›1
) di conseguenza la prima colonna di ğ‘ƒâˆ’1 Ã¨ uguale alla prima colonna di ğµ,
iterando questo procedimento per i vettori ğ‘’2
â€² ,â€¦ , ğ‘’ğ‘›
â€² risulterÃ  che ogni colonna di ğ‘ƒâˆ’1 sarÃ  uguale alla
rispettiva colonne di ğµ dunque, come volevasi dimostrare, la matrice di passaggio da â„›â€² â†’ â„› Ã¨ proprio ğ‘ƒâˆ’1.
6. Matrici simili e diagonalizzazione (spazi vettoriali)
Matrici simili
La definizione di matrici simili riguarda matrici quadrate, dunque: siano ğ´, ğ´â€² âˆˆ â„ğ‘› diremo che ğ´ Ã¨ simile ad
ğ´â€², in simboli ğ´ âˆ¼ ğ´â€², se e soltanto se esiste una matrice quadrata ğ‘ƒ con determinante diverso da zero (quindi
invertibile) tale che la ğ‘ƒâˆ’1ğ´ğ‘ƒ = ğ´â€². Definizione in simboli: ğ´ âˆ¼ ğ´â€² â‡” âˆƒğ‘ƒ âˆ¶ |ğ‘ƒ| â‰  0 e ğ‘ƒâˆ’1ğ´ğ‘ƒ = ğ´â€² (il
prodotto ğ‘ƒâˆ’1ğ´ğ‘ƒ Ã¨ chiamato in ambito algebrico anche coniugato di ğ´ mediante ğ‘ƒ).
La similitudine Ã¨ una relazione dâ€™equivalenza, cioÃ¨ riflessiva, simmetrica e transitiva:
â€¢ Riflessiva: ğ´ âˆ¼ ğ´ infatti ğ¼ğ‘›ğ´ğ¼ğ‘› = ğ´ essendo |ğ¼ğ‘›| = 1 e ğ¼ğ‘›
âˆ’1 = ğ¼ğ‘›
ğ‘ƒâˆ’1ğ´ğ‘ƒ
=
â‡“
â€¢ Simmetrica: se ğ´ âˆ¼ ğ´â€² allora ğ´â€² âˆ¼ ğ´: infatti
ğ‘ƒ(ğ‘ƒâˆ’1ğ´ğ‘ƒ)ğ‘ƒâˆ’1 =
â‡“
ğ´â€²
ğ‘ƒğ´â€²ğ‘ƒâˆ’1
ğ´
= (ğ‘ƒâˆ’1)âˆ’1ğ´â€²ğ‘ƒâˆ’1
â€¢ Transitiva: se ğ´ âˆ¼ ğµ ğ‘’ ğµ âˆ¼ ğ¶ â‡’ ğ´ âˆ¼ ğ¶: infatti per ğ´ âˆ¼ ğµ esiste un ğ‘ƒ invertibile tale che ğ‘ƒâˆ’1ğ´ğ‘ƒ = ğµ, per
ğµ âˆ¼ ğ¶ esiste invece un ğ‘ƒ1 invertibile tale che ğ‘ƒ1
âˆ’1ğµğ‘ƒ1 = ğ¶, ma questo vuol dire che per sostituzione si
ha ğ¶ = ğ‘ƒ1
âˆ’1ğµğ‘ƒ1 = ğ‘ƒ1
âˆ’1(ğ‘ƒâˆ’1ğ´ğ‘ƒ)ğ‘ƒ1 = (ğ‘ƒ1
âˆ’1ğ‘ƒâˆ’1)ğ´(ğ‘ƒğ‘ƒ1) = (ğ‘ƒğ‘ƒ1)âˆ’1ğ´(ğ‘ƒğ‘ƒ1) e quindi ğ´ âˆ¼ ğ¶ essendo ğ‘ƒğ‘ƒ1
una matrice invertibile con determinante non nullo per il teorema di Cauchy-Binet.
Teorema: Sia ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› un endomorfismo e siano â„› e â„›â€² riferimenti di ğ‘‰ğ‘› allora ğ´ = ğ‘€â„›(ğ‘“) âˆ¼ ğ‘€â„›â€²(ğ‘“) = ğ´â€²
(mette in relazione le matrici associate tra due riferimenti di un endomorfismo, ğ´ âˆ¼ ğ´â€²).
Dimostrazione: Sia ğ‘ƒ la matrice di passaggio dal riferimento â„› al riferimento â„›â€² allora per ğ‘£ âˆˆ ğ‘‰ğ‘› ho ğ‘‹ =
ğ¶â„›(ğ‘£) e ğ‘‹â€² = ğ¶â„›â€²(ğ‘£), mentre per lâ€™immagine di ğ‘£ ho ğ‘Œ = ğ¶â„› (ğ‘“(ğ‘£)) e ğ‘Œâ€² = ğ¶â„›â€² (ğ‘“(ğ‘£)). Ora, poichÃ© ğ‘ƒ Ã¨ la
matrice di passaggio da â„› a â„›â€² ho le seguenti relazioni: ğ‘‹â€² = ğ‘ƒğ‘‹ e ğ‘Œâ€² = ğ‘ƒğ‘Œ; mentre per la proprietÃ  di
matrice associata ad una funzione ho ğ‘Œ = ğ´ğ‘‹ e ğ‘Œâ€² = ğ´â€²ğ‘‹â€² a questo punto posso eseguire i seguenti passaggi:
ğ‘Œâ€² = ğ‘ƒğ‘Œ = ğ´â€²ğ‘‹â€² = ğ´â€²ğ‘ƒğ‘‹ â‡’ ğ‘Œ = ğ‘ƒâˆ’1ğ´â€²ğ‘ƒâŸ    
ğ‘
ğ‘‹ (moltiplicando entrambi i membri a sinistra per ğ‘ƒâˆ’1); il prodotto
ğ‘ Ã¨ una matrice tale che ogni volta che moltiplico a destra per le componenti di un certo vettore nel
35
ğ‘¥11
ğ‘¥21
â‹®
ğ‘¥ğ‘›1
) =
; a questo punto, prendiamo
| a â„¢~
ao â„¢~
nN
NL S

riferimento â„› ottengo le componenti in ğ‘…â€², quindi ğ‘ soddisfa la proprietÃ  di matrice associata. Ma questa
proprietÃ  definisce univocamente la matrice associata in un riferimento, e allora ğ‘ƒâˆ’1ğ´â€²ğ‘ƒ = ğ´ â‡’ ğ´â€² âˆ¼ ğ´.
Diagonalizzazione di un endomorfismo
Sia ğ´ = (
ğ‘11 â‹¯ ğ‘1ğ‘›
ğ‘ğ‘›1 â‹¯ ğ‘ğ‘›ğ‘›
â‹® â‹± â‹® ) âˆˆ â„ğ‘› ne vado a fare il determinante: det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›) dove ğ‘¡ Ã¨ unâ€™incognita. Il
determinante di questa matrice Ã¨ detto polinomio caratteristico della matrice ğ´, ne consegue che con
equazione caratteristica intendiamo det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›) = 0. ğ´ âˆ’ ğ‘¡ğ¼ğ‘› Ã¨ sostanzialmente una matrice del seguente
tipo ğ´ âˆ’ ğ‘¡ğ¼ğ‘› = (
ğ‘11 âˆ’ ğ‘¡ â‹¯ ğ‘1ğ‘›
â‹®
â‹±
â‹®
ğ‘ğ‘›1
â‹¯ ğ‘ğ‘›ğ‘› âˆ’ ğ‘¡
).
Lemma: Matrici simili hanno lo stesso polinomio caratteristico.
Dimostrazione: Se ğ´ âˆ¼ ğ´â€² allora esiste un ğ‘ƒ invertibile tale che ğ´â€² = ğ‘ƒâˆ’1ğ´ğ‘ƒ, tentiamo a questo punto di
confutare il polinomio caratteristico di ğ´â€², quindi det(ğ´â€² âˆ’ ğ‘¡ğ¼ğ‘›) = det(ğ‘ƒâˆ’1ğ´ğ‘ƒ âˆ’ ğ‘¡ğ¼ğ‘›). Osserviamo che la
matrice identica ğ¼ğ‘› = ğ‘ƒâˆ’1ğ‘ƒ, ne consegue det(ğ´â€² âˆ’ ğ‘¡ğ¼ğ‘›) = det(ğ‘ƒâˆ’1ğ´ğ‘ƒ âˆ’ ğ‘¡ğ‘ƒâˆ’1ğ‘ƒ) = det[ğ‘ƒâˆ’1(ğ´ğ‘ƒ âˆ’ ğ‘¡ğ‘ƒ)], Ã¨
possibile mettere in evidenza ğ‘ƒâˆ’1 a sinistra grazie alla distributivitÃ  del prodotto righe per colonne sulla
somma di matrici, e per lo stesso motivo metto in evidenza a destra ğ‘ƒ: det(ğ´â€² âˆ’ ğ‘¡ğ¼ğ‘›) = det[ğ‘ƒâˆ’1(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›)ğ‘ƒ],
applicando Cauchy-Binet det[ğ‘ƒâˆ’1(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›)ğ‘ƒ] = det(ğ‘ƒâˆ’1) det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›) det ğ‘ƒ, essendo numeri reali posso
spostarli a piacere, dunque det(ğ‘ƒâˆ’1) det(ğ‘ƒ) det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›) = det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›) essendo det(ğ‘ƒâˆ’1) lâ€™inverso di
det(ğ‘ƒ) e quindi det(ğ‘ƒâˆ’1ğ‘ƒ) = det(ğ¼ğ‘›) = 1. Abbiamo cosÃ¬ trovato che det(ğ´â€² âˆ’ ğ‘¡ğ¼ğ‘›) = det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›).
Diamo le seguenti definizioni:
â€¢ Sia ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› un endomorfismo, fissato un riferimento â„› ne prendiamo la matrice associata ğ´ = ğ‘€â„›(ğ‘“)
e definisco il polinomio caratteristico di ğ’‡ come il polinomio caratteristico di ğ´ (quindi della matrice
associata al suo riferimento). Il polinomio caratteristico Ã¨ ben definito, dunque non dipende dal
riferimento scelto perchÃ© le matrici associate sono simili per un teorema visto nel capitolo precedente.
â€¢ Un endomorfismo ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› Ã¨ detto diagonalizzabile se esiste almeno un riferimento â„› in cui la matrice
associata ğ‘€â„›(ğ‘“) Ã¨ diagonale (matrice quadrata dove solo la diagonale puÃ² avere valori diversi da zero).
â€¢ Una matrice ğ´ âˆˆ â„ğ‘› Ã¨ detta diagonalizzabile se Ã¨ simile ad una diagonale.
Proposizione (correlazione delle precedenti definizioni): Sia ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› un endomorfismo diagonalizzabile
allora ogni matrice associata ad ğ‘“ (non Ã¨ detto che sia diagonale) Ã¨ diagonalizzabile.
Dimostrazione: PoichÃ© lâ€™endomorfismo Ã¨ diagonalizzabile âˆƒâ„› di ğ‘‰ğ‘›
âˆ¶ ğ‘€â„›(ğ‘“) Ã¨ diagonale. A questo punto
âˆ€â„›â€² di ğ‘‰ğ‘› succede che ğ‘€â„›â€²(ğ‘“) âˆ¼ ğ‘€â„›(ğ‘“) â‡’ ğ‘€â„›â€²(ğ‘“) Ã¨ diagonalizzabile per definizione, essendo simile ad una
matrice diagonale.
Proposizione: Sia ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› un endomorfismo e sia â„› un riferimento di ğ‘‰ğ‘› con ğ‘€â„›(ğ‘“) diagonalizzabile allora
ğ‘“ Ã¨ effettivamente diagonalizzabile.
Dimostrazione: Per semplicitÃ  ğ´ = ğ‘€â„›(ğ‘“); so che questa matrice, essendo diagonalizzabile, Ã¨ simile ad una
matrice diagonale e quindi esiste una matrice ğ‘ƒ invertibile tale che ğ‘ƒâˆ’1ğ´ğ‘ƒ = ğ· con ğ· una certa matrice
diagonale. Sia â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘›) cominciamo con definire le componenti del riferimento â„› di ğ‘’1,â€¦ , ğ‘’ğ‘› ovvero
ğ‘‹1 = ğ¶â„›(ğ‘’1) = (1,0,â€¦ ,0),â€¦ , ğ‘‹ğ‘› = ğ¶â„›(ğ‘’ğ‘›) = (0,â€¦ ,0,1); definiamo con ğ¹ğ‘: ğ‘‹ âˆˆ â„ğ‘› â†¦ ğ‘ƒğ‘‹ âˆˆ â„ğ‘›
un
applicazione lineare che porta lâ€™oggetto ğ‘‹ (vettore colonna) in un altro vettore colonna ğ‘ƒğ‘‹, questa tipologia
di applicazione Ã¨ un isomorfismo lineare poichÃ© ğ¹ğ‘ Ã¨ invertibile ed ha inversa ğ¹ğ‘ƒâˆ’1: ğ‘‹ â†’ ğ‘ƒâˆ’1ğ‘‹. Inoltre,
sapendo che ğ‘‹1, â€¦ , ğ‘‹ğ‘› sono linearmente indipendenti anche le immagini ğ‘ƒğ‘‹1, â€¦ , ğ‘ƒğ‘‹ğ‘› sono linearmente
indipendenti, questi n vettori sono n-uple, essendo oggetti di â„ğ‘›, a questo punto vado a fare la
controimmagine nellâ€™isomorfismo coordinato a riferimento â„› di questi n vettori, vado praticamente a
prendere ğ¶â„›
âˆ’1(ğ‘ƒğ‘‹1) = ğ‘’1
â€² ,â€¦ , ğ¶â„›
âˆ’1(ğ‘ƒğ‘‹ğ‘›) = ğ‘’ğ‘›
â€² che costituiscono ancora a loro volta vettori indipendenti e
poichÃ© sono in numero pari alla dimensione dello spazio vettoriale questi vettori formano una base, quindi
36

posso ordinarli secondo i loro pedici e quindi avrÃ² effettivamente il riferimento â„›â€² = (ğ‘’1
â€² ,â€¦ , ğ‘’ğ‘›
â€² ). Prendiamo
ora la matrice di passaggio ğµ da â„›â€² ad â„›, quello che succede (secondo quanto visto nella dimostrazione del
teorema delle matrici simili) Ã¨ che la matrice ğµâˆ’1ğ´ğµ = ğ´â€², di conseguenza se dimostriamo che ğµ = ğ‘ƒ
avremmo dimostrato che ğ´â€² = ğ‘€â„›â€²(ğ‘“) âˆ¼ ğ‘€â„›(ğ‘“) = ğ´ e quindi la proposizione. La matrice di passaggio si
costruisce per colonne quindi osserviamo la prima colonna di ğµ, ovvero ğ¶â„›(ğ‘’1
â€²) = ğ‘ƒğ‘‹1 = ğ‘ƒ (
( \
\)
1
0
â‹®
0
),
proseguendo per le restanti colonne troveremo che tutte le colonne di ğµ coincidono a tutte le colonne di ğ‘ƒ,
e cioÃ¨ che ğµ = ğ‘ƒ e quindi ğ´â€² = ğ·.
Corollario: Se ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› Ã¨ un endomorfismo diagonalizzabile nel riferimento â„› allora anche la matrice
associata lo Ã¨ (quindi la diagonalizzabilitÃ  di un endomorfismo puÃ² essere visto con la diagonalizzabilitÃ  di
ğ‘€â„›(ğ‘“), questo corollario mette praticamente insieme le due proposizioni precedenti).
Esempio: Sia ğ´ = (
1 0 0
0 2 0
0 0 3
) una matrice diagonale e sia ğ¹ğ´: ğ‘‹ âˆˆ â„3 â†¦ ğ´ğ‘‹ âˆˆ â„3 endomorfismo, esso Ã¨
diagonalizzabile poichÃ© nel riferimento naturale la matrice associata ad ğ¹ğ´ Ã¨ proprio ğ´. Un altro esempio Ã¨
dato dallâ€™endomorfismo identico (idğ‘‰) che Ã¨ banalmente diagonalizzabile poichÃ© in un qualunque riferimento
la matrice associata ğ‘€â„›(idğ‘‰) = ğ¼ğ‘› che Ã¨ una matrice per sua natura diagonale. Anche lâ€™endomorfismo nullo
Ã¨ diagonalizzabile poichÃ© in qualunque riferimento la matrice associata Ã¨ la matrice nulla (che Ã¨ diagonale).
Definizione pratica: Sia ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› un endomorfismo allora un certo elemento ğ‘£ âˆˆ ğ‘‰ğ‘› si dice autovettore di
autovalore ğ€ (numero reale) se e solo se ğ‘£ â‰  0 e ğ‘“(ğ‘£) = ğœ†ğ‘£.
Proposizione (Il concetto di autovettore e autovalore Ã¨ ben definito): Se ğ‘£ Ã¨ un autovettore di autovalori ğœ†1
e ğœ†2 allora ğœ†1 = ğœ†2 (un autovettore puÃ² avere un unico e solo autovalore).
Dimostrazione: ğ‘“(ğ‘£) = ğœ†1ğ‘£ essendo autovettore di autovalore ğœ†1, ma anche autovalore ğœ†2 quindi ğ‘“(ğ‘£) =
ğœ†1ğ‘£ = ğœ†2ğ‘£ â‡’ (ğœ†1 âˆ’ ğœ†2)ğ‘£ = 0 â‡’ ğœ†1 âˆ’ ğœ†2 = 0 â‡’ ğœ†1 = ğœ†2 poichÃ© ğ‘£ â‰  0 per definizione.
Teorema: un endomorfismo lineare ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› Ã¨ diagonalizzabile â‡” esiste una base formata da autovettori
(rapporto preliminare tra diagonalizzabilitÃ  ed esistenza degli autovettori).
Dimostrazione: cominciamo col dimostrare che se ğ‘“ Ã¨ diagonalizzabile allora esiste una base di autovettori.
ğ‘“ Ã¨ diagonalizzabile significa che esiste un riferimento in cui la matrice Ã¨ diagonale, supponiamo che â„› =
(ğ‘’1,â€¦ , ğ‘’ğ‘›) sia il riferimento per cui ğ‘€â„›(ğ‘“) = (
ğ‘1 0 â€¦
0
â‹®
0
ğ‘2
â‹±
0
â‹®
0
â€¦ 0 ğ‘ğ‘›
), scriviamo le immagini del riferimento
come combinazione lineare delle colonne, ovvero ğ‘“(ğ‘’1) = ğ‘1ğ‘’1 + 0ğ‘’2 +â‹¯+ 0ğ‘’ğ‘› = ğ‘1ğ‘’1,â€¦ , ğ‘“(ğ‘’ğ‘›) = ğ‘ğ‘›ğ‘’ğ‘›
questo significa che ğ‘’1 Ã¨ un autovettore poichÃ© ğ‘’1 Ã¨ non nullo e la sua immagine Ã¨ proporzionale a se stesso,
allo stesso modo ğ‘’2,â€¦ , ğ‘’ğ‘› sono autovettori e dunque il riferimento â„› Ã¨ formata da autovettori e quindi esiste
effettivamente una base formata da autovettori e la base in questione Ã¨ proprio quella data dal riferimento
in cui la funzione ha una matrice associata diagonale. Resta da dimostrare lâ€™altra implicazione: sia â„› =
(ğ‘’1,â€¦ , ğ‘’ğ‘›) con ğ‘’1,â€¦ , ğ‘’ğ‘› autovettori, questo vuol dire che
âˆƒğœ†1 âˆˆ â„ âˆ¶ ğ‘“(ğ‘’1) = ğœ†1ğ‘’1
â‹®
âˆƒğœ†ğ‘› âˆˆ â„ âˆ¶ ğ‘“(ğ‘’ğ‘›) = ğœ†ğ‘›ğ‘’ğ‘›
sono gli autovettori a non dover essere nulli, non gli autovalori), di conseguenza la matrice associata ad ğ‘“ nel
riferimento â„› Ã¨ ğ‘€â„›(ğ‘“) = (
ğœ†1 0 â€¦
0
â‹®
0
ğœ†2
â‹±
0
â‹®
0
â€¦ 0 ğœ†ğ‘›
).
37
(si tenga presente che

Proposizione: prendiamo un endomorfismo ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› e fissiamone un riferimento â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘›) con
ğ‘€â„›(ğ‘“) = ğ´ = (ğ‘ğ‘–ğ‘—) allora esiste un autovettore che ammette â„ come autovalore se e solamente se
det(ğ´ âˆ’ â„ğ¼ğ‘›) = 0 (quindi per poter trovare gli autovalori bisogna risolvere lâ€™equazione caratteristica ).
ğ‘£ Ã¨ autovettore di ğ‘“ â‡” ğ‘‹ = ğ¶â„›(ğ‘£) Ã¨ una soluzione non banale dellâ€™equazione matriciale (ğ´ âˆ’ â„ğ¼ğ‘›)ğ‘‹ = 0.
Dimostrazione: â„ Ã¨ un autovalore significa che esiste un ğ‘£ â‰  0 tale che ğ‘“(ğ‘£) = â„ğ‘£, in termini di coordinate
il tutto si traduce nel seguente modo: esiste un ğ‘ = ğ¶â„›(ğ‘£) â‰  0 tale che ğ´ğ‘ = â„ğ‘, dove ğ‘ sono le componenti
di ğ‘£. Ma allora ğ´ğ‘ = â„ğ‘ â‡’ ğ´ğ‘ âˆ’ â„ğ¼ğ‘›ğ‘ = 0 â‡’ (ğ´ âˆ’ â„ğ¼ğ‘›)ğ‘ = 0, abbiamo cosÃ¬ trovato che â„ Ã¨ una autovalore
se e solamente se esiste un ğ‘£ le cui componenti sono diverse da zero e soddisfano lâ€™equazione (ğ´ âˆ’ â„ğ¼ğ‘›).
Si osservi lâ€™equazione (ğ´ âˆ’ â„ğ¼ğ‘›)ğ‘‹ = 0, dove ğ‘‹ Ã¨ una colonna di incognite che ha 2 soluzioni (matrice nulla o
ğ‘) ma questo significa che il sistema di equazione omogeneo ha âˆ soluzioni per i sistemi di equazioni (che
ha una, nessuna o infinite soluzioni). A questo punto si puÃ² assumere che il rango di ğ´ âˆ’ â„ğ¼ğ‘› non Ã¨ massimo
(avendo infinite soluzioni) e quindi il det(ğ´ âˆ’ â„ğ¼ğ‘›) = 0. Abbiamo cosÃ¬ dimostrato entrambe le proposizioni
poichÃ© sostanzialmente le implicazioni scritte sopra sono in realtÃ  equivalenze.
Definizione: sia â„ autovalore dellâ€™endomorfismo ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› definisco come autospazio relativo ad ğ’‰ e lo
denoto ğ‘‰(â„) = {ğ‘£ âˆˆ ğ‘‰ğ‘›|ğ‘“(ğ‘£) = â„(ğ‘£)} (non necessariamente ğ‘£ deve essere non nullo).
Proposizioni:
1) ğ‘‰(â„) â‰¤ ğ‘‰ğ‘› e dimğ‘‰(â„) â‰¥ 1
Dim.: se â„ Ã¨ un autovalore vuol dire che esiste un vettore non nullo ğ‘£ âˆˆ ğ‘‰(â„), di conseguenza ğ‘‰(â„) â‰  âˆ…
e la dimensione Ã¨ maggiore o uguale ad uno poichÃ© câ€™Ã¨ almeno un vettore non nullo, resta da dimostrare
che ğ‘‰(â„) sia sottospazio vettoriale e che quindi sia stabile rispetto al somma e il prodotto: siano ğ‘£, ğ‘¤ âˆˆ
ğ‘‰(â„) allora ğ‘“(ğ‘£) = â„ğ‘£ e ğ‘“(ğ‘¤) = â„ğ‘¤ (il fatto che siano autovettori o meno non Ã¨ rilevante) ne consegue
ğ‘“(ğ‘£ + ğ‘¤) = ğ‘“(ğ‘£) + ğ‘“(ğ‘¤) = â„ğ‘£ + â„ğ‘¤ = â„(ğ‘£ + ğ‘¤). Ragionamento analogo per il prodotto, sia ğœ† âˆˆ â„ si
ha ğ‘“(ğœ†ğ‘£) = ğœ† â‹… ğ‘“(ğ‘£) = ğœ† â‹… (â„ğ‘£) = â„ â‹… (ğœ†ğ‘£).
2) Lâ€™autospazio Ã¨ isomorfo: ğ‘‰(â„) â‰ƒ {ğ‘‹|(ğ´ âˆ’ â„ğ¼ğ‘›)ğ‘‹ = 0} = ğ‘†
Dim.: Basta considerare la coordinazione associata e ridurre il domino allâ€™autospazio, cosÃ¬ posso
prenderne le componenti che per la proposizione precedente devono appartenere allâ€™insieme delle
soluzioni ğ‘†, in simboli ğ‘£ âˆˆ ğ‘‰(â„) â†¦ ğ¶â„›(ğ‘£) âˆˆ ğ‘†. Viceversa, se prendo un elemento di ğ‘†: se Ã¨ nullo allora
appartiene a ğ‘‰(â„), altrimenti Ã¨ un autovettore e allora sempre per la proposizione precedente posso
trovare un vettore appartenente allâ€™autospazio che abbia quelle immagini.
3) Lâ€™intersezione di due autospazi con autovalori diversi Ã¨ triviale (cioÃ¨ fa il singleton dellâ€™elemento neutro):
ğ‘‰(â„) âˆ© ğ‘‰(ğ‘˜) = {0} se â„ â‰  ğ‘˜ (in particolare vuol dire che i due sottospazi sono in somma diretta)
Dim.: Prendiamo un qualunque vettore ğ‘£ âˆˆ ğ‘‰(â„) âˆ© ğ‘‰(ğ‘˜) e supponiamo che sia diverso dal vettore nullo,
quindi Ã¨ sia autovettore di autovalore â„ che autovettore di autovalore ğ‘˜, ma poichÃ© un autovettore puÃ²
avere un unico e solo autovalore si arriverebbe allâ€™assurdo che â„ = ğ‘˜, di conseguenza ğ‘£ = 0
4) Autospazi relativi ad autovalori distinti ğ‘‰(â„1),â€¦ , ğ‘‰(â„ğ‘¡) con â„ğ‘– â‰  â„ğ‘— sono in somma diretta
Dim. per induzione: ğ‘¡ = 2 Ã¨ vera per la proposizione precedente, supposta vera per ğ‘¡ âˆ’ 1 dimostriamo
che lâ€™intersezione di un sottospazio con il sottospazio generato da tutti gli altri sia triviale: ğ‘£ âˆˆ ğ‘‰(â„1) âˆ©
âŒ©ğ‘‰(â„2), â€¦ , ğ‘‰(â„ğ‘¡)âŒª ma âŒ©ğ‘‰(â„2),â€¦ , ğ‘‰(â„ğ‘¡)âŒª significa che ğ‘‰(â„2)â¨â€¦â¨ğ‘‰(â„ğ‘¡), allora per ğ‘£ so che ğ‘“(ğ‘£) = â„1ğ‘£
poichÃ© appartiene a ğ‘‰(â„1), ma so anche che appartiene al sottospazio generato dai ğ‘¡ âˆ’ 1 rimanenti e
quindi posso scriverlo come ğ‘£ = ğ‘£2 +â‹¯+ ğ‘£ğ‘¡ e quindi ğ‘“(ğ‘£) = ğ‘“(ğ‘£2) +â‹¯+ ğ‘“(ğ‘£ğ‘¡) ma essendo ğ‘“(ğ‘£2)
oggetto di ğ‘‰(â„2) posso scriverlo ğ‘“(ğ‘£2) = â„2ğ‘£2â€¦ allora ğ‘“(ğ‘£) = â„2ğ‘£2 +â‹¯+ â„ğ‘¡ğ‘£ğ‘¡ ma Ã¨ anche vero che
posso scrivere ğ‘“(ğ‘£) = â„1ğ‘£2 +â‹¯+ â„1ğ‘£ğ‘¡ di conseguenza â„1 = â„2,â€¦ , â„1 = â„ğ‘¡ (essendoci lâ€™unicitÃ  di
scrittura per la somma diretta) ma questo contraddice lâ€™ipotesi che gli autovalori siano tutti distinti.
5) Autovettori di autovalori distinti sono indipendenti
Dim.: Siano ğœ†1,â€¦ , ğœ†ğ‘¡ autovalori degli autovettori ğ‘£1, â€¦ , ğ‘£ğ‘¡, rispettivamente; supponiamo per assurdo che
gli autovettori non siano indipendenti, cioÃ¨ ad esempio ğ‘£1 âˆˆ âŒ©ğ‘£2,â€¦ , ğ‘£ğ‘¡âŒª ma questo significa che ğ‘‰(ğœ†1) âˆ©
38

âŒ©ğ‘‰(ğœ†2),â€¦ , ğ‘‰(ğœ†ğ‘¡)âŒª â‰  {0}, e ciÃ² contraddice lâ€™ipotesi che i vettori siano in somma diretta per la proprietÃ 
precedente.
Corollario: Se lâ€™equazione caratteristica di un endomorfismo ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› ha ğ‘› radici (numero massimo) reali e
distinte allora ğ‘“ Ã¨ diagonalizzabile (lâ€™altra implicazione non sussiste).
Dimostrazione: Se ha ğ‘› radici reali e distinte significa che ciascuna di queste radici per il polinomio
caratteristico Ã¨ un autovalore, e dunque esistono ğ‘› autovalori ğœ†1,â€¦ , ğœ†ğ‘›. Di questi autovalori vado a prendere
uno degli autovettori corrispondenti che lo caratterizzano, supponiamo siano ğ‘£1,â€¦ , ğ‘£ğ‘›. Questi vettori,
essendo autovettori di autovalori distinti, sono linearmente indipendenti, di conseguenza sono una base di
ğ‘‰ğ‘›, ma per un teorema precedente se esiste una base formata da autovettori allora ğ‘“ Ã¨ diagonalizzabile.
Alcune definizioni:
â€¢ MolteplicitÃ  algebrica: sia ğ‘(ğ‘¥) = ğ‘ğ‘›ğ‘¥ğ‘› + ğ‘ğ‘›âˆ’1ğ‘¥ğ‘›âˆ’1 +â‹¯+ ğ‘1ğ‘¥ + ğ‘0 = 0 un polinomio esso ha sempre
nel campo dei numeri complessi â„‚ al piÃ¹ ğ‘› soluzioni. Allora posso fattorizzare questo polinomi nel
seguente modo: (ğ‘¥ âˆ’ ğ›¼1)ğ‘›ğ›¼1 â‹… â€¦ â‹… (ğ‘¥ âˆ’ ğ›¼ğ‘¡)ğ‘›ğ›¼ğ‘¡ dove ğ‘›ğ›¼ğ‘– Ã¨ la molteplicitÃ  algebrica della radice ğ›¼ğ‘¡. Inoltre,
gli ğ›¼ğ‘– sono tutte e sole le soluzioni del polinomio in questione. ğ‘¡ â‰¤ ğ‘› succede che la molteplicitÃ  algebrica
delle soluzioni ğ‘›ğ›¼1 +â‹¯+ ğ‘›ğ›¼ğ‘¡ = ğ‘›.
â€¢ MolteplicitÃ  geometrica: Sia ğ‘‰(â„) un autospazio relativo ad â„; dimğ‘‰(â„) Ã¨ detta molteplicitÃ  geometrica
di â„, in simboli ğ‘šğ‘”(â„)
â€¢ La molteplicitÃ  algebrica di un autovalore â„ Ã¨ ğ‘šğ‘(â„) ed Ã¨ pari alla ğ‘šğ‘(â„) in det(ğ´ âˆ’ ğ‘¡ğ¼ğ‘›) = 0
Proposizione: ğ‘šğ‘”(â„) â‰¤ ğ‘šğ‘(â„)
Dimostrazione: Prendiamo una base per ğ‘‰(â„) = ğ‘’1,â€¦ , ğ‘’ğ‘¡ con ğ‘¡ = ğ‘šğ‘”(â„) per definizione, allora completiamo
ad una base di ğ‘‰ğ‘›: ğ‘’1,â€¦ , ğ‘’ğ‘¡, ğ‘’ğ‘¡+1,â€¦ , ğ‘’ğ‘› e ne prendo il riferimento corrispondente â„› = (ğ‘’1,â€¦ , ğ‘’ğ‘¡, ğ‘’ğ‘¡+1,â€¦ , ğ‘’ğ‘›)
e vado a calcolare la matrice associata al riferimento:
fa st â€œ|14-45, (a)Sut 5
sche)
bem,LO)
Corollario: Se ğ‘šğ‘(â„) = 1 â‡’ ğ‘šğ‘”(â„) = 1
Dimostrazione: Per definizione ğ‘šğ‘”(â„) â‰¥ 1, mentre per il teorema precedente ğ‘šğ‘”(â„) â‰¤ ğ‘šğ‘(â„) dunque
risulterÃ  1 â‰¤ ğ‘šğ‘”(â„) â‰¤ ğ‘šğ‘(â„) = 1
Teorema: Un endomorfismo ğ‘“: ğ‘‰ğ‘› â†’ ğ‘‰ğ‘› Ã¨ diagonalizzabile â‡” il polinomio caratteristico di ğ‘“ ha tutte le radici
in â„ (sono tutte radici reali) e per ogni radice â„ si ha che ğ‘šğ‘(â„) = ğ‘šğ‘”(â„).
Dimostrazione: â‡’: Essendo ğ‘“ diagonalizzabile âˆƒâ„› = (ğ‘’1, â€¦ , ğ‘’ğ‘›) di autovettori, non Ã¨ detto che questi vettori
siano autovettori di autovalori distinti, a tal proposito considero i vettori ordinati nel seguente modo:
âŒ©ğ‘’1,â€¦ , ğ‘’ğ‘–1âŒª â‰¤ ğ‘‰(ğœ†1),â€¦ , âŒ©ğ‘’ğ‘–ğ‘šâˆ’1+1,â€¦ , ğ‘’ğ‘–ğ‘›âŒª â‰¤ ğ‘‰(ğœ†ğ‘š) (praticamente metto vicini quelli con lo stesso
autovalore) cosÃ¬ facendo so che ğ‘‰(ğœ†1)â¨â€¦â¨ğ‘‰(ğœ†ğ‘š) = ğ‘‰ poichÃ© questi sottospazi contengono delle basi di ğ‘‰
e ciÃ² vuol dire che âŒ©ğ‘’1,â€¦ , ğ‘’ğ‘–1âŒª = ğ‘‰(ğœ†1),â€¦ , âŒ©ğ‘’ğ‘–ğ‘šâˆ’1+1,â€¦ , ğ‘’ğ‘–ğ‘›âŒª = ğ‘‰(ğœ†ğ‘š) altrimenti si arriverebbe allâ€™assurdo
che V appartenga ad un suo sottospazio proprio. Grazie allâ€™uguaglianza possiamo calcolarci la molteplicitÃ 
geometrica degli autovalori: ğ‘šğ‘”(ğœ†1) = ğ‘–1,â€¦ , ğ‘šğ‘”(ğœ†ğ‘š) = ğ‘› âˆ’ ğ‘–ğ‘šâˆ’1. A questo punto, computata la
molteplicitÃ  algebrica, andiamo a computare il polinomio caratteristico, riprendiamo il riferimento di
autovettore e prendiamo la matrice associata al riferimento (vedi immagine in seguito).
39

Esplicitando ogni volta il polinomio caratteristico avremo il seguente
determinante: det = (ğœ†1 âˆ’ ğ‘¥)ğ‘–1 â‹… â€¦ â‹… (ğœ†ğ‘š âˆ’ ğ‘¥)ğ‘›âˆ’ğ‘–ğ‘šâˆ’1 , questo non solo ci
dice che il polinomio caratteristico visto che si decompone in polinomi di primo
grado ha tutte radici reali ma anche che ğ‘šğ‘(ğœ†1) = ğ‘–1,â€¦ , ğ‘šğ‘(ğœ†ğ‘š) = ğ‘› âˆ’ ğ‘–ğ‘šâˆ’1.
â‡: scriviamoci il polinomio caratteristico ğ‘(ğ‘¥) = (ğ‘¥ âˆ’ ğœ†1)ğ‘›1 â‹… â€¦ â‹… (ğ‘¥ âˆ’ ğœ†ğ‘¡)ğ‘›ğ‘¡,
poichÃ© ha tutte le radici in â„ il polinomio si puÃ² decomporre nel prodotto di
polinomi di primo grado (a meno del segno); inoltre il prodotto di polinomi ha
come grado la somma dei gradi e quindi ğ‘›1 +â‹¯+ ğ‘›ğ‘¡ = ğ‘›, sapendo poi che per ogni radice dellâ€™equazione
caratteristica (per ipotesi) deve succedere che la molteplicitÃ  geometrica Ã¨ uguale a quella algebrica, dunque:
ğ‘›1 = ğ‘šğ‘”(ğœ†1),â€¦ , ğ‘›ğ‘¡ = ğ‘šğ‘”(ğœ†ğ‘¡). Andiamo ad analizzare la somma diretta degli autospazi relativi allâ€™autovalore
ğœ†ğ‘–: ğ‘‰(ğœ†1)â¨â€¦â¨ğ‘‰(ğœ†ğ‘¡) che ha dimensione ğ‘› (corollario della relazione di Grassmann) e allora essendo
ğ‘‰(ğœ†1)â¨â€¦â¨ğ‘‰(ğœ†ğ‘¡) â‰¤ ğ‘‰ si ha proprio ğ‘‰(ğœ†1)â¨â€¦â¨ğ‘‰(ğœ†ğ‘¡) = ğ‘‰. Bisogna ora dimostrare che il mio
endomorfismo sia diagonalizzabile, dunque mostriamo che esista una base di ğ‘‰ fatta di autovettori; per una
proprietÃ  della somma diretta (relazione di Grassmann per la somma diretta) prendiamo una base per ogni
autospazio e andiamo a farne lâ€™unione, questa sarÃ  una base per ğ‘‰ fatta di autovettori: ğµ1 âˆª â€¦âˆª ğµğ‘¡ e a
questo punto per il criterio di diagonalizzabilitÃ  abbiamo terminato.
Diagonalizzazione di una matrice
Sia ğ´ âˆˆ â„ğ‘› noi sappiamo che ğ´ Ã¨ diagonalizzabile â‡” ğ¹ğ´ Ã¨ diagonalizzabile, i concetti di autovalore e
autovettore si trasportano per quanto riguarda la diagonalizzabilitÃ  per la matrice, definisco dunque
autovettore per ğ‘¨: ğ‘Œ âˆˆ â„ğ‘› â‰  0 âˆ¶ ğ´ğ‘Œ = â„ğ‘Œ con ğ‘Œ colonna o riga e â„ autovalore corrispondente. Invece con
autospazio si intende ğ‘‰(â„) = {ğ‘‹ âˆˆ â„ğ‘›|ğ´ğ‘‹ = â„ğ‘‹}.
Supponiamo che ğ´ sia diagonalizzabile, se ğ¹ğ´ Ã¨ diagonalizzabile (Ã¨ lo Ã¨ per la proprietÃ  di diagonalizzabilitÃ )
allora esiste un riferimento di autovettori per ğ¹ğ´: â„ğ‘› â†’ â„ğ‘›. Prendiamo un riferimento di autovettori â„› =
(ğ‘’1,â€¦ , ğ‘’ğ‘›), abbiamo quindi la matrice associata ğ‘€â„›(ğ¹ğ´) diagonale, dâ€™altro canto, come giÃ  osservato, nel
riferimento naturale ğ¹ğ´ ha come matrice associata al riferimento naturale proprio ğ´ = ğ‘€â„›nat(ğ¹ğ´). Di
conseguenza sappiamo che matrici associate a due riferimenti dello stesso endomorfismo sono simili, quindi
ğ‘€â„›(ğ¹ğ´) = ğ· âˆ¼ ğ´ = ğ‘€â„›nat(ğ¹ğ´), e questo vuol dire che esiste una matrice ğ‘ƒ invertibile tale che ğ‘ƒâˆ’1ğ´ğ‘ƒ = ğ·
dove ğ‘ƒ Ã¨ la matrice di passaggio da â„› â†’ â„›nat (abbiamo giÃ  visto in precedenza la possibilitÃ  di poter scegliere
ğ‘ƒ come matrice di passaggio). La matrice ğ‘ƒ sappiamo che Ã¨ fatta nel seguente modo (costruita per colonne):
Cy? 0 U9 o)++aa 0,0..,4)
Â©Qs
28 (4G-10) +.+ Car(8-. ,0,A)
Le colonne sono i componenti del vecchio nel nuovo, quindi quello che succede Ã¨ che, di fatto, ğ· Ã¨ la matrice
deli autovalori presi nellâ€™ordine.
Praticamente se noi troviamo le componenti degli autovettori nel riferimento naturale le possiamo mettere
nella matrice ğ‘ƒ e questa matrice realizza la diagonalizzazione.
Spazi Vettoriali: Prodotti diretti esterni
Vediamo di seguito un procedimento per la costruzione di ulteriori spazi vettoriali ed Ã¨ il concetto di prodotto
esterno. Il prodotto che fino ad ora avevamo visto Ã¨ il prodotto diretto interno (dove abbiamo giÃ  lo spazio
vettoriale e scrivevamo un prodotto diretto da qualcosa interno allo spazio vettoriale).
40

Il prodotto diretto esterno, invece, prende due spazi vettoriali e ne crea uno nuovo che viene poi ad essere
canonicamente somma diretta interna dei due â€œsottospaziâ€. Siano ğ‘‰, ğ‘Š spazi vettoriali arbitrari ne prendo il
prodotto cartesiano ğ‘‰ Ã— ğ‘Š = {(ğ‘£, ğ‘¤)|ğ‘£ âˆˆ ğ‘‰, ğ‘¤ âˆˆ ğ‘Š} che sarÃ  il nostro insieme sostegno, devo andarci a
definire una somma interna ed un prodotto esterno e li definisco nel seguente modo:
â€¢ +âˆ¶ (ğ‘‰ Ã— ğ‘Š) Ã— (ğ‘‰ Ã— ğ‘Š) â†’ ğ‘‰ Ã— ğ‘Š
((ğ‘£, ğ‘¤), (ğ‘£â€², ğ‘¤â€²)) â†¦ (ğ‘£ + ğ‘£â€², ğ‘¤ + ğ‘¤â€²)
â€¢ â‹… âˆ¶ â„ Ã— (ğ‘‰ Ã— ğ‘Š) â†’ ğ‘‰ Ã— ğ‘Š
(ğœ†, (ğ‘£, ğ‘¤)) â†¦ (ğœ†ğ‘£, ğœ†ğ‘¤)
Ãˆ banale vedere che la terna (ğ‘‰ Ã— ğ‘Š, +, â‹… ) Ã¨ spazio vettoriale (ovvero ne soddisfa gli assiomi). Esplicitiamo
a questo punte alcune cose:
â€¢ Elemento neutro sarÃ  la coppia (0, 0) con primo elemento appartenente a ğ‘‰ e secondo a ğ‘Š
â€¢ Lâ€™opposto di (ğ‘£, ğ‘¤) sarÃ  la coppia (âˆ’ğ‘£,âˆ’ğ‘¤)
Questo metodo di costruire spazi vettoriali crea uno spazio vettoriale piÃ¹ grande perchÃ© allâ€™interno ğ‘‰ Ã— ğ‘Š
contiene dei sottospazi vettoriali che sono da un lato isomorfi a ğ‘‰ e dallâ€™altro isomorfi a ğ‘Š. Sono inoltre
sottospazi canonici: ğ» = {(0, ğ‘¤)|ğ‘¤ âˆˆ ğ‘Š} e ğ¾ = {(ğ‘£, 0)|ğ‘£ âˆˆ ğ‘‰}, questi due sottospazi (Ã¨ semplice
dimostrare che siano sottospazi) hanno come intersezione la coppia (0, 0), quindi ğ» âˆ© ğ¾ = {(0, 0)}, quello
che andremo a vedere Ã¨ che ogni elemento del prodotto diretto ğ‘‰ Ã— ğ‘Š puÃ² essere scritto come somma di
un elemento di ğ» e un elemento di ğ¾, praticamente ğ‘‰ Ã— ğ‘Š âˆ‹ ğ‘¢ = (ğ‘£, ğ‘¤) = (ğ‘£, 0) + (0, ğ‘¤) e questo vuol
dire che ğ‘‰ Ã— ğ‘Š Ã¨ in realtÃ  somma diretta dei sottospazi ğ» e ğ¾. Ãˆ facile convincersi che ğ¾ Ã¨ isomorfo a ğ‘‰ e
che ğ» Ã¨ isomorfo a ğ‘Š, infatti ğ¾ â‰ƒ ğ‘‰ perchÃ© ğ‘£ âˆˆ ğ‘‰ â†’ (ğ‘£, 0) e analogamente ğ» â‰ƒ ğ‘Š perchÃ© ğ‘¤ âˆˆ ğ‘Š â†’ (0, ğ‘¤)
quindi possiamo dire che il prodotto diretto ha dimensione la somma delle dimensioni di ğ» e di ğ¾, poichÃ©
ğ‘‰ Ã— ğ‘Š = ğ»â¨ğ¾, ma essendo dimğ¾ = dimğ‘‰ e dimğ» = dimğ‘Š la dimensione del prodotto interno Ã¨ la
somma delle due dimensioni: dim(ğ‘‰ Ã— ğ‘Š) = dimğ‘‰ + dimğ‘Š.
7. Geometria
Spazio vettoriale dei vettori geometrici liberi dello spazio (e del piano)
Gli spazi vettoriali dei vettori geometrici liberi nello spazio (o piano) sono classi di equipollenza in cui figurano
tutti i vettori equipollenti ad un dato vettore geometrico. Prendiamo due vettori geometrici liberi non nulli
(ovvero diversi dal vettore triviale): ğ‘ = ğ´ğµ e ğ‘ = ğ¶ğ· dove ğ´ğµ e ğ¶ğ· sono segmenti generici (posso prendere
tutti i segmenti a loro equipollenti). Andiamo adesso a dare le seguenti proprietÃ :
â€¢ ğ‘ âˆ¥ ğ‘ â‡” ğ´ğµ e ğ¶ğ· (i segmenti corrispondenti che li rappresentano) sono paralleli
Verifichiamo che questa definizione sia ben posta (il che vuol dire che cambiando i rappresentanti i due
oggetti sono ancora paralleli tra loro): se prendo un vettore ğ´â€²ğµâ€² equipollente ad ğ´ğµ e un vettore ğ¶â€²ğ·â€²
equipollente a ğ¶ğ·, a causa della relazione di equipollenza trovo subito, sotto il punto di vista pratico, che
anche ğ´â€²ğµâ€² âˆ¥ ğ¶â€²ğ·â€².
In termini di spazi vettoriali fissiamo un punto ğ‘‚, allora possiamo prenderci dei rappresentati come segue:
ğ‘‚ğ´â€² âˆ¥ ğ´ğµ e ğ‘‚ğµâ€² âˆ¥ ğ¶ğ·, ora, poichÃ© la definizione precedente Ã¨ ben posta si ha che ğ‘ âˆ¥ ğ‘ â‡” ğ‘‚ğ´â€² e ğ‘‚ğµâ€² sono
paralleli, ciÃ² significa che i due segmenti oltre ad essere paralleli ed hanno un punto in comune giacciono
sulla stessa retta. Di conseguenza si puÃ² estendere la definizione
precedente in:
41

â€¢ ğ‘ âˆ¥ ğ‘ â‡” ğ‘‚ğ´â€² e ğ‘‚ğµâ€² sono paralleli â‡” ğ‘‚ğ´â€² e ğ‘‚ğµâ€² giacciono sulla stessa retta â‡” ğ‘‚ğ´â€² e ğ‘‚ğµâ€² sono
proporzionali â‡” ğ‘ e ğ‘ sono proporzionali â‡” ğ‘ e ğ‘ sono dipendenti (linearmente).
Il vettore nullo Ã¨ parallelo ad ogni vettore (per definizione), e questo implica, essendo un sistema contenente
il vettore nullo quasi per definizione dipendente, che:
â€¢ ğ‘ âˆ¥ ğ‘ â‡” ğ‘ e ğ‘ costituiscono un sistema linearmente dipendente
Siano ğ‘, ğ‘, ğ‘ âˆˆ ğ’± (dove ğ’± Ã¨ spazio, ma vale anche per il piano) e fissiamo un punto ğ‘‚, ğ‘ = ğ‘‚ğ´, ğ‘ = ğ‘‚ğµ, ğ‘ =
ğ‘‚ğ¶, allora:
â€¢ ğ‘, ğ‘, ğ‘ dipendenti â‡” ğ‘ = â„ğ‘ + ğ‘˜ğ‘ con â„, ğ‘˜ âˆˆ â„ â‡” ğ‘‚ğ´ = â„ğ‘‚ğµ + ğ‘˜ğ‘‚ğ¶ â‡” ğ‘‚ğ´, ğ‘‚ğµ, ğ‘‚ğ¶ sono contenuti in
uno stesso piano
Dalla penultima condizione possiamo dire due cose: o che i punti ğ‘‚, ğµ, ğ¶ sono allineati e quindi giacciono
sulla stessa retta, e per questa retta passante per i tre punti esiste una retta per cui passa ğ´, altrimenti,
se ğ‘‚, ğµ, ğ¶ non sono allineati significa che esiste un unico piano passante per ğ‘‚, ğµ, ğ¶ ed il punto ğ´ sta nel
piano identificato da ğ‘‚, ğµ, ğ¶. Il piano che contiene ğ‘‚, ğµ, ğ¶, ğ´ vale anche per il primo caso poichÃ© per una
retta passano infiniti piani.
Definizione: Siano ğ‘, ğ‘ âˆˆ ğ’± vettori geometrici liberi non nulli e fissiamo un punto ğ‘‚ allora ğ‘ = ğ‘‚ğ‘ƒ e ğ‘ = ğ‘‚ğ‘„
allora lâ€™angolo ğ‘^ğ‘ Ã¨ la misura in radianti dellâ€™angolo convesso (â‰¤ 180Â°) formato da ğ‘‚ğ‘ƒ e ğ‘‚ğ‘„ (si verifica
intuitivamente che la definizione Ã¨ ben posta).
Definizione (prodotto scalare standard tra due vettori geometrici liberi) ğ’± Ã— ğ’± â†’ â„:
â€¢ ğ‘£ â‹… ğ‘¤ = 0 se ğ‘£ = 0 o ğ‘¤ = 0
â€¢ ğ‘£ â‹… ğ‘¤ = |ğ‘£| â‹… |ğ‘¤| â‹… cos(ğ‘£^ğ‘¤) = |ğ‘¤| â‹… |ğ‘‚ğ»|
Questo prodotto gode delle seguenti proprietÃ :
1. Simmetria (commutativitÃ  per prodotti esterni) ğ‘£ â‹… ğ‘¤ = ğ‘¤ â‹… ğ‘£ dipende dal fatto che ğ‘£^ğ‘¤ = ğ‘¤^ğ‘£
(poichÃ© per definizione bisogna fare la misura in radianti dellâ€™angolo convesso)
2. BilinearitÃ  (â„ğ‘¢ + ğ‘˜ğ‘£)ğ‘¤ = â„(ğ‘¢ â‹… ğ‘¤) + ğ‘˜(ğ‘£ â‹… ğ‘¤) (dimostrazione geometrica, servono altre nozioni)
3. Definito positivo âˆ€ğ‘£ âˆˆ ğ’± ğ‘£ â‹… ğ‘£ â‰¥ 0 essendo ğ‘£ â‹… ğ‘£ = |ğ‘£| â‹… |ğ‘£| â‹… cos(ğ‘£^ğ‘£) = |ğ‘£|
2
ğ‘£ â‹… ğ‘£ = 0 âŸº ğ‘£ = 0 essendo ğ‘£ â‹… ğ‘£ = | ğ‘£| = 0 â‡” ğ‘£ = 0
2
Questo prodotto scalare standard ci permette di dire che ğ‘£ â‹… ğ‘£ = |ğ‘£| â‡’ |ğ‘£| = âˆšğ‘£ â‹… ğ‘£
2
Definizione: chiamerÃ² versore un vettore di lunghezza unitaria, ovvero un vettore il cui modulo Ã¨ pari ad uno.
Mentre con versore di una retta orientata indicherÃ² quel versore parallelo e concorde alla retta.
Vettori ortogonali: siano ğ‘ = ğ´ğµ e ğ‘ = ğ¶ğ· due vettori non nulli poniamo per definizione:
â€¢
ğ‘ âŠ¥ ğ‘ â‡” ğ¶ğ· âŠ¥ ğ´ğµ Ã¨ questa Ã¨ una definizione ben posta
â€¢ Fissato un punto ğ‘‚ avremo ğ‘ âŠ¥ ğ‘ â‡” ğ‘‚ğ´ âŠ¥ ğ‘‚ğµ â‡” ğœƒ = ğ‘^ğ‘ =
ğœ‹
2 â‡” cos ğœƒ = 0 â‡” ğ‘ â‹… ğ‘ = 0
Sempre per definizione si pone che il vettore nullo Ã¨ ortogonale ad ogni vettore; quindi, non Ã¨ necessario
prendere ğ‘ e ğ‘ non nulli per dire che ğ‘ â‹… ğ‘ = 0 â‡” ğ‘ âŠ¥ ğ‘ âˆ€ğ‘, ğ‘ âˆˆ ğ’±
Cominciamo ora con il ricordare che lo spazio vettoriale dei vettori geometrici liberi del piano ğ’±ğœ‹ ha
dimensione 2 mentre lo spazio vettoriale dei vettori geometrici liberi dello spazio ha dimğ’± = 3. E
generalizziamo questa osservazione dando la seguente definizione: Si dice riferimento ortonormale del
piano un riferimento in cui i vettori sono ortogonali quindi â„›ğœ‹ = (ğ‘£, ğ‘¤) con ğ‘£ â‹… ğ‘¤ = 0. Allo stesso modo il
riferimento ortonormale dello spazio Ã¨ â„› = (ğ‘£, ğ‘¤, ğ‘¢) con ğ‘£ â‹… ğ‘¤ = 0, ğ‘¤ â‹… ğ‘¢ = 0, ğ‘¢ â‹… ğ‘£ = 0. Sia per quanto
42

riguarda il piano che lo spazio, lâ€™altra condizione per essere un riferimento ortogonale Ã¨ che i vettori devono
essere versori. Per semplicitÃ  di notazione consideriamo un riferimento ortonormale del piano.
Proposizione: Se ğ‘, ğ‘ sono vettori geometrici del piano (ğ‘, ğ‘ âˆˆ ğ’±ğœ‹) e ğ‘ = ğ‘1ğ‘£ + ğ‘2ğ‘¤, ğ‘ = ğ‘1ğ‘£ + ğ‘2ğ‘¤ (ovvero
scritti come combinazione lineare del riferimento â„›ğœ‹) allora ğ‘ â‹… ğ‘ = ğ‘1ğ‘1 + ğ‘2ğ‘2 = (ğ‘1, ğ‘2) â‹… (ğ‘1, ğ‘2).
Dimostrazione: applichiamo al prodotto scalare standard la sua proprietÃ  di essere bilineare e simmetrico:
ğ‘ â‹… ğ‘ = (ğ‘1ğ‘£ + ğ‘2ğ‘¤) â‹… (ğ‘1ğ‘£ + ğ‘2ğ‘¤) = ğ‘1ğ‘1(ğ‘£ â‹… ğ‘£) + ğ‘1ğ‘2(ğ‘£ â‹… ğ‘¤) + ğ‘2ğ‘1(ğ‘¤ â‹… ğ‘£) + ğ‘2ğ‘2(ğ‘¤ â‹… ğ‘¤) essendo ğ‘£
e ğ‘¤ versori ortogonali si ha che (ğ‘£ â‹… ğ‘£) = 1, (ğ‘¤ â‹… ğ‘¤) = 1, (ğ‘£ â‹… ğ‘¤) = 0 e (ğ‘¤ â‹… ğ‘£) = 0, da cui la tesi.
Corollario: Se esprimo ğ‘£ come ğ¶â„›(ğ‘£) = (ğ‘, ğ‘) avrÃ² |ğ‘£| = âˆšğ‘£ â‹… ğ‘£ = âˆšğ‘2 + ğ‘2, considerazioni del tutto
analoghe (anche per la proposizione precedente) si attuano nello spazio: |ğ‘£| = âˆšğ‘2 + ğ‘2 + ğ‘2 esprimendo
ğ‘£ come ğ¶â„›(ğ‘£) = (ğ‘, ğ‘, ğ‘).
Definizione: definisco riferimento cartesiano ortogonale monometrico una coppia che ha come primo
oggetto un punto detto origine e secondo oggetto una coppia (se si parla di spazio sarÃ  una terna), in
particolare un riferimento ortonormale del piano: â„› = (ğ‘‚, (ğ‘’ğ‘¥, ğ‘’ğ‘¦)).
Essendo ğ‘’ğ‘¥ un versore e quindi un vettore geometrico libero ne posso prendere un segmento che rappresenti
il vettore, ad esempio ğ‘‚ğ‘ˆ = ğ‘’ğ‘¥, allo stesso modo ğ‘‚ğ‘ˆâ€² = ğ‘’ğ‘¦, i punti ğ‘ˆ, ğ‘ˆâ€² sono detti punti unitari. Mentre le
rette passanti per ğ‘‚ğ‘ˆ e ğ‘‚ğ‘ˆâ€² sono detti assi coordinati (praticamente lâ€™asse ğ‘¥ e lâ€™asse ğ‘¦). Di seguito diamo la
rappresentazione delle rette orientate concordemente ai versori e calcolo di un punto ğ‘ƒ tramite proiezioni:
Con ovviamente i punti particolari con coordinate:
ğ‘‚(0,0)
ğ‘ˆ(1,0)
ğ‘ˆâ€²(0,1)
Proposizione: dati due punti ğ´(ğ‘¥1, ğ‘¦1) e ğµ(ğ‘¥2, ğ‘¦2), le componenti del vettore ğ´ğµ (la classe di equipollenza
dei vettori equipollenti del vettore geometrico di punto iniziale ğ´ e finale ğµ) sono ğ‘¥2 âˆ’ ğ‘¥1 e ğ‘¦2 âˆ’ ğ‘¦1.
Dimostrazione: iniziamo con lâ€™osservare che per la regola del parallelogrammo ğ‘‚ğ´ + ğ´ğµ = ğ‘‚ğµ (vedi sotto),
ed essendo questi vettori geometrici liberi posso estrapolare ğ´ğµ = ğ‘‚ğµ âˆ’ ğ‘‚ğ´
e da questa relazione applichiamo lâ€™isomorfismo coordinato che ci dice che le
componenti di ğ´ğµ saranno uguali alle componenti di ğ‘‚ğµ meno le componenti
di ğ‘‚ğ´, dunque chiamiamo le componenti incognite di ğ´ğµ come (ğ‘¥, ğ‘¦), mentre le
componenti di ğ‘‚ğ´ ed ğ‘‚ğµ sono per definizione (ğ‘¥1, ğ‘¦1) e (ğ‘¥2, ğ‘¦2) rispettivamente. Allora ciÃ² vuol dire che la
coppia (ğ‘¥, ğ‘¦) = (ğ‘¥1, ğ‘¦1) âˆ’ (ğ‘¥2, ğ‘¦2) = (ğ‘¥2 âˆ’ ğ‘¥1, ğ‘¦2 âˆ’ ğ‘¦1), come volevasi dimostrare.
Spesso denoteremo ğ´ğµ(ğ‘¥2 âˆ’ ğ‘¥1, ğ‘¦2 âˆ’ ğ‘¦1) direttamente con le componenti come facciamo con i punti, ma
questa definizione (per la precedente proposizione) non Ã¨ ambigua infatti ğ‘‚ğ‘ƒ(ğ‘, ğ‘) â‰¡ ğ‘ƒ(ğ‘, ğ‘).
Prendiamo due vettori geometrici liberi ğ‘£(ğ‘£ğ‘¥, ğ‘£ğ‘¦) e ğ‘¤(ğ‘¤ğ‘¥, ğ‘¤ğ‘¦) diversi dal vettore nullo, allora:
ğ‘£ â‹… ğ‘¤
cos ğ‘£^ğ‘¤ =
=
|ğ‘£| â‹… |ğ‘¤|
âˆšğ‘£ğ‘¥
2 + ğ‘£ğ‘¦
2 â‹… âˆšğ‘¤ğ‘¥
2 + ğ‘¤ğ‘¦
2
ğ‘£ğ‘¥ğ‘¤ğ‘¥ + ğ‘£ğ‘¦ğ‘¤ğ‘¦
cos ğ‘£^ğ‘’ğ‘¥ =
ğ‘£ğ‘¥
âˆšğ‘£ğ‘¥
2 + ğ‘£ğ‘¦
2
cos ğ‘£^ğ‘’ğ‘¦ =
ğ‘£ğ‘¦
âˆšğ‘£ğ‘¥
2 + ğ‘£ğ‘¦
2
43

Cambiamenti di riferimento
Se dati due riferimenti cartesiani ortogonali monometrici â„› = (ğ‘‚, (ğ‘’ğ‘¥, ğ‘’ğ‘¦)), â„›â€² = (ğ‘‚â€², (ğ‘’ğ‘¥
â€² , ğ‘’ğ‘¦
â€² )) voglio
passare dalle coordinate di un punto ğ‘ƒ in â„› alle coordinate in â„›â€² si usa il seguente metodo.
Diciamo che il punto ğ‘ƒ abbia coordinate (ğ‘¥, ğ‘¦) in â„› e coordinate (ğ‘¥â€², ğ‘¦â€²) in â„›â€² e noi vogliamo trovare delle
formule che ci permettono di passare da (ğ‘¥, ğ‘¦) a (ğ‘¥â€², ğ‘¦â€²). Per poter fare questa cosa ci viene in aiuto la
matrice di passaggio da un riferimento ad un altro, in particolare dal riferimento (ğ‘’ğ‘¥, ğ‘’ğ‘¦) al riferimento
(ğ‘’ğ‘¥
â€² , ğ‘’ğ‘¦
â€² ), ovvero la matrice ğµ = (
ğ‘11 ğ‘12
ğ‘21 ğ‘22
) e quindi (proprietÃ  della matrice di passaggio) se moltiplichiamo
a destra la colonna delle componenti di un vettore nel vecchio riferimento otteniamo la colonna delle
componenti nel nuovo riferimento.
Riprendiamo le coordinate nel punto ğ‘ƒ che, come ben sappiamo, per definizione sono le componenti del
vettore geometrico libero ğ‘‚ğ‘ƒ e ğ‘‚â€²ğ‘ƒ, rispettivamente per (ğ‘¥, ğ‘¦) e (ğ‘¥â€², ğ‘¦â€²), e andiamo a definire anche le
coordinate delle origini dei riferimenti. Per il punto ğ‘‚ Ã¨ (0,0) mentre per ğ‘‚â€², essendo traslato rispetto
allâ€™origine, chiamiamole (ğ‘1, ğ‘2), una volta conosciute le coordinate di ğ‘‚ e ğ‘ƒ, per un lemma visto in
precedenza, si conoscono anche le coordinate di ğ‘‚ğ‘ƒ ovvero (ğ‘¥, ğ‘¦), mentre ğ‘‚â€²ğ‘ƒ(ğ‘¥â€² âˆ’ ğ‘1, ğ‘¦â€² âˆ’ ğ‘2).
A questo punto utilizziamo la matrice di passaggio moltiplicandola a sinistra della colonna delle componenti
del vettore ğ‘‚ğ‘ƒ nel riferimento che sottende â„›, risulteranno le componenti dello stesso vettore nel
riferimento che sottende ğ‘…â€² quindi ğµ (
ğ‘¥
ğ‘¦) = (
ğ‘¥â€² âˆ’ ğ‘1
ğ‘¦â€² âˆ’ ğ‘2
) â‡’ {
ğ‘¥â€² âˆ’ ğ‘1 = ğ‘11ğ‘¥ + ğ‘12ğ‘¦
ğ‘¦â€² âˆ’ ğ‘2 = ğ‘21ğ‘¥ + ğ‘22ğ‘¦
, a questo sistema
esplicitando le coordinate dei punti ğ‘¥â€² e ğ‘¦â€² in termini di coordinate di ğ‘ƒ nel riferimento â„› otterremo il
seguente sistema: {
ğ‘¥â€² = ğ‘11ğ‘¥ + ğ‘12ğ‘¦ + ğ‘1
ğ‘¦â€² = ğ‘21ğ‘¥ + ğ‘22ğ‘¦ + ğ‘2
che sono le formule di passaggio da ğ“¡ a ğ“¡â€².
Prodotto vettoriale
Definiamo il prodotte vettoriale nello spazio (non Ã¨ possibile definirlo con il piano): prendo un riferimento
cartesiano ortogonale monometrico â„› = (ğ‘‚, â„›ğ’± = (ğ‘’ğ‘¥, ğ‘’ğ‘¦, ğ‘’ğ‘§)) e due vettori: ğ‘£(ğ‘£ğ‘¥, ğ‘£ğ‘¦, ğ‘£ğ‘§) = ğ‘£ğ‘¥ğ‘’ğ‘¥ +
ğ‘£ğ‘¦ğ‘’ğ‘¦ + ğ‘£ğ‘§ğ‘’ğ‘§ e ğ‘¤(ğ‘¤ğ‘¥, ğ‘¤ğ‘¦, ğ‘¤ğ‘§) = ğ‘¤ğ‘¥ğ‘’ğ‘¥ + ğ‘¤ğ‘¦ğ‘’ğ‘¦ + ğ‘¤ğ‘§ğ‘’ğ‘§. Allora il prodotto vettoriale ğ‘£ Ã— ğ‘¤ Ã¨ per definizione
ğ‘’ğ‘¥
ğ‘£ Ã— ğ‘¤ = |ğ‘£ğ‘¥
ğ‘’ğ‘¦
ğ‘£ğ‘¦
ğ‘’ğ‘§
ğ‘¤ğ‘¥ ğ‘¤ğ‘¦ ğ‘¤ğ‘§
ğ‘£ğ‘§ | = (ğ‘£ğ‘¦ğ‘¤ğ‘§ âˆ’ ğ‘¤ğ‘¦ğ‘£ğ‘§)ğ‘’ğ‘¥ âˆ’ (ğ‘£ğ‘¥ğ‘¤ğ‘§ âˆ’ ğ‘£ğ‘§ğ‘¤ğ‘¥)ğ‘’ğ‘¦ + (ğ‘£ğ‘¥ğ‘¤ğ‘¦ âˆ’ ğ‘¤ğ‘¥ğ‘£ğ‘¦)ğ‘’ğ‘§
sviluppato per la prima riga).
Esempio: ğ‘£(1,0,1), ğ‘¤(2,2,0)
ğ‘£ Ã— ğ‘¤ = |
ğ‘’ğ‘¥
ğ‘’ğ‘¦
ğ‘’ğ‘§
1 0 1
2 2 0
| = (|0 1
2 0
| , âˆ’ |1 1
2 0
| , |1 0
2 2
(il determinante
|) = (âˆ’2,2,2)
ProprietÃ : Siano ğ‘£(ğ‘£ğ‘¥, ğ‘£ğ‘¦, ğ‘£ğ‘§) e ğ‘¤(ğ‘¤ğ‘¥, ğ‘¤ğ‘¦, ğ‘¤ğ‘§) âˆˆ ğ’± e â„› = (ğ‘‚, â„›ğ’± = (ğ‘’ğ‘¥, ğ‘’ğ‘¦, ğ‘’ğ‘§))
1. (ğ‘£ Ã— ğ‘¤) â‹… ğ‘£ = 0 (il prodotto vettoriale Ã¨ sempre ortogonale al prodotto dei due vettori fra di loro)
Dim.: (ğ‘£ Ã— ğ‘¤) â‹… ğ‘£ = ((ğ‘£ğ‘¦ğ‘¤ğ‘§ âˆ’ ğ‘¤ğ‘¦ğ‘£ğ‘§)ğ‘’ğ‘¥ âˆ’ (ğ‘£ğ‘¥ğ‘¤ğ‘§ âˆ’ ğ‘£ğ‘§ğ‘¤ğ‘¥)ğ‘’ğ‘¦ + (ğ‘£ğ‘¥ğ‘¤ğ‘¦ âˆ’ ğ‘¤ğ‘¥ğ‘£ğ‘¦)ğ‘’ğ‘§) â‹… ğ‘£ = ğ‘£ğ‘¦ğ‘¤ğ‘§ğ‘£ğ‘¥
Ì‡ âˆ’
Ìˆ âˆ’ ğ‘£ğ‘¥ğ‘¤ğ‘§ğ‘£ğ‘¦
ğ‘¤ğ‘¦ğ‘£ğ‘§ğ‘£ğ‘¥
Ì‡ + ğ‘£ğ‘§ğ‘¤ğ‘¥ğ‘£ğ‘¦
âƒ› + ğ‘£ğ‘¥ğ‘¤ğ‘¦ğ‘£ğ‘§
Ìˆ âˆ’ ğ‘¤ğ‘¥ğ‘£ğ‘¦ğ‘£ğ‘§
âƒ› = 0
2. (ğ‘£ Ã— ğ‘¤) â‹… ğ‘¤ = 0
Dunque: (ğ‘£ Ã— ğ‘¤) âŠ¥ ğ‘£ e (ğ‘£ Ã— ğ‘¤) âŠ¥ ğ‘¤
3. ğ‘£ Ã— ğ‘¤ = 0 â‡” ğ‘£ e ğ‘¤ sono dipendenti â‡” ğ‘£ âˆ¥ ğ‘¤
Dim.: le componenti del prodotto vettoriale sono i minori di ordine 2 della matrice (
ğ‘’ğ‘¥
ğ‘£ğ‘¥
ğ‘’ğ‘¦
ğ‘£ğ‘¦
ğ‘’ğ‘§
ğ‘¤ğ‘¥ ğ‘¤ğ‘¦ ğ‘¤ğ‘§
ğ‘£ğ‘§ )
e quindi per dimostrare la nostra ipotesi bisogna andare a dimostrare che tutti i minori di ordine 2
44

della matrice rettangolare [ğ‘¤ğ‘¥ ğ‘¤ğ‘¦ ğ‘¤ğ‘§
ğ‘£ğ‘¥
ğ‘£ğ‘¦
ğ‘£ğ‘§
sottomatrice [ğ‘¤ğ‘¥ ğ‘¤ğ‘¦ ğ‘¤ğ‘§
ğ‘£ğ‘¥
ğ‘£ğ‘¦
ğ‘£ğ‘§
] Ã¨ 1; e di conseguenza |ğ‘£ğ‘¥
] siano uguali a 0 e lo sono, quindi il rango di questa
ğ‘’ğ‘¥
ğ‘’ğ‘¦
ğ‘£ğ‘¦
ğ‘’ğ‘§
ğ‘¤ğ‘¥ ğ‘¤ğ‘¦ ğ‘¤ğ‘§
ğ‘£ğ‘§ | = 0 e dunque per il teorema
degli orlati (essendo la sottomatrice di rango 1) le righe (ğ‘£ğ‘¥, ğ‘£ğ‘¦, ğ‘£ğ‘§) e (ğ‘¤ğ‘¥, ğ‘¤ğ‘¦, ğ‘¤ğ‘§) sono
proporzionali (dipendenti), ovvero (per la coordinazione associata) ğ‘£ e ğ‘¤ sono dipendenti.
4. ğ‘£ Ã— ğ‘¤ = âˆ’(ğ‘¤ Ã— ğ‘£) (non Ã¨ simmetrico)
Dim.: Pensando al determinante |
ğ‘’ğ‘¥
ğ‘£ğ‘¥
ğ‘’ğ‘¦
ğ‘£ğ‘¦
ğ‘’ğ‘§
ğ‘¤ğ‘¥ ğ‘¤ğ‘¦ ğ‘¤ğ‘§
ğ‘£ğ‘§ | se si scambiano la seconda e la terza riga per la
proprietÃ  del determinante le due matrici avranno il segno scambiato.
5. ğ‘’ğ‘¥ Ã— ğ‘’ğ‘¦ = ğ‘’ğ‘§
ğ‘’ğ‘¦ Ã— ğ‘’ğ‘§ = ğ‘’ğ‘¥
ğ‘’ğ‘§ Ã— ğ‘’ğ‘¥ = ğ‘’ğ‘¦
Dim.: Basta farsi i conti: (1,0,0) Ã— (0,1,0) = (0,0,1) (nota che (0,1,0) Ã— (1,0,0) = (0,0, âˆ’1)
Rappresentazioni
Definizione: un insieme di punti del piano ğ‘‹ Ã¨ rappresentabile se e soltanto se esiste un sistema di equazioni
ğ‘†ğ‘‡ in due incognite (ed eventuali parametri ğ‘‡) tale che ğ‘ƒ âˆˆ ğ‘‹ â‡” âˆƒğ‘‡ (valore per quei parametri) tale che le
coordinate di ğ‘ƒ nel riferimento fissato appartengono a ğ‘†ğ‘‡ (lâ€™insieme di soluzioni di ğ‘†ğ‘‡).
Esempio ipotetico di parametri: se avessimo 3ğ‘¥ + 4ğ‘¦ + ğ‘˜ = 0 come nostro sistema e (2,3) ne Ã¨ soluzione
allora deve esistere un ğ‘˜ per cui (2,3) Ã¨ soluzione di 3ğ‘¥ + 4ğ‘¦ + ğ‘˜ = 0. Concetto analogo ovviamente nel
caso dello spazio, che avrÃ² semplicemente tre componenti e quindi 3 incognite.
Rappresentazione di un piano nello spazio
Rappresentazione parametrica: Sia ğœ‹ un piano dello spazio. Allora ğœ‹ Ã¨ rappresentato da un sistema
parametrico a coefficienti reali del tipo {
ğ‘¥ = ğ‘¥ğ‘œ + ğ‘™ğ‘  + ğ‘™â€²ğ‘¡
ğ‘¦ = ğ‘¦0 + ğ‘šğ‘  + ğ‘šâ€²ğ‘¡
ğ‘¡ = ğ‘¡0 + ğ‘›ğ‘  + ğ‘›â€²ğ‘¡
dove (ğ‘™, ğ‘š, ğ‘›) ed (ğ‘™â€², ğ‘šâ€², ğ‘›â€²) sono terne di
numeri reali indipendenti ed ğ‘ , ğ‘¡ parametri reali. ğ‘¥, ğ‘¦, ğ‘§ sono soluzioni di questo sistema se esistono dei valori
per ğ‘ , ğ‘¡ tale che ğ‘¥, ğ‘¦, ğ‘§ soddisfino il sistema
Dimostrazione: Vogliamo trovare le costanti (ğ‘™, ğ‘š, ğ‘›) e (ğ‘™â€², ğ‘šâ€², ğ‘›â€²) tali che un punto ğ‘ƒ appartenga al piano se
e solamente se le sue coordinate soddisfino quel sistema di equazioni. Fissiamo un punto del piano
ğ´(ğ‘¥0, ğ‘¦0, ğ‘§0) âˆˆ ğœ‹, dopodichÃ©, sapendo che il piano Ã¨ determinato da un punto e da due vettori che giacciono
sul piano e ci danno la direzione del piano (oppure semplicemente da tre punti), siano ğ‘£(ğ‘™, ğ‘š, ğ‘›) e
ğ‘£â€²(ğ‘™â€², ğ‘šâ€², ğ‘›â€²) due vettori liberi indipendenti e paralleli a ğœ‹ allora: ğ‘ƒ âˆˆ ğœ‹ â‡” ğ´ğ‘ƒ, ğ‘£, ğ‘£â€² applicati in ğ´ sono
complanari â‡” ğ´ğ‘ƒ, ğ‘£, ğ‘£â€² dipendenti â‡” ğ´ğ‘ƒ âˆˆ âŒ©ğ‘£, ğ‘£â€²âŒª. Abbiamo cosÃ¬ visto che questo sistema Ã¨ formato da tre
vettori dipendenti e quello che dipende dai rimanenti Ã¨ proprio ğ´ğ‘ƒ essendo ğ‘£, ğ‘£â€² indipendenti. In termini di
componenti questo significa che (applicando la coordinazione associata) ğ¶â„›(ğ‘ƒ) = ğ¶â„›(ğ‘¥ âˆ’ ğ‘¥0, ğ‘¦ âˆ’ ğ‘¦0, ğ‘§ âˆ’
ğ‘§0) âˆˆ âŒ©(ğ‘™, ğ‘š, ğ‘›), (ğ‘™â€², ğ‘šâ€², ğ‘›â€²)âŒª = âŒ©ğ‘£, ğ‘£â€²âŒª che Ã¨ equivalente a scrivere: âˆƒğ‘¡, ğ‘  âˆˆ â„ âˆ¶ {
ğ‘¥ âˆ’ ğ‘¥0 = ğ‘™ğ‘  + ğ‘™â€²ğ‘¡
ğ‘¦ âˆ’ ğ‘¦0 = ğ‘šğ‘  + ğ‘šâ€²ğ‘¡
ğ‘¡ âˆ’ ğ‘¡0 = ğ‘›ğ‘  + ğ‘›â€²ğ‘¡
RF NN,
â€˜
~
yw
â€œA(9,46)
a?
Ogni sistema del tipo {
ğ‘¥ = ğ‘¥0 + ğ‘™ğ‘  + ğ‘™â€²ğ‘¡
ğ‘¦ = ğ‘¦0 + ğ‘šğ‘  + ğ‘šâ€²ğ‘¡
ğ‘¡ = ğ‘¡0 + ğ‘›ğ‘  + ğ‘›â€²ğ‘¡
rappresenta un piano.
Di quanto mi muovo su una direzione Ã¨ determinato dal parametro ğ‘ 
mentre di quanto mi muovo sullâ€™altra Ã¨ determinato dal parametro ğ‘¡
45
.

Proposizione (rappresentazione in forma ordinaria o cartesiana): Il piano ğœ‹ Ã¨ rappresentato da unâ€™equazione
del tipo ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0 con (ğ‘, ğ‘, ğ‘) â‰  (0,0,0), inoltre il vettore ğ‘¤(ğ‘, ğ‘, ğ‘) âŠ¥ ğœ‹.
Dimostrazione: Segue lo stesso percorso della dimostrazione precedente solamente che arrivati al punto
della coordinazione associata non sviluppiamo in termini di combinazione lineare ma utilizziamo il fatto che
questi tre vettori sono dipendenti: ğ‘ƒ âˆˆ ğœ‹ â‡” ğ‘£, ğ‘£â€² e ğ´ğ‘ƒ dipendenti â‡” |
ğ‘¥ âˆ’ ğ‘¥0 ğ‘¦ âˆ’ ğ‘¦0 ğ‘§ âˆ’ ğ‘§0
ğ‘™
ğ‘š
ğ‘™â€²
ğ‘šâ€²
ğ‘›
ğ‘›â€²
| = 0,
sviluppandolo per la prima riga: (ğ‘šğ‘›â€² âˆ’ ğ‘›â€²ğ‘š) (ğ‘¥ âˆ’ ğ‘¥0) + (ğ‘™â€²ğ‘› âˆ’ ğ‘™ğ‘›â€²) (ğ‘¦ âˆ’ ğ‘¦0) + (ğ‘™ğ‘šâ€² âˆ’ ğ‘™â€²ğ‘š) (ğ‘§ âˆ’ ğ‘§0) = 0
âŸ        
ğ‘
âŸ      
ğ‘
âŸ        
ğ‘
chiamando poi tutti i termini senza incognita ğ‘‘ = âˆ’ğ‘ğ‘¥0 âˆ’ ğ‘ğ‘¦0 âˆ’ ğ‘ğ‘§0 risulterÃ  ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0; ora ci
rimane da osservare che (ğ‘, ğ‘, ğ‘) â‰  (0,0,0) e che ğ‘¤(ğ‘, ğ‘, ğ‘) âŠ¥ ğœ‹; ma essendo ğ‘, ğ‘, ğ‘ i minori della
sottomatrice rettangolare presi a segno alterno essi rappresentano le componenti del prodotto vettoriale tra
ğ‘£ e ğ‘£â€², e poichÃ© questi ultimi non sono paralleli (essendo indipendenti) il prodotto non puÃ² essere nullo (per
una proprietÃ  giÃ  vista) deve succedere che (ğ‘, ğ‘, ğ‘) = (ğ‘™, ğ‘š, ğ‘›) Ã— (ğ‘™â€², ğ‘šâ€², ğ‘›â€²) â‰  0, dopodichÃ© il prodotto
vettoriale Ã¨ perpendicolare a entrambi i vettori del prodotto, ma allora se Ã¨ perpendicolare ai due vettori del
piano ğ‘£ e ğ‘£â€², evidentemente Ã¨ perpendicolare anche al piano stesso.
Proposizione (il viceversa della precedente): Ogni equazione ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0 con (ğ‘, ğ‘, ğ‘) â‰  (0,0,0)
rappresenta un piano ğœ‹ ortogonale a (ğ‘, ğ‘, ğ‘).
Dimostrazione: vado a prendere due vettori ortogonali ad (ğ‘, ğ‘, ğ‘) che siano indipendenti, per trovarli devo
risolvere il sistema ğ‘£ â‹… (ğ‘, ğ‘, ğ‘) = 0, ovvero devo risolvere il sistema ğ‘ğ‘£ğ‘¥ + ğ‘ğ‘£ğ‘¦ + ğ‘ğ‘£ğ‘§ = 0; essendo per
ipotesi (ğ‘, ğ‘, ğ‘) â‰  (0,0,0) abbiamo la certezza che uno tra ğ‘, ğ‘, ğ‘ deve essere diverso da zero, diciamo che
sia ğ‘ â‰  0 allora ğ‘£ğ‘¥ = âˆ’
1
ğ‘ (ğ‘ğ‘£ğ‘¦ + ğ‘ğ‘£ğ‘§) e quindi ğ‘† = {(âˆ’
1
ğ‘ (ğ‘ğ‘£ğ‘¦ + ğ‘ğ‘£ğ‘§), ğ‘£ğ‘¦, ğ‘£ğ‘§) |ğ‘£ğ‘¦, ğ‘£ğ‘§ âˆˆ â„} con dimğ‘† = 2 e
quindi sicuramente posso trovare due vettori ortogonali ad (ğ‘, ğ‘, ğ‘) che siano indipendenti. Prendo un piano
ğœ‹â€² passante per questi due vettori e perpendicolare ad (ğ‘, ğ‘, ğ‘), mi fisso una soluzione dellâ€™equazione ğ‘ğ‘¥ +
ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0 e il punto corrispondente a questa soluzione lo chiamo ğ´(ğ‘¥0, ğ‘¦0, ğ‘§0) âˆˆ ğœ‹ allora succede che
il piano ğœ‹â€² per la rappresentazione ordinaria Ã¨ rappresentato dallâ€™equazione ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘§ + ğ‘‘â€² = 0 e
(ğ‘â€², ğ‘â€², ğ‘â€²) ed Ã¨ perpendicolare a ğœ‹â€², ma essendo ğœ‹â€² perpendicolare a sua volta alla terna (ğ‘, ğ‘, ğ‘) (essendo
parallelo ai due vettori fissati in precedenza), ed essendo le due terne entrambe perpendicolari allo stesso
piano risulta (ğ‘, ğ‘, ğ‘) âˆ¥ (ğ‘â€², ğ‘â€², ğ‘â€²) e questo vuol dire che posso scrivere ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0 come ğ‘˜ğ‘ğ‘¥ +
ğ‘˜ğ‘ğ‘¦ + ğ‘˜ğ‘ğ‘§ + ğ‘‘â€² = 0 con ğ‘˜ â‰  0; il piano ğœ‹â€² risulta quindi avere lâ€™equazione cosÃ¬ descritta, inoltre essendo
ğ‘˜ â‰  0 posso scrivere ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ +
ğ‘‘â€²
ğ‘˜ = 0; a questo punto per la scelta fatta di ğ´ le sue coordinate
soddisfano lâ€™equazione ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0 oltre allâ€™equazione ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ +
ğ‘‘â€²
ğ‘˜ = 0, ma poichÃ©
entrambi passano per ğ´(ğ‘¥0, ğ‘¦0, ğ‘§0) posso eguagliare le equazioni e quindi ğ‘‘ =
ğ‘‘â€²
ğ‘˜ â‡’ ğ‘‘â€² = ğ‘‘ğ‘˜ e questo vuol
dire che lâ€™equazione ğœ‹â€²: ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘§ + ğ‘‘â€² = 0 Ã¨ equivalente (dividendo per ğ‘˜) a ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0
e quindi ğœ‹â€² Ã¨ il piano ğœ‹ stesso
Osservazione: Abbiamo dimostrato che due equazioni del tipo ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0 che rappresentano lo
stesso identico piano devono essere proporzionali (ğ‘˜ â‰  0) e viceversa.
Esempi:
1) Come si rappresenta tutto lo spazio?
Semplicemente con una tautologia (unâ€™equazione sempre vera) come 0 = 0
2) Come si rappresenta lâ€™insieme vuoto?
Con una contraddizione: 0 â‰  0 (lâ€™equazione parametrica non Ã¨ mai soddisfatta)
3) Sia ğœ‹ per ğ´(4,3, âˆ’2) e parallelo ai vettori ğ‘£(1,âˆ’1,0) e ğ‘£â€²(2,1,3). Come si scrive lâ€™equazione parametrica
e la rappresentazione cartesiana?
ğœ‹ âˆ¶ {
ğ‘¥ = 4 + ğ‘  + 2ğ‘¡
ğ‘¦ = 3 âˆ’ ğ‘  + ğ‘¡
ğ‘§ = âˆ’2 + 3ğ‘¡
|
ğ‘¥ âˆ’ 4 ğ‘¦ âˆ’ 3 ğ‘§ + 2
1
âˆ’1
2
1
0
3
| = ğ‘¥ + ğ‘¦ âˆ’ ğ‘§ âˆ’ 9 = 0
46

Rappresentazione della retta nel piano
Rappresentazione parametrica: Una retta ğ‘Ÿ puÃ² essere rappresentata mediante un sistema di equazioni in
un parametro del tipo {
ğ‘¥ = ğ‘¥0 + ğ‘™ğ‘¡
ğ‘¦ = ğ‘¦0 + ğ‘šğ‘¡ con la coppia (ğ‘™, ğ‘š) â‰  (0,0) e ğ‘¡ parametro (si nota subito che si ha una
dimostrazione simile a quella fatta con il piano nello spazio).
Dimostrazione (simile a quella fatta con il piano): Prendiamo un punto ğ´(ğ‘¥0, ğ‘¦0) âˆˆ ğ‘Ÿ e un vettore direzione
ğ‘£(ğ‘™, ğ‘š) âˆ¥ ğ‘Ÿ con (ğ‘™, ğ‘š) â‰  (0,0), vediamo che un punto ğ‘ƒ âˆˆ ğ‘Ÿ â‡” ğ´ğ‘ƒ âˆ¥ ğ‘£, e questo mi assicura anche che ğ‘ƒ
appartenga alla retta, altrimenti non potrebbe essere parallelo a ğ‘£, inoltre ğ´ğ‘ƒ âˆ¥ ğ‘£ â‡” ğ´ğ‘ƒ e ğ‘£ sono dipendenti
â‡” (ğ‘¥ âˆ’ ğ‘¥0, ğ‘¦ âˆ’ ğ‘¦0), (ğ‘™, ğ‘š) dipendenti (per la coordinazione associata) â‡” âˆƒğ‘¡ âˆˆ â„ âˆ¶
{
ğ‘¥ âˆ’ ğ‘¥0 = ğ‘¡ğ‘™
ğ‘¦ âˆ’ ğ‘¦0 = ğ‘¡ğ‘š;
questâ€™ultima condizione significa anche che il primo vettore Ã¨ proporzionale al secondo.
Rappresentazione ordinaria: la retta Ã¨ rappresentata da unâ€™equazione del tipo ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 con (ğ‘, ğ‘) â‰ 
(0,0), inoltre il vettore ğ‘£(âˆ’ğ‘, ğ‘) âˆ¥ ğ‘Ÿ.
Dimostrazione: Prendiamo un punto ğ´(ğ‘¥0, ğ‘¦0) âˆˆ ğ‘Ÿ e un vettore direzione ğ‘£(ğ‘™, ğ‘š) âˆ¥ ğ‘Ÿ con (ğ‘™, ğ‘š) â‰  (0,0)
allora ğ‘ƒ âˆˆ ğ‘Ÿ â‡” ğ´ğ‘ƒ âˆ¥ ğ‘£ â‡” ğ´ğ‘ƒ e ğ‘£ sono dipendenti â‡” (ğ‘¥ âˆ’ ğ‘¥0, ğ‘¦ âˆ’ ğ‘¦0) con (ğ‘™, ğ‘š) dipendenti; si mettano
queste due coppie sulla matrice e se ne faccia il determinante: |
ğ‘¥ âˆ’ ğ‘¥0 ğ‘¦ âˆ’ ğ‘¦0
ğ‘™
ğ‘š
| = 0; poichÃ© sono
dipendenti il determinante Ã¨ zero e questo vuol dire anche che (sviluppando il determinante attraverso la
prima riga) ğ‘š(ğ‘¥ âˆ’ ğ‘¥0) âˆ’ ğ‘™(ğ‘¦ âˆ’ ğ‘¦0) = 0 â‡” ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 con (ğ‘š, âˆ’ğ‘™) = (ğ‘, ğ‘) e ğ‘ = âˆ’ğ‘šğ‘¥0 + ğ‘™ğ‘¦0; si noti
anche che la coppia (ğ‘, ğ‘) â‰  0 per il semplice motivo che per ipotesi (ğ‘™, ğ‘š) â‰  (0,0) ed inoltre (âˆ’ğ‘, ğ‘) âˆ¥ ğ‘£ e
quindi parallelo ad ğ‘Ÿ.
Viceversa (della rappresentazione parametrica): Ogni sistema {
ğ‘¥ = ğ‘¥0 + ğ‘ ğ‘™
ğ‘¦ = ğ‘¦0 + ğ‘ ğ‘š con (ğ‘™, ğ‘š) â‰  (0,0) rappresenta
la retta che passa per (ğ‘¥0, ğ‘¦0) ed Ã¨ parallela al vettore ğ‘£(ğ‘™, ğ‘š)
Dimostrazione: non Ã¨ una vera dimostrazione, Ã¨ piÃ¹ una cosa intuitiva. Il fatto che le
coordinate di un punto debbano soddisfare quel sistema parametrico significa che
(essendo ğ‘  parametro) se faccio ğ‘  = 0 si ha che ğ‘¥ = ğ‘¥0 e ğ‘¦ = ğ‘¦0; di conseguenza
lâ€™insieme di soluzioni del sistema ammette per certo la soluzione (ğ‘¥0, ğ‘¦0); in realtÃ 
per ogni valore di ğ‘  il sistema ammette sempre e solo una soluzione, essendo
(ğ‘¥0, ğ‘¦0) fissati a monte. Quindi variare ğ‘  significa variare il modulo del vettore
ğ‘£(ğ‘™, ğ‘š) e quindi ci si sposta sempre muovendosi sulla stessa retta (vedi figura a destra).
Gu)
Viceversa (della rappresentazione ordinaria): Ogni equazione ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 con (ğ‘, ğ‘) â‰  (0,0)
rappresenta una retta ğ‘Ÿ che sia parallela al vettore ğ‘£(âˆ’ğ‘, ğ‘).
Dimostrazione: poichÃ© (ğ‘, ğ‘) â‰  (0,0) lâ€™equazione ammette ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 almeno una soluzione (se ğ‘ â‰ 
0 esplicito ğ‘¥, se Ã¨ ğ‘ â‰  0 allora esplicito ğ‘¦) allora mi prendo una soluzione ğ´(ğ‘¥0, ğ‘¦0) e vado a costruirmi la
retta ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¦ + ğ‘â€² = 0 passante per il punto ğ´ e parallela al vettore ğ‘£(âˆ’ğ‘, ğ‘). Ne consegue che la coppia
(âˆ’ğ‘â€², ğ‘â€²) deve essere proporzionale a (âˆ’ğ‘, ğ‘) e quindi (âˆ’ğ‘â€², ğ‘â€²) âˆ¥ (âˆ’ğ‘, ğ‘) ed allora, essendo entrambe le
coppie diverse da (0,0), posso scrivere ğ‘â€² = ğ‘˜ğ‘, ğ‘â€² = ğ‘˜ğ‘, dopodichÃ© (esattamente come fatto con il piano),
imponendo la condizione che lâ€™equazione ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¦ + ğ‘â€² = 0 deve passare per il punto (ğ‘¥0, ğ‘¦0) si ha anche
ğ‘â€² = ğ‘˜ğ‘. Quindi abbiamo trovato che ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¦ + ğ‘â€² = 0 â‡” ğ‘˜ğ‘ğ‘¥ + ğ‘˜ğ‘ğ‘¦ + ğ‘˜ğ‘ = 0; semplificando la
costante ğ‘˜ (che non puÃ² essere nulla per via delle tre uguaglianze descritte precedentemente) vuol dire che
Ã¨ la stessa equazione di partenza e mi rappresenta proprio la retta ğ‘Ÿ: ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0.
Osservazione: Due equazioni ordinarie rappresentano la stessa retta se e solo se sono proporzionali (ğ‘˜ â‰  0).
Definizione: se ho una retta ğ‘Ÿ ed un vettore non nullo ğ‘£(ğ‘™, ğ‘š) âˆ¥ ğ‘Ÿ allora le componenti di questo vettore ğ‘£ le
chiamo numeri direttori (o parametri) della retta ğ‘Ÿ. E questi parametri di vettori (per il parallelismo) sono
ben definiti a meno di un fattore di proporzionalitÃ  non nullo.
47

Altre tipologie di espressione
Espressione di una retta passante per due punti
Siano ğ´(ğ‘¥1, ğ‘¦1), ğµ(ğ‘¥2, ğ‘¦2) âˆˆ ğœ‹, una retta ğ‘Ÿ passante per ğ´ e ğµ (si puÃ² parafrasare anche con ğ´ğµ âˆ¥ ğ‘Ÿ ) Ã¨
semplicemente una retta passante per ğ´ e parallela a ğ‘£(ğ‘¥2 âˆ’ ğ‘¥1, ğ‘¦2 âˆ’ ğ‘¦1). Quindi ğ‘Ÿ âˆ¶ {
ğ‘¥ = ğ‘¥1 + (ğ‘¥2 âˆ’ ğ‘¥1)ğ‘¡
ğ‘¦ = ğ‘¦1 + (ğ‘¦2 âˆ’ ğ‘¦1)ğ‘¡
con stesso parametro ğ‘¡. Inoltre, il precedente sistema si puÃ² riscrivere come {
ğ‘¥ âˆ’ ğ‘¥1 = (ğ‘¥2 âˆ’ ğ‘¥1)ğ‘¡
ğ‘¦ âˆ’ ğ‘¦1 = (ğ‘¦2 âˆ’ ğ‘¦1)ğ‘¡
e se li
guardo come vettori avrÃ² che (ğ‘¥ âˆ’ ğ‘¥1, ğ‘¦ âˆ’ ğ‘¦1) Ã¨ proporzionale a (ğ‘¥2 âˆ’ ğ‘¥1, ğ‘¦2 âˆ’ ğ‘¦1), altro modo per vedere
che sono proporzionali Ã¨ il determinante: |
ğ‘¥ âˆ’ ğ‘¥1
ğ‘¦ âˆ’ ğ‘¦1
ğ‘¥2 âˆ’ ğ‘¥1 ğ‘¦2 âˆ’ ğ‘¦1
| = 0 â‡” (ğ‘¥ âˆ’ ğ‘¥1)(ğ‘¦2 âˆ’ ğ‘¦1) âˆ’ (ğ‘¦ âˆ’ ğ‘¦1)(ğ‘¥2 âˆ’
ğ‘¥1) = 0 â‡” (ğ‘¥ âˆ’ ğ‘¥1)(ğ‘¦2 âˆ’ ğ‘¦1) = (ğ‘¦ âˆ’ ğ‘¦1)(ğ‘¥2 âˆ’ ğ‘¥1); che si avvicina molto alla formula dei rapporti uguali,
infatti se succede che ğ‘¦2 âˆ’ ğ‘¦1 â‰  0 â‰  ğ‘¥2 âˆ’ ğ‘¥1 (quindi se ğ´, ğµ non sono paralleli ne allâ€™asse ğ‘¥ ne allâ€™asse ğ‘¦)
dividendo per (ğ‘¥2 âˆ’ ğ‘¥1) e (ğ‘¦2 âˆ’ ğ‘¦1) avrÃ² la formula dei rapporti uguali:
ğ‘¥âˆ’ğ‘¥1
=
.
ğ‘¥2âˆ’ğ‘¥1
ğ‘¦2âˆ’ğ‘¦1
Altra formulazione classica per una retta Ã¨ la forma esplicita: parto dalla forma ordinaria ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0
della retta ğ‘Ÿ (si noti che una retta passa per (0,0) se e soltanto se ğ‘ = 0). PuÃ² succedere che se ğ‘ â‰  0 posso
esplicitare ğ‘¦ â‡’ ğ‘¦ = âˆ’
ğ‘
ğ‘ ğ‘¥ âˆ’
ğ‘
ğ‘, chiamando âˆ’
ğ‘
ğ‘ = ğ‘š e âˆ’
ğ‘¦âˆ’ğ‘¦1
ğ‘
ğ‘ = ğ‘, si ha la forma esplicita (che non Ã¨ detto che
esista, infatti dipende da ğ‘) ğ‘¦ = ğ‘šğ‘¥ + ğ‘ dove ğ‘š Ã¨ detto coefficiente angolare di ğ‘Ÿ.
Coseni direttori
Prendiamo una retta orientata ğ‘Ÿ (ne fissiamo un verso) e prendiamo un vettore ğ‘£ âˆ¥ ğ‘Ÿ e definisco i coseni
direttori di questa retta come i coseni dellâ€™angolo che forma con il vettore delle ascisse e quello che forma
con il vettore unitario dellâ€™asse delle ordinate, rispettivamente: cos(ğ‘’ğ‘¥^ğ‘£) e cos(ğ‘’ğ‘¦^ğ‘£). E come giÃ  visto in
precedenza per ğ‘Ÿ: ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 sarÃ : : cos(ğ‘’ğ‘¥^ğ‘£) = Â± ğ‘
â„
âˆšğ‘2 + ğ‘2 e cos(ğ‘’ğ‘¦^ğ‘£) = Â±ğ‘
â„âˆšğ‘2 + ğ‘2; non
Ã¨ detto che il vettore (âˆ’ğ‘, ğ‘) punti nella stessa direzione della retta, ma Ã¨ comunque parallelo ad essa, per
cui il Â± Ã¨ a seconda che (âˆ’ğ‘, ğ‘) sia concorde (+) o discorde (âˆ’) con lâ€™orientazione fissata della retta ğ‘Ÿ.
Quindi, i coseni direttori sono semplicemente i coseni degli angoli che formano un vettore parallelo alla retta
con gli assi coordinati.
Rette parallele
Due rette ğ‘Ÿ e ğ‘Ÿâ€² sono parallele se e solamente se o hanno intersezione vuota ğ‘Ÿ âˆ© ğ‘Ÿâ€² â‰  âˆ… (propriamente),
oppure se coincidono ğ‘Ÿ = ğ‘Ÿâ€² (impropriamente).
Al fine di determinare qualche criterio di parallelismo prendiamo dei numeri di vettori per ğ‘Ÿ e ğ‘Ÿâ€². Ovvero
siano ğ‘£(ğ‘™, ğ‘š) âˆ¥ ğ‘Ÿ e ğ‘£â€²(ğ‘™â€², ğ‘šâ€²) âˆ¥ ğ‘Ÿâ€², dire che ğ‘Ÿ âˆ¥ ğ‘Ÿâ€² equivale a dire che quei vettori sono paralleli e dunque che
(ğ‘™, ğ‘š), (ğ‘™â€², ğ‘šâ€²) sono proporzionali. Volendo esprimere le rette con la rappresentazione cartesiana, quindi si
ha ğ‘Ÿ: ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 e ğ‘Ÿâ€²: ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¦ + ğ‘â€² = 0 con (âˆ’ğ‘, ğ‘) âˆ¥ ğ‘Ÿ e (âˆ’ğ‘â€², ğ‘â€²) âˆ¥ ğ‘Ÿâ€² e di conseguenza ğ‘Ÿ âˆ¥ ğ‘Ÿâ€² â‡”
(âˆ’ğ‘, ğ‘) Ã¨ proporzionale a (âˆ’ğ‘â€², ğ‘â€²) â‡” (ğ‘, ğ‘) proporzionale a (ğ‘â€², ğ‘â€²); a questo punto possono succedere
due cose: tutta la terna (ğ‘, ğ‘, ğ‘) Ã¨ proporzionale a (ğ‘â€², ğ‘â€², ğ‘â€²) e quindi le due equazioni sono proporzionali di
una costante non nulla e definiscono quindi la stessa retta (parallele impropriamente); altrimenti, (ğ‘, ğ‘, ğ‘)
non Ã¨ proporzionale a (ğ‘â€², ğ‘â€², ğ‘â€²) e quindi sono parallele propriamente (non possono avere punti in comune).
Vediamo perchÃ© non possono avere punti in comune, prendiamo il sistema {
ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0
ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¦ + ğ‘â€² = 0
, sappiamo
che (ğ‘, ğ‘) Ã¨ proporzionale a (ğ‘â€², ğ‘â€²), se risulta (ğ‘, ğ‘, ğ‘) non proporzionale a (ğ‘â€², ğ‘â€², ğ‘â€²) allora il rango della
matrice incompleta di quel sistema Ã¨ 1, ma essendo le terne non proporzionali la matrice completa ha rango
2 e quindi per RouchÃ©-Capelli avremo un sistema non compatibile e cioÃ¨ che le due equazioni non hanno
punti in comune. Viceversa, se anche (ğ‘, ğ‘, ğ‘) Ã¨ proporzionale a (ğ‘â€², ğ‘â€², ğ‘â€²) allora il sistema avrÃ  un numero
infinito di soluzione e quindi sarÃ  un sistema compatibile.
48

Distanza tra insiemi
Vediamola per il piano (in maniera analoga si procede per lo spazio), siano ğ´(ğ‘¥1, ğ‘¦1) e ğµ(ğ‘¥2, ğ‘¦2) âˆˆ ğœ‹ la
distanza dal punta ğ´ al punto ğµ si definisce ğ‘‘(ğ´, ğµ) = âˆš(ğ‘¥2 âˆ’ ğ‘¥1)2 + (ğ‘¦2 âˆ’ ğ‘¦1)2 = |ğ´ğµ|
La distanza tra due sottoinsiemi ğ‘†, ğ‘‡ âŠ† ğœ‹ la definisco come lâ€™estremo inferiore (non dico minimo poichÃ© non
ho la certezza che stia allâ€™interno degli insiemi) delle distanze tra i punti di ğ‘† e di ğ‘‡, piÃ¹ precisamente
dist(ğ‘†, ğ‘‡) = inf{ğ‘‘(ğ‘ƒ, ğ‘„), ğ‘ƒ âˆˆ ğ‘†, ğ‘„ âˆˆ ğ‘‡} â‰¥ 0.
Esempi: 1)
A
LA
ye
7 1Â°)|m eN
(4,0)/ aeN :
olt (X,Y) =0
2) ğ‘‹ âˆ© ğ‘Œ â‰  âˆ… â‡’ dist(ğ‘‹, ğ‘Œ) = 0 poichÃ© âˆƒğ‘ƒ âˆˆ ğ‘‹ âˆ© ğ‘Œ per cui ğ‘‘(ğ‘ƒ, ğ‘ƒ) = 0.
Punto medio di un segmento
Prendiamo un segmento del piano, che Ã¨ ovviamente delimitato dai suoi estremi: ğ´(ğ‘¥1, ğ‘¦1) â‰  ğµ(ğ‘¥2, ğ‘¦2),
allora il punto medio ğ‘€(ğ‘¥ğ‘€, ğ‘¦ğ‘€) Ã¨ un punto che si trova alla stessa distanza dal punta ğ´ e dal punto ğµ, quindi
risulterÃ  che i vettori geometrici ğ´ğ‘€ e ğ‘€ğµ sono uguali, allora passando alla coordinazione associata le
componenti di ğ´ğ‘€ e ğ‘€ğµ devono essere le stesse, quindi (ğ‘¥ğ‘€ âˆ’ ğ‘¥1, ğ‘¦ğ‘€ âˆ’ ğ‘¦1) = (ğ‘¥2 âˆ’ ğ‘¥ğ‘€, ğ‘¦2 âˆ’ ğ‘¦ğ‘€) da cui il
sistema {
ğ‘¥ğ‘€ âˆ’ ğ‘¥1 = ğ‘¥2 âˆ’ ğ‘¥ğ‘€
ğ‘¦ğ‘€ âˆ’ ğ‘¦1 = ğ‘¦2 âˆ’ ğ‘¦ğ‘€
â‡’ {
ğ‘¥ğ‘€ =
ğ‘¦ğ‘€ =
ğ‘¥2+ğ‘¥1
2
ğ‘¦2+ğ‘¦1
2
Asse del segmento
Dato sempre il segmento precedente, lâ€™asse di un segmento Ã¨ il luogo geometrico dei
punti (lâ€™insieme dei punti) che ha la stessa distanza dal punto ğ´ e dal punto ğµ (si trova
quindi sulla retta perpendicolare al segmento ğ´ğµ che passa per il punto medio).
Si puÃ² verificare con le distanze, infatti, ğ‘ƒ âˆˆ ğ‘Ÿ â‡” ğ‘‘(ğ´, ğ‘ƒ) = ğ‘‘(ğµ, ğ‘ƒ), e ciÃ² vuol dire
(ğ‘¥ âˆ’ ğ‘¥1)2 + (ğ‘¦ âˆ’ ğ‘¦1)2 = (ğ‘¥ âˆ’ ğ‘¥2)2 + (ğ‘¦ âˆ’ ğ‘¦2)2 â‡” 2ğ‘¥(ğ‘¥2 âˆ’ ğ‘¥1) + 2ğ‘¦(ğ‘¦2 âˆ’ ğ‘¦1) + ğ‘¥1
2 + ğ‘¦1
2 âˆ’ ğ‘¥2
2 âˆ’ ğ‘¦2
2 = 0
che, se la si nota bene, Ã¨ lâ€™equazione di una retta del tipo ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ = 0 e poichÃ© ğ´ â‰  ğµ o ğ‘¥2 âˆ’ ğ‘¥1 â‰  0
oppure ğ‘¦2 âˆ’ ğ‘¦1 â‰  0 perchÃ© o ğ‘¥1 â‰  ğ‘¥2 oppure ğ‘¦1 â‰  ğ‘¦2, questa Ã¨ un equazione ordinaria della retta.
Un vettore parallelo a questa retta sarÃ  dunque (âˆ’ğ‘, ğ‘) = (ğ‘¦1 âˆ’ ğ‘¦2, ğ‘¥2 âˆ’ ğ‘¥1) e quello che si puÃ² verificare e
che il vettore geometrico ğ´ğµ ha le componenti (ğ‘¥2 âˆ’ ğ‘¥1, ğ‘¦2 âˆ’ ğ‘¦1) ovvero (ğ‘, ğ‘) e quindi il prodotto scalare
tra (âˆ’ğ‘, ğ‘) e (ğ‘, ğ‘) Ã¨ pari a zero, di conseguenza se âˆ’ğ‘ğ‘ + ğ‘ğ‘ = 0 â‡’ ğ‘Ÿ âŠ¥ ğ´ğµ.
Questâ€™asse, come giÃ  detto in precedenza, deve passare per il punto medio del segmento, infatti se si prova
a sostituire le espressioni del punto medio alle incognite dellâ€™equazione 2ğ‘¥(ğ‘¥2 âˆ’ ğ‘¥1) + 2ğ‘¦(ğ‘¦2 âˆ’ ğ‘¦1) + ğ‘¥1
2 +
2 âˆ’ ğ‘¥2
ğ‘¦1
2 âˆ’ ğ‘¦2
2 = 0 (quindi ğ‘¥ğ‘€ con ğ‘¥ e ğ‘¦ğ‘€ con ğ‘¦) si troverÃ  che il punto medio Ã¨ soluzione dellâ€™equazione.
Rappresentazione ordinaria di una retta nello spazio
Una retta nello spazio si potrebbe rappresentare utilizzando una rappresentazione parametrica dello stesso
ğ‘¥ = ğ‘¥0 + ğ‘™ğ‘¡
tipo di quella usata con il piano, quindi {
ğ‘¦ = ğ‘¦0 + ğ‘šğ‘¡
ğ‘§ = ğ‘§0 + ğ‘›ğ‘¡
, ma quello che non funziona come analogo Ã¨ la
rappresentazione ordinaria poichÃ© quello che ottengo Ã¨ una matrice rettangolare e quindi non mi Ã¨ possibile
49

fare il determinante, ma quello che posso fare Ã¨ definire una retta nello spazio come intersezione dei due
piani, e sarÃ  proprio questa che chiamerÃ² rappresentazione ordinaria della retta nello spazio.
Vado a prendere due piani che non siano paralleli (altrimenti avrei una intersezione o vuota oppure i due
piani sono coincidenti) {
ğ‘ğ‘¥ + ğ‘ğ‘¦ + ğ‘ğ‘§ + ğ‘‘ = 0
ğ‘â€²ğ‘¥ + ğ‘â€²ğ‘¦ + ğ‘â€²ğ‘§ + ğ‘‘â€² = 0
e la loro intersezione sarÃ  una retta, il fatto che non siano
paralleli implica, oltre che la terna (ğ‘, ğ‘, ğ‘) rappresenta le componenti di un vettore perpendicolare al piano,
che le due terne non sono proporzionali, e questo significa che la matrice incompleta (3x2), dato che coincide
con la dimensione del sottospazio generato ad esempio dalle righe (non proporzionali), ha rango 2. Quindi
avendo rango massimo, per la teoria dei sistemi, il sistema omogeneo associato ammette âˆ1 soluzioni.
DopodichÃ©, considerato che questo Ã¨ un sistema particolare perchÃ© dovrebbe esserci ğ‘‘, tutte le soluzioni di
questa equazione si scrivono come una somma di una soluzione particolare, ad esempio (ğ‘¥0, ğ‘¦0, ğ‘§0), cioÃ¨ un
punto comune alle due equazioni e somma di un elemento generico che sia soluzione del sistema omogeneo
associato, quindi con ğ‘‘ = ğ‘‘â€² = 0, la si puÃ² scrivere quindi come sistema generato dalla terna (ğ‘™, ğ‘š, ğ‘›). PiÃ¹
precisamente, tutte le soluzioni saranno descritte da (ğ‘¥0, ğ‘¦0, ğ‘§0) + âŒ©(ğ‘™, ğ‘š, ğ‘›)âŒª con, ovviamente, (ğ‘™, ğ‘š, ğ‘›) â‰ 
(0,0,0), e sostanzialmente sto descrivendo una retta, perchÃ© prendo (ğ‘¥0, ğ‘¦0, ğ‘§0) e ci sommo una cosa
proporzionale ad (ğ‘™, ğ‘š, ğ‘›) di una certa costante di proporzionalitÃ :
Dallâ€™intersezione di due piani non paralleli viene fuori una retta.
ZA.Oma)
Oot)
50
